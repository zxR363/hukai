import sys
import os
import re
import uuid
import time
import shutil
import atexit
import json
from multiprocessing import Pool, cpu_count, freeze_support
from dataclasses import dataclass
from collections import Counter

# --------------------------------------------------
# ğŸ“¦ IMPORTLAR
# --------------------------------------------------
import fitz  # PyMuPDF
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_core.messages import SystemMessage, HumanMessage
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance, Filter, FieldCondition, MatchValue
from fpdf import FPDF
from fpdf.enums import XPos, YPos
from langchain_community.document_loaders import PyMuPDFLoader

# UTF-8 AyarÄ±
sys.stdout.reconfigure(encoding="utf-8")


# ==================================================
# 1ï¸âƒ£ KONFÄ°GÃœRASYON SINIFI
# ==================================================
@dataclass
class LegalConfig:
    SOURCES = {
        "mevzuat": {
            "folder": "mevzuatlar",
            "collection": "legal_statutes_v48",
            "desc": "MEVZUAT"
        },
        "emsal": {
            "folder": "belgeler",
            "collection": "legal_precedents_v48",
            "desc": "EMSAL KARAR"
        }
    }
    MEMORY_COLLECTIONS = {
        "decision": "judge_memory_v1",  # Karar HafÄ±zasÄ±
        "principle": "principle_memory_v1"  # Ä°lke HafÄ±zasÄ±
    }

    QDRANT_PATH = "qdrant_db_master"
    EMBEDDING_MODEL = "nomic-embed-text"
    LLM_MODEL = "qwen2.5"
    SEARCH_LIMIT_PER_SOURCE = 30
    SCORE_THRESHOLD = 0.40
    LLM_RERANK_LIMIT = 5


# ==================================================
# 2ï¸âƒ£ YARDIMCI ARAÃ‡LAR (STATIC)
# ==================================================
def worker_embed_batch_global(args):
    """Multiprocessing iÃ§in global kalmalÄ±."""
    texts, model_name = args
    try:
        embedder = OllamaEmbeddings(model=model_name)
        return embedder.embed_documents(texts)
    except Exception as e:
        print(f"âš ï¸ Batch hatasÄ± (atlanÄ±yor): {e}")
        return []


class LegalUtils:
    @staticmethod
    def force_unlock_db():
        lock_file = os.path.join(LegalConfig.QDRANT_PATH, ".lock")
        if os.path.exists(lock_file):
            try:
                os.remove(lock_file);
                print("ğŸ”“ KÄ°LÄ°T DOSYASI TEMÄ°ZLENDÄ°.")
            except:
                pass

    @staticmethod
    def extract_pdf_conclusion(file_path, char_limit=2500):
        try:
            if not os.path.exists(file_path): return "[Dosya bulunamadÄ±.]"
            doc = fitz.open(file_path)
            total_pages = len(doc)
            text = "";
            start_page = max(0, total_pages - 2)
            for i in range(start_page, total_pages): text += doc[i].get_text()
            doc.close();
            return text[-char_limit:]
        except Exception as e:
            return f"[Karar okunamadÄ±: {e}]"

    @staticmethod
    def clean_text(text):
        text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text


# ==================================================
# 3ï¸âƒ£ HAFIZA YÃ–NETÄ°CÄ°SÄ° (V70: DISCOVERY ENGINE)
# ==================================================
class LegalMemoryManager:
    def __init__(self, client, embedder, llm):
        self.client = client
        self.embedder = embedder
        self.llm = llm
        self._init_memory_collections()

    def _init_memory_collections(self):
        for name, col_name in LegalConfig.MEMORY_COLLECTIONS.items():
            if not self.client.collection_exists(col_name):
                print(f"ğŸ§  HafÄ±za oluÅŸturuluyor: {col_name}")
                self.client.create_collection(col_name, vectors_config=VectorParams(size=768, distance=Distance.COSINE))

    def recall_principles(self, query_text):
        try:
            vector = self.embedder.embed_query(query_text)
            hits = self.client.query_points(
                collection_name=LegalConfig.MEMORY_COLLECTIONS["principle"],
                query=vector,
                limit=5
            ).points

            sorted_hits = sorted(hits, key=lambda x: (
                x.payload.get("timestamp", 0),
                len(x.payload.get("principle", ""))
            ), reverse=True)[:3]

            if not sorted_hits: return ""

            memory_text = "\nğŸ’¡ YERLEÅÄ°K Ä°Ã‡TÄ°HAT HAFIZASI (Sistem GeÃ§miÅŸi):\n"
            for h in sorted_hits:
                memory_text += f"- {h.payload['principle']}\n"
            return memory_text
        except:
            return ""

    # --- V70 GÃœNCELLEMESÄ°: KEÅÄ°F BONUSU ---
    def calculate_memory_consensus(self, source_name, current_decision, vector_score):
        """
        DÃ¶nÃ¼ÅŸ: Ã‡arpan (float)
        MantÄ±k:
        1. GeÃ§miÅŸi varsa: GÃ¼ven oranÄ±na gÃ¶re artÄ±r/azalt.
        2. GeÃ§miÅŸi yoksa VE VektÃ¶r Skoru yÃ¼ksekse: 'KeÅŸif Bonusu' ver.
        """
        try:
            scroll_filter = Filter(
                must=[FieldCondition(key="source", match=MatchValue(value=source_name))]
            )
            points, _ = self.client.scroll(
                collection_name=LegalConfig.MEMORY_COLLECTIONS["decision"],
                scroll_filter=scroll_filter,
                limit=20
            )

            # --- YENÄ° MANTIK: KEÅÄ°F BONUSU ---
            if not points:
                # EÄŸer belge hiÃ§ kullanÄ±lmamÄ±ÅŸsa (yeni) ama matematiksel olarak Ã§ok uyumluysa (score > 0.80)
                if vector_score > 0.80:
                    return 1.10  # %10 'HoÅŸgeldin Bonusu'
                return 1.0  # SÄ±radan yeni belge

            # Eski mantÄ±k (GeÃ§miÅŸe dayalÄ± gÃ¼ven)
            match_count = sum(1 for p in points if p.payload.get("decision") == current_decision)
            total = len(points)
            ratio = match_count / total

            if ratio > 0.8: return 1.15  # GÃ¼venilir Eski Belge
            if ratio < 0.2: return 0.85  # HatalÄ± OlduÄŸu Bilinen Belge
            return 1.0
        except:
            return 1.0

    def save_decision(self, query, doc_name, decision, reason, doc_type):
        try:
            text_to_embed = f"{query} {doc_name} {decision} {reason}"
            vector = self.embedder.embed_query(text_to_embed)

            payload = {
                "query": query,
                "source": doc_name,
                "decision": decision,
                "reason": reason,
                "doc_type": doc_type,  # TÃ¼rÃ¼ kaydet (Anti-Bias iÃ§in)
                "timestamp": time.time()
            }

            self.client.upsert(
                collection_name=LegalConfig.MEMORY_COLLECTIONS["decision"],
                points=[PointStruct(id=str(uuid.uuid4()), vector=vector, payload=payload)]
            )

            # Mevzuat deÄŸilse Ã§eliÅŸki analizi yap
            if doc_type != "MEVZUAT":
                self._analyze_contradictions(doc_name, decision, reason)

        except Exception as e:
            print(f"âš ï¸ HafÄ±za hatasÄ±: {e}")

    def _analyze_contradictions(self, source_name, current_decision, current_reason):
        try:
            scroll_filter = Filter(
                must=[FieldCondition(key="source", match=MatchValue(value=source_name))]
            )
            points, _ = self.client.scroll(
                collection_name=LegalConfig.MEMORY_COLLECTIONS["decision"],
                scroll_filter=scroll_filter,
                limit=10
            )

            if len(points) < 2: return

            decisions = set(p.payload.get("decision") for p in points)
            if len(decisions) > 1:
                print(f"   âš¡ Ã‡eliÅŸki Tespit Edildi: {source_name} iÃ§in hem KABUL hem RED var.")

                record1 = next((p.payload for p in points if p.payload["decision"] == "KABUL"), {})
                record2 = next((p.payload for p in points if p.payload["decision"] == "RED"), {})

                prompt = f"""
SEN KIDEMLÄ° BÄ°R YARGITAY RAPORTÃ–RÃœSÃœN.
AÅŸaÄŸÄ±daki aynÄ± belge iÃ§in verilmiÅŸ Ã§eliÅŸkili kararlarÄ± analiz et ve ortak bir ilke Ã§Ä±kar.

KARAR 1 (KABUL): GerekÃ§e: {record1.get('reason', 'Yok')}
KARAR 2 (RED): GerekÃ§e: {record2.get('reason', 'Yok')}

CEVAP:
1. Ã‡eliÅŸki neden kaynaklandÄ±?
2. Bu belge hangi durumda emsal olur?
3. GENEL HUKUK Ä°LKESÄ°NÄ° TEK CÃœMLEYLE YAZ.
"""
                res = self.llm.invoke(prompt).content.strip()
                self._save_principle(res, source=source_name)
        except Exception as e:
            print(f"âš ï¸ Ã‡eliÅŸki analizi hatasÄ±: {e}")

    def consolidate_daily_principles(self):
        """
        GÃ¼nlÃ¼k Konsolidasyon (Mevzuat HariÃ§ - Anti-Bias)
        """
        print("\nğŸ”„ GÃœNLÃœK Ä°LKE KONSOLÄ°DASYONU (Anti-Bias Modu)...")
        try:
            points, _ = self.client.scroll(
                collection_name=LegalConfig.MEMORY_COLLECTIONS["decision"],
                limit=100
            )

            if not points: print("   â„¹ï¸ Yeterli veri yok."); return

            # MevzuatlarÄ± filtreleyerek Ã¶ÄŸren
            sources = [
                p.payload['source']
                for p in points
                if p.payload.get('decision') == 'KABUL'
                   and p.payload.get('doc_type') != 'MEVZUAT'
            ]

            if not sources:
                print("   â„¹ï¸ Ã–ÄŸrenilecek yeni bir iÃ§tihat (Emsal Karar) bulunamadÄ±.")
                return

            source_counts = Counter(sources)

            print("   ğŸ“Š Ä°Ã‡TÄ°HAT RAPORU:")
            for source, count in source_counts.most_common(3):
                if count > 1:
                    print(f"      ğŸ”¹ {source}: {count} kez baÅŸarÄ±lÄ± bulundu.")
                    principle_text = f"Ä°STATÄ°STÄ°K: '{source}' kaynaÄŸÄ±, sistem tarafÄ±ndan {count} kez gÃ¼venilir emsal olarak kabul edilmiÅŸtir."
                    self._save_principle(principle_text, source="Sistem Ä°statistiÄŸi")

            print("âœ… Konsolidasyon tamamlandÄ±.")

        except Exception as e:
            print(f"âš ï¸ Konsolidasyon hatasÄ±: {e}")

    def _save_principle(self, principle_text, source="Genel"):
        try:
            vec = self.embedder.embed_query(principle_text)
            self.client.upsert(
                collection_name=LegalConfig.MEMORY_COLLECTIONS["principle"],
                points=[PointStruct(
                    id=str(uuid.uuid4()),
                    vector=vec,
                    payload={"principle": principle_text, "source": source, "timestamp": time.time()}
                )]
            )
            print("   ğŸ“˜ Yeni Ä°Ã§tihat Ä°lkesi HafÄ±zaya Eklendi.")
        except:
            pass


# ==================================================
# 4ï¸âƒ£ ARAMA MOTORU SINIFI (SEARCH ENGINE)
# ==================================================
class LegalSearchEngine:
    def __init__(self):
        self.config = LegalConfig()
        self.dense_embedder = OllamaEmbeddings(model=self.config.EMBEDDING_MODEL)
        self.client = None
        atexit.register(self.close)

    def connect_db(self):
        if self.client is not None: return True
        print("   ğŸ”Œ VeritabanÄ± baÄŸlantÄ±sÄ± baÅŸlatÄ±lÄ±yor...")
        LegalUtils.force_unlock_db()
        try:
            self.client = QdrantClient(path=self.config.QDRANT_PATH)
            print("   âœ… VeritabanÄ± baÄŸlantÄ±sÄ± BAÅARILI.")
            return True
        except Exception as e:
            print(f"\nâŒ VERÄ°TABANI HATASI: {e}")
            return False

    def close(self):
        if self.client:
            try:
                self.client.close()
                self.client = None
                print("\nğŸ”’ VeritabanÄ± baÄŸlantÄ±sÄ± gÃ¼venli ÅŸekilde kapatÄ±ldÄ±.")
            except:
                pass

    def run_indexing(self):
        if not self.connect_db(): return False

        for key, config in self.config.SOURCES.items():
            collection_name = config["collection"];
            folder_path = config["folder"]
            print(f"   ğŸ‘‰ Koleksiyon kontrol ediliyor: {config['desc']}...")

            if not os.path.exists(folder_path):
                os.makedirs(folder_path);
                print(f"      âš ï¸ KlasÃ¶r oluÅŸturuldu: {folder_path}");
                continue

            if not self.client.collection_exists(collection_name):
                print(f"      âš™ï¸ '{collection_name}' oluÅŸturuluyor...")
                self.client.create_collection(collection_name,
                                              vectors_config=VectorParams(size=768, distance=Distance.COSINE))

            print(f"      ğŸ” Mevcut dosyalar taranÄ±yor...")
            indexed_files = set()
            offset = None
            while True:
                points, offset = self.client.scroll(collection_name, limit=100, with_payload=True, with_vectors=False,
                                                    offset=offset)
                for p in points:
                    if 'source' in p.payload: indexed_files.add(p.payload['source'])
                if offset is None: break

            files_on_disk = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]
            new_files = [f for f in files_on_disk if f not in indexed_files]

            if not new_files: print(f"      âœ… {config['desc']} gÃ¼ncel ({len(files_on_disk)} dosya)."); continue
            print(f"      â™»ï¸ {config['desc']} iÃ§in {len(new_files)} yeni dosya iÅŸleniyor...")

            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            all_texts = [];
            all_metadatas = []

            for filename in new_files:
                try:
                    loader = PyMuPDFLoader(os.path.join(folder_path, filename))
                    docs = loader.load()
                    chunks = text_splitter.split_documents(docs)
                    for c in chunks:
                        clean_content = LegalUtils.clean_text(c.page_content)
                        all_texts.append(clean_content)
                        all_metadatas.append(
                            {"source": filename, "type": config['desc'], "page": c.metadata.get("page", 0) + 1})
                    print(f"      ğŸ“„ Okundu: {filename}")
                except Exception as e:
                    print(f"      âš ï¸ Hata: {filename} - {e}")

            if not all_texts: continue
            print(f"      ğŸš€ VektÃ¶rleÅŸtiriliyor ({len(all_texts)} parÃ§a)...")

            num_cores = cpu_count();
            batch_size = (len(all_texts) // num_cores) + 1;
            batches = []
            for i in range(0, len(all_texts), batch_size): batches.append(
                (all_texts[i:i + batch_size], self.config.EMBEDDING_MODEL))

            all_vectors = []
            try:
                with Pool(processes=num_cores) as pool:
                    results = pool.map(worker_embed_batch_global, batches)
                    for res in results: all_vectors.extend(res)
            except Exception as e:
                print(f"âŒ Ä°ÅŸlemci HatasÄ±: {e}");
                return False

            print(f"      ğŸ’¾ Kaydediliyor...");
            points = []
            for i, (vec, meta, txt) in enumerate(zip(all_vectors, all_metadatas, all_texts)):
                payload = {"page_content": txt, "source": meta["source"], "page": meta["page"], "type": meta["type"]}
                point_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, txt + meta["source"] + collection_name))
                points.append(PointStruct(id=point_id, vector=vec, payload=payload))

            batch_size_upload = 64
            for i in range(0, len(points), batch_size_upload): self.client.upsert(collection_name,
                                                                                  points[i:i + batch_size_upload])

        print("âœ… Ä°ndeksleme TamamlandÄ±.");
        return True

    def retrieve_raw_candidates(self, full_query):
        print("\nğŸ” Belgeler TaranÄ±yor (Dual Search - AÅŸama 1: GeniÅŸ Havuz)...")
        try:
            query_vector = self.dense_embedder.embed_query(full_query)
        except Exception as e:
            print(f"âŒ Embedding HatasÄ±: {e}");
            return []

        all_candidates = []
        for key, config in self.config.SOURCES.items():
            try:
                results = self.client.query_points(collection_name=config["collection"], query=query_vector,
                                                   limit=40).points
                for hit in results:
                    if 'type' not in hit.payload: hit.payload['type'] = config['desc']
                    all_candidates.append(hit)
            except:
                pass

        unique_docs = {}
        for hit in all_candidates:
            if hit.score < self.config.SCORE_THRESHOLD: continue
            key = f"{hit.payload['source']}_{hit.payload['page']}"
            if key not in unique_docs or hit.score > unique_docs[key].score: unique_docs[key] = hit

        candidates = sorted(unique_docs.values(), key=lambda x: x.score, reverse=True)[:self.config.LLM_RERANK_LIMIT]

        if not candidates: print("ğŸ”´ Uygun belge bulunamadÄ±."); return []
        print(f"   âœ… {len(candidates)} potansiyel belge bulundu. YargÄ±ca gÃ¶nderiliyor...")
        return candidates


# ==================================================
# 5ï¸âƒ£ YARGIÃ‡ VE MUHAKEME SINIFI (JUDGE)
# ==================================================
class LegalJudge:
    def __init__(self, memory_manager=None):
        self.llm = ChatOllama(model=LegalConfig.LLM_MODEL, temperature=0.1)
        self.memory = memory_manager

    def validate_user_input(self, story, topic):
        prompt = f"""
GÃ–REV: Metnin tamamen anlamsÄ±z rastgele tuÅŸlama (gibberish) olup olmadÄ±ÄŸÄ±nÄ± tespit et.
METÄ°N: "{story} {topic}"
ANALÄ°Z KURALLARI:
1. "araba", "miras" gibi tek kelimelik girdiler [GEÃ‡ERLÄ°].
2. Sadece "asdasd", "lkgjdf" gibi rastgele tuÅŸlamalar [GEÃ‡ERSÄ°Z].
CEVAP (SADECE BÄ°RÄ°): [GEÃ‡ERLÄ°] veya [GEÃ‡ERSÄ°Z]
"""
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "GEÃ‡ERSÄ°Z" in res: return False
            return True
        except:
            return True

    def generate_expanded_queries(self, story, topic):
        print("   â†³ ğŸ§  Sorgu GeniÅŸletiliyor...")
        try:
            prompt = f"GÃ–REV: Hukuki terimler.\nOLAY: {story}\nODAK: {topic}\n3 kÄ±sa cÃ¼mle."
            res = self.llm.invoke(prompt).content
            return [line.strip() for line in res.splitlines() if len(line) > 5][:3]
        except:
            return [story]

    def _check_relevance_judge_smart(self, user_query, user_filter, negative_keywords, document_text, source_name):
        found_negative = None
        if negative_keywords:
            doc_lower = document_text.lower()
            for bad in negative_keywords:
                if re.search(rf"\b{re.escape(bad)}\b", doc_lower): found_negative = bad; break

        if found_negative:
            prompt = f"HUKUKÃ‡U. Sorgu: '{user_query}'. YasaklÄ±: '{found_negative}'. Uygun mu? [RED]/[KABUL]."
            res = self.llm.invoke(prompt).content.strip()
            if "RED" in res: return False, f"â›” YASAKLI: {res}"

        memory_context = ""
        if self.memory:
            memory_context = self.memory.recall_principles(user_query)

        prompt_gen = f"""
SEN KIDEMLI BIR HUKUKCUSSUN.
{memory_context}

SORGUNUN AMACI: Benzer YargÄ±tay iÃ§tihatlarÄ±nÄ± bulmak.
Sorgu: "{user_query}"
Belge: "{document_text[:700]}..."
SORU: Bu belge; hukuki ilke, yorum yaklaÅŸÄ±mÄ±, miras hukuku mantÄ±ÄŸÄ± bakÄ±mÄ±ndan sorguyla ne derece BENZER?
SADECE BÄ°RÄ°NÄ° SEÃ‡: [Ã‡OK BENZER], [BENZER], [ZAYIF]
AltÄ±na tek cÃ¼mlelik gerekÃ§e yaz.
"""
        res = self.llm.invoke(prompt_gen).content.strip()
        is_ok = ("Ã‡OK BENZER" in res) or ("BENZER" in res)
        return is_ok, res

    def _assign_document_role(self, user_query, document_text):
        prompt = f"""
SEN HUKUKÃ‡USUN.
Sorgu: "{user_query}"
Belge: "{document_text[:800]}..."
GÃ–REV: Bu belge hukuki analizde nasÄ±l kullanÄ±lmalÄ±?
1. [DOÄRUDAN DELÄ°L]: Olay Ã¶rgÃ¼sÃ¼ birebir Ã¶rtÃ¼ÅŸÃ¼yor.
2. [EMSAL Ä°LKE]: Olay farklÄ± ama hukuk kuralÄ± uygulanabilir.
SADECE ÅUNLARDAN BÄ°RÄ°NÄ° SEÃ‡:
[DOÄRUDAN DELÄ°L] veya [EMSAL Ä°LKE]
"""
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "DOÄRUDAN" in res: return "[DOÄRUDAN DELÄ°L]"
            return "[EMSAL Ä°LKE]"
        except:
            return "[EMSAL Ä°LKE]"

    def evaluate_candidates(self, candidates, story, topic, negatives):
        print("\nâš–ï¸  AkÄ±llÄ± YargÄ±Ã§ DeÄŸerlendiriyor (V70: Discovery Engine):")
        valid_docs = []

        for hit in candidates:
            doc_text = hit.payload['page_content']
            source = hit.payload['source']
            page = hit.payload['page']
            type_desc = hit.payload['type']

            is_ok, reason = self._check_relevance_judge_smart(story, topic, negatives, doc_text, source)

            # AÅAMA 4 GÃœNCELLENDÄ°: KeÅŸif Bonusu Matematiksel HesabÄ±
            consensus_multiplier = 1.0
            if self.memory:
                consensus_decision = "KABUL" if is_ok else "RED"
                # hit.score gÃ¶nderiliyor
                consensus_multiplier = self.memory.calculate_memory_consensus(source, consensus_decision, hit.score)

            base_score = min(max(hit.score, 0), 1) * 100
            norm_score = min(base_score * consensus_multiplier, 100.0)

            icon = "âœ…" if is_ok else "âŒ"

            if self.memory:
                decision_tag = "KABUL" if is_ok else "RED"
                self.memory.save_decision(f"{story} {topic}", source, decision_tag, reason, type_desc)

            if is_ok:
                role = self._assign_document_role(story, doc_text)

                log_score = f"%{norm_score:.1f}"
                if consensus_multiplier > 1.1:
                    log_score += " (â¬†ï¸ YÃœKSEK GÃœVEN)"
                elif consensus_multiplier == 1.10:
                    log_score += " (âœ¨ KEÅÄ°F BONUSU)"
                elif consensus_multiplier < 1.0:
                    log_score += " (â¬‡ï¸ RÄ°SKLÄ°)"

                print(f"{icon} [{type_desc}] {source:<20} | GÃ¼ven: {log_score} | Rol: {role}")

                extra_context = ""
                if type_desc == "EMSAL KARAR":
                    real_path = os.path.join(LegalConfig.SOURCES["emsal"]["folder"], source)
                    verdict = LegalUtils.extract_pdf_conclusion(real_path)
                    extra_context = f"\n\nğŸ›‘ [OTOMATÄ°K EKLENEN KARAR SONUCU ({source})]:\n{verdict}\nğŸ›‘ KARAR SONU."

                valid_docs.append({
                    "source": source, "page": page, "type": type_desc, "role": role,
                    "text": doc_text + extra_context, "score": norm_score, "reason": reason
                })
            else:
                print(f"{icon} [{type_desc}] {source:<20} | GÃ¼ven: %{norm_score:.1f}")

        return valid_docs

    def generate_final_opinion(self, story, topic, context_str):
        print("\nğŸ§‘â€âš–ï¸  AVUKAT YAZIYOR (V70: Full Analysis)...")

        system_content = """SEN KIDEMLÄ° BÄ°R HUKUKÃ‡USUN.
GÃ–REVÄ°N: Sana verilen "DELÄ°LLER" listesindeki YargÄ±Ã§ notlarÄ±nÄ± derleyerek nihai raporu yazmak.

KURALLAR:
1. SADECE YargÄ±Ã§'Ä±n "GerekÃ§e" veya "Sebep" olarak yazdÄ±ÄŸÄ± bilgileri temel al.
2. Belgelerin iÃ§indeki konuyla alakasÄ±z (harÃ§ iadesi, usul detaylarÄ± vb.) kÄ±sÄ±mlarÄ± GÃ–RMEZDEN GEL.
3. ASLA aynÄ± bilgiyi tekrar etme.
4. Ã‡Ä±ktÄ±yÄ± tam olarak ÅŸu baÅŸlÄ±klarla ver:

A. MEVZUAT DAYANAKLARI
(Burada sadece MEVZUAT etiketli belgeleri Ã¶zetle)

B. Ä°LGÄ°LÄ° EMSAL KARARLAR
(Burada EMSAL KARAR etiketli belgeleri, YargÄ±Ã§'Ä±n belirlediÄŸi ROL'e gÃ¶re, YargÄ±Ã§ GerekÃ§esi'ni kullanarak anlat)

C. SONUÃ‡ VE HUKUKÄ° TAVSÄ°YE
(KullanÄ±cÄ±nÄ±n olayÄ±na gÃ¶re, bulunan emsallere dayanarak net bir yol haritasÄ± Ã§iz)"""

        user_content = f"""AÅŸaÄŸÄ±daki "DELÄ°LLER" listesinde sunulan belgeleri kullanarak olayÄ± analiz et.
OLAY: "{story}"
ODAK: "{topic}"
DELÄ°LLER:
{context_str}
ANALÄ°ZÄ° BAÅLAT:"""

        messages = [SystemMessage(content=system_content), HumanMessage(content=user_content)]

        full_res = ""
        for chunk in self.llm.stream(messages):
            c = chunk.content;
            full_res += c;
            print(c, end="", flush=True)
        print("\n")
        return full_res


# ==================================================
# 6ï¸âƒ£ RAPORLAMA SINIFI (REPORTER)
# ==================================================
class PDFReportGenerator(FPDF):
    def header(self):
        self.set_font('helvetica', 'B', 15)
        self.cell(0, 10, 'HUKUKI ANALIZ RAPORU', new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='C');
        self.ln(5)

    def footer(self):
        self.set_y(-15);
        self.set_font('helvetica', 'I', 8);
        self.cell(0, 10, f'Sayfa {self.page_no()}', align='C')


class LegalReporter:
    @staticmethod
    def create_report(user_story, valid_docs, advice_text, filename="Hukuki_Rapor_V70.pdf"):
        pdf = PDFReportGenerator();
        pdf.add_page();
        pdf.set_font("helvetica", size=11)

        def clean(t):
            if not t: return ""
            tr = {'ÄŸ': 'g', 'Ã¼': 'u', 'ÅŸ': 's', 'Ä±': 'i', 'Ã¶': 'o', 'Ã§': 'c', 'Ä': 'G', 'Ãœ': 'U', 'Å': 'S', 'Ä°': 'I',
                  'Ã–': 'O', 'Ã‡': 'C'}
            for k, v in tr.items(): t = t.replace(k, v)
            return t.encode('latin-1', 'replace').decode('latin-1')

        pdf.set_font(style='B', size=12);
        pdf.cell(0, 10, clean("1. OLAY:"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font(style='', size=10);
        pdf.multi_cell(w=pdf.epw, h=6, text=clean(user_story));
        pdf.ln(5)

        pdf.set_font(style='B', size=12);
        pdf.cell(0, 10, clean("2. KULLANILAN KAYNAKLAR:"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        for doc in valid_docs:
            pdf.set_font(style='B', size=9)
            source_title = f"[{doc['type']}] {doc['source']} (Sf. {doc['page']})"
            pdf.cell(0, 6, clean(source_title), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            pdf.set_font(style='B', size=8)
            pdf.cell(0, 5, clean(f"   Rol: {doc['role']}"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            pdf.set_font(style='I', size=8);
            pdf.multi_cell(w=pdf.epw, h=4, text=clean(f"   Sebep: {doc['reason']}"));
            pdf.ln(2)

        pdf.add_page();
        pdf.set_font(style='B', size=12);
        pdf.cell(0, 10, clean("3. HUKUKI GORUS:"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font(style='', size=10);
        pdf.multi_cell(w=pdf.epw, h=6, text=clean(advice_text))
        try:
            pdf.output(filename);
            print(f"\nğŸ“„ Rapor HazÄ±r: {filename}")
        except:
            pass


# ==================================================
# 7ï¸âƒ£ ANA UYGULAMA (MAIN APP)
# ==================================================
class LegalApp:
    def __init__(self):
        print("ğŸš€ LEGAL SUITE V70 (Discovery Engine: Opportunity for New Docs)...")
        self.search_engine = LegalSearchEngine()

        if self.search_engine.connect_db():
            self.memory_manager = LegalMemoryManager(
                self.search_engine.client,
                self.search_engine.dense_embedder,
                ChatOllama(model=LegalConfig.LLM_MODEL, temperature=0.1)
            )
        else:
            self.memory_manager = None

        self.judge = LegalJudge(memory_manager=self.memory_manager)
        self.reporter = LegalReporter()

    def run(self):
        if not self.search_engine.run_indexing():
            self.search_engine.close()
            sys.exit()

        if self.memory_manager:
            self.memory_manager.consolidate_daily_principles()

        print("\nâœ… SÄ°STEM HAZIR. (Ã‡Ä±kÄ±ÅŸ: 'q')")

        try:
            while True:
                print("-" * 60)
                story = input("ğŸ“ Olay: ");
                if story == 'q': break
                topic = input("ğŸ¯ Odak: ")
                neg_input = input("ğŸš« YasaklÄ±: ")
                negatives = [w.strip().lower() for w in neg_input.split(",")] if neg_input else []

                print("   ğŸ›¡ï¸ Girdi kontrol ediliyor...")
                if not self.judge.validate_user_input(story, topic):
                    print("   âŒ UYARI: Girdi anlamsÄ±z. LÃ¼tfen mantÄ±klÄ± bir olay giriniz.")
                    continue

                expanded = self.judge.generate_expanded_queries(story, topic)
                full_query = f"{story} {topic} " + " ".join(expanded)
                print(f"   âœ“ Sorgu: {len(full_query)} karakter")

                candidates = self.search_engine.retrieve_raw_candidates(full_query)
                if not candidates: continue

                valid_docs = self.judge.evaluate_candidates(candidates, story, topic, negatives)
                if not valid_docs: print("ğŸ”´ YargÄ±Ã§ hepsini eledi."); continue

                context_str = ""
                for i, d in enumerate(valid_docs):
                    context_str += f"""
                        BELGE #{i + 1}
                        KAYNAK: {d['source']}
                        TÃœR: {d['type']}
                        ROL: {d['role']}
                        YARGIÃ‡ GEREKÃ‡ESÄ°: {d['reason']}
                        Ä°Ã‡ERÄ°K Ã–ZETÄ°: {d['text'][:800]}...
                        =========================================
                        """
                print("\n" + "=" * 30)
                print("### Kaynaklar ve Sebebi")
                print("=" * 30)
                for d in valid_docs:
                    print(f"â€¢ [{d['type']}] {d['source']} (Sf. {d['page']}) | Skor: %{d['score']:.1f}")
                    print(f"  Rol:   {d['role']}")
                    print(f"  Sebep: {d['reason']}")
                    print("-" * 40)

                full_advice = self.judge.generate_final_opinion(story, topic, context_str)
                self.reporter.create_report(story, valid_docs, full_advice)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Program durduruldu.")
        except Exception as e:
            print(f"\nâš ï¸ Hata: {e}")
        finally:
            self.search_engine.close()


if __name__ == "__main__":
    freeze_support()
    app = LegalApp()
    app.run()