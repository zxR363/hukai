import sys
import os
import re
import uuid
import time
import shutil
import atexit
import json
import random
import math
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime
from multiprocessing import Pool, cpu_count, freeze_support
from dataclasses import dataclass, field
from collections import Counter

# --------------------------------------------------
# üì¶ IMPORTLAR
# --------------------------------------------------
import fitz  # PyMuPDF
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_core.messages import SystemMessage, HumanMessage
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance, Filter, FieldCondition, MatchValue, Range
from fpdf import FPDF
from fpdf.enums import XPos, YPos
from langchain_community.document_loaders import PyMuPDFLoader


# PDF CIKTILARI Mevcut importlarƒ±n altƒ±na ekleyin
from pdf_reports import (
    LegacyPDFReport,
    JudicialPDFReport,
    ClientSummaryPDF,  # Eƒüer kullanacaksanƒ±z
    ReportOrchestrator
)


# UTF-8 Ayarƒ±
# sys.stdout.reconfigure(encoding="utf-8")


# ==================================================
# 1Ô∏è‚É£ KONFƒ∞G√úRASYON VE BAƒûLAM SINIFLARI
# ==================================================

# üî® Commit 5.3: Query Context (Single Source of Truth)
@dataclass
class QueryContext:
    """
    Sistemde TEK baƒülayƒ±cƒ± baƒülam nesnesi.
    T√ºm mod√ºller yalnƒ±zca bunu referans alƒ±r.
    """
    # Kullanƒ±cƒ± girdisi
    query_text: str

    # Hukuki baƒülam
    topic: str
    detected_domain: str  # √∂rn: "miras", "icra", "ceza"

    # Kapsam sƒ±nƒ±rlarƒ±
    negative_scope: List[str]
    allowed_sources: List[str] = None

    # Sistem i√ßi bayraklar
    allow_analogy: bool = False
    allow_speculation: bool = False
    allow_soft_language: bool = False

    # üÜï EKLENECEK SATIR (Guard Bayraƒüƒ±)
    judge_evaluated: bool = False

    def assert_hard_limits(self):
        """
        Hukuki g√ºvenlik kemeri.
        """
        if self.allow_speculation:
            raise ValueError("Speculation is forbidden in legal analysis.")

        if self.allow_analogy:
            raise ValueError("Analogy is forbidden unless explicitly enabled.")


# üî® Commit 5.4: Decision Context (Yargƒ±sal Zemin)
@dataclass
class DecisionContext:
    """
    Hakim ve LLM i√ßin ortak, temiz ve s√ºz√ºlm√º≈ü karar zemini.
    Bu nesne olu≈ümadan LLM √áAƒûRILAMAZ.
    """

    # Kaynaklar
    documents: List[Dict[str, Any]] = field(default_factory=list)
    principles: List[Dict[str, Any]] = field(default_factory=list)

    # Analitik katman
    relevance_scores: Dict[str, float] = field(default_factory=dict)
    conflicts: List[str] = field(default_factory=list)

    def has_minimum_legal_basis(self) -> bool:
        """
        Hukuki tartƒ±≈üma yapƒ±labilmesi i√ßin asgari e≈üik.
        """
        return bool(self.documents) or bool(self.principles)


# üî® Commit 5.5: Judge Reflex (Refleks Veri Yapƒ±sƒ±)
@dataclass
class JudgeReflex:
    """
    Hakimin ilk refleksi.
    """
    tendency: str  # "KABUL" | "RED" | "TEREDD√úT"
    score: int  # 0‚Äì100
    doubts: List[str]  # Hakimin kafasƒ±na takƒ±lanlar


# üî® Commit 5.6: Persona Response (Persona √áƒ±ktƒ± Modeli)
@dataclass
class PersonaResponse:
    role: str  # DAVACI | DAVALI | BILIRKISI
    response: str
    addressed_doubts: List[str]


# üî® Commit 5.7: Strengthening Action (Aksiyon Modeli)
@dataclass
class StrengtheningAction:
    title: str
    description: str
    related_doubt: str
    impact_score: int  # 1‚Äì10 arasƒ± katkƒ± puanƒ±


@dataclass
class LegalConfig:
    # Google Drive Ana Yolu (HukAI Klas√∂r√º)
    # DRIVE_ROOT = "/content/drive/MyDrive/HukAI"
    DRIVE_ROOT = os.path.dirname(os.path.abspath(__file__))

    SOURCES = {
        "mevzuat": {
            "folder": os.path.join(DRIVE_ROOT, "mevzuatlar"),
            "collection": "legal_statutes_v48",
            "desc": "MEVZUAT"
        },
        "emsal": {
            "folder": os.path.join(DRIVE_ROOT, "belgeler"),
            "collection": "legal_precedents_v48",
            "desc": "EMSAL KARAR"
        }
    }

    MEMORY_COLLECTIONS = {
        "decision": "judge_memory_v1",
        "principle": "principle_memory_v1"
    }

    # Veritabanƒ±nƒ± da HukAI i√ßine kaydediyoruz (Kalƒ±cƒ± Hafƒ±za)
    QDRANT_PATH = os.path.join(DRIVE_ROOT, "qdrant_db_master")

    # Sistem durum dosyasƒ± da burada
    STATE_FILE = os.path.join(DRIVE_ROOT, "system_state.json")

    EMBEDDING_MODEL = "nomic-embed-text"
    LLM_MODEL = "qwen2.5"

    # V120: YENƒ∞ LLM PARAMETRELERƒ∞ (GLOBAL KALƒ∞TE KONTROL)
    LLM_CONFIG = {
        "temperature": 0.4,
        "top_p": 0.9,
        "repeat_penalty": 1.2,  # frequency_penalty kar≈üƒ±lƒ±ƒüƒ± (Ollama/Llama)
        "num_predict": 1200  # max_tokens kar≈üƒ±lƒ±ƒüƒ±
    }

    # V124: G√ú√áLENDƒ∞Rƒ∞LMƒ∞≈û PROMPT GUARD
    PROMPT_GUARD = """
ZORUNLU YAZIM VE AKIL Y√úR√úTME KURALLARI:

1. SADECE verilen olay, scope ve hukuki baƒülam i√ßinde kal.
2. Genel hukuk bilgisi, √∂ƒüretici anlatƒ±m veya akademik a√ßƒ±klama YAPMA.
3. ‚ÄúGenel olarak‚Äù, ‚Äú√ßoƒüunlukla‚Äù, ‚Äúdoktrinde‚Äù gibi belirsiz ifadeler KULLANMA.
4. Aynƒ± hukuki ilkeyi veya TMK/Yargƒ±tay maddesini Bƒ∞R KEZ a√ßƒ±kla.
5. Aynƒ± d√º≈ü√ºnceyi farklƒ± kelimelerle TEKRAR ETME.
6. Somut olayla baƒülantƒ±sƒ± olmayan hi√ßbir bilgi EKLEME.
7. Emsal yoksa uydurma; belirsizlik varsa A√áIK√áA belirt.
8. Deƒüer yargƒ±sƒ±, ahlaki yorum, sosyal politika yorumu YAPMA.
9. ‚ÄúBu durumda karar verilmelidir‚Äù gibi H√úK√úM KURAN ifadeler kullanma.
10. Hakim, avukat veya bilirki≈üi rol√º dƒ±≈üƒ±nda d√º≈ü√ºnme.
11. √áƒ±ktƒ±, ger√ßek bir mahkeme dosyasƒ±na girebilecek ciddiyette olsun.
12. Bu kurallarƒ±n dƒ±≈üƒ±na √ßƒ±kma; √ßƒ±ktƒ±yƒ± bu kurallara g√∂re DENETLE.
13.Her belge yalnƒ±zca bir kez √∂zetlenir.√ñzet, sorgudaki somut olayla doƒürudan baƒü kurmak zorundadƒ±r.
"Bu belge, sorgudaki [X] durumuna ≈üu ≈üekilde uygulanƒ±r: ..." formatƒ± zorunludur.
14.Belge ‚Üí Hukuki ƒ∞lke ‚Üí Somut Olay ‚Üí Dosyaya Etki zinciri kurulmadan belge kullanƒ±lamaz.
15. Subjektif kelimeler ("benzetebilirsiniz", "olabilir", "gibi") KULLANMA; her atƒ±f SOMUT olsun ("Yargƒ±tay 14. HD 2015/2278 E. kararƒ±nda ≈ü√∂yle belirtilmi≈ütir: ...").
"""

    # --- V120: CORE RULE REGISTRY (YAML SIMULATION) ---
    # Harici dosya okuma mantƒ±ƒüƒ± eklendiƒüinde burasƒ± fallback olur.
    CORE_RULES_DB = {
        "miras_hukuku": {
            "description": "Miras ve √ßeki≈ümesiz yargƒ± i≈üleri",
            "rules": [
                {
                    "id": "CR_MIRAS_001",
                    "rule": "Veraset ilamƒ± √ßeki≈ümesiz yargƒ± i≈üidir.",
                    "effect": "Maddi anlamda kesin h√ºk√ºm olu≈üturmaz.",
                    "applies_to": ["judge", "risk", "persona"]
                },
                {
                    "id": "CR_MIRAS_002",
                    "rule": "Miras√ßƒ±lƒ±k belgesi aksi ispat edilinceye kadar ge√ßerlidir.",
                    "effect": "ƒ∞ptal davasƒ± a√ßƒ±labilir.",
                    "applies_to": ["judge"]
                }
            ]
        },
        "ceza_hukuku": {
            "description": "Ceza yargƒ±lamasƒ±na ili≈ükin temel ilkeler",
            "rules": [
                {
                    "id": "CR_CEZA_001",
                    "rule": "≈û√ºpheden sanƒ±k yararlanƒ±r (In Dubio Pro Reo).",
                    "effect": "Delil yetersizliƒüi halinde beraat esastƒ±r.",
                    "applies_to": ["judge", "risk"]
                },
                {
                    "id": "CR_CEZA_002",
                    "rule": "Ceza hukukunda kƒ±yas yasaƒüƒ± esastƒ±r.",
                    "effect": "Kanunsuz su√ß ve ceza olmaz, aleyhe yorum yapƒ±lamaz.",
                    "applies_to": ["judge"]
                }
            ]
        },
        "is_hukuku": {
            "description": "ƒ∞≈ü hukuku ve i≈ü√ßi-i≈üveren ili≈ükileri",
            "rules": [
                {
                    "id": "CR_IS_001",
                    "rule": "ƒ∞≈ü hukukunda i≈ü√ßi lehine yorum ilkesi esastƒ±r.",
                    "effect": "Mevzuat bo≈üluklarƒ±nda i≈ü√ßi yararƒ± g√∂zetilir.",
                    "applies_to": ["judge", "persona"]
                }
            ]
        },
        "genel_hukuk": {
            "description": "Genel hukuk ilkeleri",
            "rules": [
                {
                    "id": "CR_GENEL_001",
                    "rule": "ƒ∞ddia eden iddiasƒ±nƒ± ispatla m√ºkelleftir.",
                    "effect": "ƒ∞spat y√ºk√º kural olarak davacƒ±dadƒ±r.",
                    "applies_to": ["judge", "risk"]
                }
            ]
        }
    }

    SEARCH_LIMIT_PER_SOURCE = 60
    SCORE_THRESHOLD = 0.35
    LLM_RERANK_LIMIT = 10

    DECAY_RATE_PER_MONTH = 0.98
    PRINCIPLE_MERGE_THRESHOLD = 0.90
    MIN_CONFIDENCE_THRESHOLD = 0.55


# ==================================================
# 2Ô∏è‚É£ YARDIMCI ARA√áLAR (STATIC)
# ==================================================
def _contains_decision(text: str, decision: str) -> bool:
    text = text.upper()
    decision = decision.upper()

    if decision == "KABUL":
        return "KABUL" in text or "KABUL EDƒ∞L" in text
    if decision == "RED":
        return "RED" in text or "REDDEDƒ∞L" in text
    return False

def worker_embed_batch_global(args):
    """Multiprocessing i√ßin global kalmalƒ±."""
    texts, model_name = args
    try:
        embedder = OllamaEmbeddings(model=model_name)
        return embedder.embed_documents(texts)
    except Exception as e:
        print(f"‚ö†Ô∏è Batch hatasƒ± (atlanƒ±yor): {e}")
        return []


# üî® Commit 5.4: Decision Builder (Adapt√∂r)
class DecisionBuilder:
    """
    Sistemin farklƒ± √ßƒ±ktƒ±larƒ±ndan DecisionContext in≈üa eden yardƒ±mcƒ± sƒ±nƒ±f.
    """

    @staticmethod
    def build_decision_context_from_valid_docs(valid_docs: list) -> DecisionContext:
        """
        LegalJudge tarafƒ±ndan filtrelenmi≈ü 'valid_docs' listesini alƒ±r.
        """
        context = DecisionContext()

        for doc in valid_docs:
            # ID yoksa ge√ßici √ºret, varsa kullan
            doc_id = str(uuid.uuid4())

            context.documents.append({
                "id": doc_id,
                "type": doc.get("type"),  # EMSAL / MEVZUAT
                "source": doc.get("source"),
                "confidence": doc.get("score"),  # Judge skoru (0-100)
                "content": doc.get("text"),
                "role": doc.get("role"),
                "reason": doc.get("reason")
            })

            context.relevance_scores[doc_id] = doc.get("score", 0.0)

        return context

    @staticmethod
    def enrich_decision_context_with_memory(context: DecisionContext, memory_principles: list) -> DecisionContext:
        """
        Hafƒ±zadan gelen ilkeleri Context'e ekler.
        """
        if not memory_principles:
            return context

        for principle in memory_principles:
            context.principles.append({
                "principle": principle.get("text"),
                "confidence": principle.get("score_data", {}).get("success_probability", 0),
                "source": "memory_v1",
                "trend": principle.get("trend_log", "")
            })

        return context


# üî® Commit 5.5: Judge Core (Deterministik Akƒ±l)
class JudgeCore:
    """
    LLM'siz, deterministik hakim muhakemesi.
    """

    def evaluate(self, decision_context: DecisionContext) -> JudgeReflex:
        score = 0
        doubts = []

        # 1Ô∏è‚É£ Belgelerden gelen g√º√ß
        for doc in decision_context.documents:
            # Skorlar 0-100 arasƒ±nda geliyordu, burada normalize edip topluyoruz
            conf = doc.get("confidence", 0)
            if conf >= 90:
                score += 15
            elif conf >= 80:
                score += 10
            elif conf >= 70:
                score += 5
            else:
                doubts.append(
                    f"D√º≈ü√ºk g√ºvenli belge: {doc.get('source')}"
                )

        # 2Ô∏è‚É£ Hukuki ilkeler
        for principle in decision_context.principles:
            conf = principle.get("confidence", 0)  # 0-100 arasƒ± success probability
            if conf >= 85:
                score += 10
            elif conf < 60:
                doubts.append(
                    "Zayƒ±f i√ßtihat/ilke tespiti"
                )

        # 3Ô∏è‚É£ Skoru sƒ±nƒ±rla
        score = min(score, 100)

        # 4Ô∏è‚É£ Hakim refleksi
        if score >= 70:
            tendency = "KABUL"
        elif score <= 40:
            tendency = "RED"
        else:
            tendency = "TEREDD√úT"

        return JudgeReflex(
            tendency=tendency,
            score=score,
            doubts=doubts
        )


# ==================================================
# [YENƒ∞] üß† LEGAL DECISION LOGIC (KARAR MANTIK MOTORU)
# ==================================================
class LegalDecisionLogic:
    """
    LLM √ßƒ±ktƒ±larƒ±nƒ± matematiksel kurallarla denetler ve
    nihai kararƒ± (Refleks) yeniden hesaplar.
    """

    # ADIM 1: Teredd√ºt Anahtar Kelimeleri
    TEREDDUT_KEYWORDS = [
        "teredd√ºt", "eksik", "yetersiz",
        "belirsiz", "dikkat", "potansiyel", "≈ü√ºphe",
        "√ßeli≈üki", "muƒülak"
    ]

    # ADIM 4: Bilirki≈üi Netlik Kelimeleri
    NETLIK_KELIMELERI = ["kanaat", "sonu√ß", "tespit edilmi≈ütir", "m√ºtalaa", "g√∂r√º≈ü","a√ßƒ±k√ßa",
                         "kesin olarak", "g√∂r√º≈ü√ºndeyim", "neticesinde"]

    # ADIM 7: Hukuki Terminoloji Zorunluluƒüu
    REQUIRED_LEGAL_TERMS = ["TBK", "TMK", "ispat", "delil", "h√ºk√ºm", "yargƒ±tay"]

    def detect_tereddut(self, text: str) -> bool:
        text = text.lower()
        return any(k in text for k in self.TEREDDUT_KEYWORDS)

    def count_tereddut_sources(self, bilirkisi_text, davali_text, delil_durumu_metni=""):
        count = 0
        if self.detect_tereddut(bilirkisi_text): count += 1
        if self.detect_tereddut(davali_text): count += 1
        # Delil durumu metni opsiyonel, genelde analizden gelir
        if "belirsiz" in delil_durumu_metni.lower() or "eksik" in delil_durumu_metni.lower():
            count += 1
        return count

    def bilirkisi_net_mi(self, text):
        return any(k in text.lower() for k in self.NETLIK_KELIMELERI)

    def davali_gucu_hesapla(self, text):
        score = 0
        text = text.lower()
        if "delil" in text and "eksik" in text: score += 4
        if "yargƒ±tay" in text or "emsal" in text: score += 3
        if "belge" in text and "yok" in text: score += 2
        # Maksimum 10 √ºzerinden normalize edelim
        return min(score, 10)

    def hukuki_tavsif_gecerli_mi(self, text):
        return any(r in text for r in self.REQUIRED_LEGAL_TERMS)

    def calculate_final_score(self, base_score, davali_gucu, tereddut_sayisi, bilirkisi_net):
        # ADIM 6: Genel G√º√ß Skoru Normalizasyonu
        # Base score JudgeCore'dan gelir (√ñrn: 80)
        score = base_score

        # Teredd√ºt cezasƒ±
        score -= tereddut_sayisi * 15  # Teredd√ºt ba≈üƒ±na 15 puan kƒ±r (Sƒ±kƒ±la≈ütƒ±rdƒ±m)

        # Davalƒ± g√ºc√º cezasƒ±
        score -= davali_gucu * 2

        # Bilirki≈üi vetosu
        if not bilirkisi_net:
            score -= 20

        return max(0, min(score, 100))

    def decide_verdict(self, bilirkisi_net, tereddut_sayisi, davali_gucu, final_score):
        # ADIM 3: Hakim Refleksi Decision Tree

        # 1. Kilit: Bilirki≈üi net deƒüilse direkt Teredd√ºt
        if not bilirkisi_net:
            return "TEREDD√úTL√ú ‚Äì Bƒ∞Lƒ∞RKƒ∞≈ûƒ∞ MUƒûLAK"

        # 2. Kilit: Teredd√ºt sayƒ±sƒ± 1'den fazlaysa
        if tereddut_sayisi >= 1:
            return f"TEREDD√úTL√ú ‚Äì {tereddut_sayisi} KAYNAK ≈û√úPHELƒ∞"

        # 3. Kilit: Davalƒ± √ßok g√º√ßl√ºyse
        if davali_gucu >= 7:
            return "TEREDD√úTL√ú ‚Äì DAVALI SAVUNMASI G√ú√áL√ú"

        # 4. Kilit: Skor yeterliliƒüi
        if final_score >= 75:
            return "KABUL Eƒûƒ∞Lƒ∞MLƒ∞"

        return "RED Eƒûƒ∞Lƒ∞MLƒ∞"

    def final_sanity_check(self, refleks, skor, tereddut_sayisi):
        # ADIM 8: Son G√ºvenlik Kilidi
        is_kabul = "KABUL" in refleks.upper()

        if is_kabul and (tereddut_sayisi > 0 or skor < 75):
            print(f"üö® SANITY CHECK FAILED: Refleks={refleks}, Skor={skor}, Teredd√ºt={tereddut_sayisi}")
            # Zorla d√ºzelt
            return "TEREDD√úTL√ú (OTOMATƒ∞K D√úZELTME)", skor

        return refleks, skor

    def run_logic(self, initial_reflex, persona_outputs):
        """
        T√ºm mantƒ±ƒüƒ± √ßalƒ±≈ütƒ±rƒ±r ve g√ºncellenmi≈ü bir JudgeReflex nesnesi d√∂ner.
        """
        if initial_reflex.score > 85 and initial_reflex.doubts:
            initial_reflex.score = min(initial_reflex.score, 75)

        # Metinleri ayƒ±kla
        davaci_text = next((p.response for p in persona_outputs if "DAVACI" in p.role), "")
        davali_text = next((p.response for p in persona_outputs if "DAVALI" in p.role), "")
        bilirkisi_text = next((p.response for p in persona_outputs if "Bƒ∞Lƒ∞RKƒ∞≈ûƒ∞" in p.role), "")

        # Analizler
        bilirkisi_net = self.bilirkisi_net_mi(bilirkisi_text)
        davali_gucu = self.davali_gucu_hesapla(davali_text)
        tereddut_sayisi = self.count_tereddut_sources(bilirkisi_text, davali_text,
                                                      initial_reflex.doubts[0] if initial_reflex.doubts else "")

        # Skorlama
        # Ba≈ülangƒ±√ß skorunu JudgeCore'dan alƒ±yoruz
        final_score = self.calculate_final_score(initial_reflex.score, davali_gucu, tereddut_sayisi, bilirkisi_net)

        # Karar Aƒüacƒ±
        new_tendency = self.decide_verdict(bilirkisi_net, tereddut_sayisi, davali_gucu, final_score)

        # Sanity Check
        checked_tendency, checked_score = self.final_sanity_check(new_tendency, final_score, tereddut_sayisi)

        # G√ºncellenmi≈ü Teredd√ºt Listesi
        new_doubts = initial_reflex.doubts
        if tereddut_sayisi > 0 and not new_doubts:
            new_doubts = ["Otomatik tespit: Metinlerde belirsizlik/teredd√ºt ifadeleri mevcut."]

        print(f"\nüß† MANTIK MOTORU DEVREDE:")
        print(f"   - Teredd√ºt Sayƒ±sƒ±: {tereddut_sayisi}")
        print(f"   - Davalƒ± G√ºc√º: {davali_gucu}")
        print(f"   - Bilirki≈üi Net mi?: {bilirkisi_net}")
        print(f"   - Eski Skor: {initial_reflex.score} -> Yeni Skor: {checked_score}")
        print(f"   - Eski Karar: {initial_reflex.tendency} -> Yeni Karar: {checked_tendency}")

        return JudgeReflex(
            tendency=checked_tendency,
            score=int(checked_score),
            doubts=new_doubts
        )


# üî® Commit 5.6: Persona Engine (Kontroll√º LLM)
class PersonaEngine:
    """
    LLM kontroll√º persona sim√ºlasyonu.
    Hakimin teredd√ºtlerine cevap √ºretir.
    """

    def __init__(self, llm):
        self.llm = llm
        self.current_doubts = []

    def run(
            self,
            context: QueryContext,
            decision_context: DecisionContext,
            judge_reflex: JudgeReflex
    ) -> List[PersonaResponse]:

        self.current_doubts = judge_reflex.doubts
        if not self.current_doubts:
            # Teredd√ºt yoksa standart bir ba≈ülangƒ±√ß ata
            self.current_doubts = ["Dosyanƒ±n esasƒ±na ili≈ükin genel delil durumu", "Hukuki tavsif"]

        print(f"   üó£Ô∏è  Persona Tartƒ±≈ümasƒ± Ba≈ülatƒ±lƒ±yor ({len(self.current_doubts)} Teredd√ºt)...")
        responses = []

        responses.append(
            self._invoke_persona(
                role="DAVACI VEKƒ∞Lƒ∞",
                instruction="Hakimin teredd√ºtlerini gider, davanƒ±n kabul√º i√ßin arg√ºman √ºret."
            )
        )

        responses.append(
            self._invoke_persona(
                role="DAVALI VEKƒ∞Lƒ∞",
                instruction="Hakimin teredd√ºtlerini derinle≈ütir, davanƒ±n reddi i√ßin itiraz et."
            )
        )

        responses.append(
            self._invoke_persona(
                role="Bƒ∞Lƒ∞RKƒ∞≈ûƒ∞",
                instruction="Teredd√ºtlerin hukuki tutarlƒ±lƒ±ƒüƒ±nƒ± ve delil zincirini denetle."
            )
        )

        return responses

    def _invoke_persona(self, role: str, instruction: str) -> PersonaResponse:
        prompt = f"""
        ROL: {role}
        BAƒûLAM: T√ºrk Hukuku.
        {LegalConfig.PROMPT_GUARD}

        G√ñREV:
        {instruction}

        HAKƒ∞Mƒ∞N SOMUT TEREDD√úTLERƒ∞:
        {self._format_doubts()}

        SINIRLAR:
        - Yeni hukuki kural √ºretme.
        - Hakim kararƒ±nƒ± deƒüi≈ütirmeye √ßalƒ±≈üma (Sadece ikna et/ele≈ütir).
        - Skor veya oran verme.
        - Sadece yukarƒ±daki teredd√ºtlere odaklan.

        √áIKTI:
        - Net, hukuki dilde, maksimum 2 paragraf.
        """

        try:
            result = self.llm.invoke(prompt).content.strip()
        except:
            result = f"{role}: Beyan olu≈üturulamadƒ±."

        return PersonaResponse(
            role=role,
            response=result,
            addressed_doubts=self.current_doubts
        )

    def _format_doubts(self):
        return "\n".join(f"- {d}" for d in self.current_doubts)


# üî® Commit 5.7: Action Engine
class ActionEngine:
    """
    Hakim teredd√ºtlerini azaltmaya y√∂nelik
    somut hukuki aksiyonlar √ºretir.
    """

    def __init__(self, llm):
        self.llm = llm

    def run(
            self,
            judge_reflex: JudgeReflex,
            persona_outputs: List[PersonaResponse]
    ) -> List[StrengtheningAction]:

        if not judge_reflex.doubts:
            return []

        actions = []

        for doubt in judge_reflex.doubts:
            action = self._generate_action(doubt, persona_outputs)
            if action:
                actions.append(action)

        return actions

    def _generate_action(
            self,
            doubt: str,
            persona_outputs: List[PersonaResponse]
    ) -> StrengtheningAction:

        persona_context = "\n\n".join(
            f"{p.role}: {p.response}"
            for p in persona_outputs
            # Eƒüer persona cevabƒ±nda bu doubt ge√ßiyorsa al, yoksa hepsini al (basit e≈üle≈üme)
            if True
        )

        prompt = f"""
        HAKƒ∞M TEREDD√úD√ú:
        {doubt}

        PERSONA DEƒûERLENDƒ∞RMELERƒ∞:
        {persona_context}

        G√ñREV:
        Bu teredd√ºd√º azaltmak i√ßin yapƒ±labilecek
        TEK ve SOMUT hukuki aksiyonu yaz.

        SINIRLAR:
        - Tavsiye tonu kullanma
        - Genel laf √ºretme
        - En fazla 3 c√ºmle

        FORMAT:
        Ba≈ülƒ±k:
        A√ßƒ±klama:
        Etki Puanƒ± (1-10):
        """

        try:
            result = self.llm.invoke(prompt).content
            return self._parse_action(result, doubt)
        except:
            return None

    def _parse_action(self, text: str, doubt: str) -> StrengtheningAction:
        lines = text.splitlines()

        title = "Ek Delil Sunumu"
        description = "ƒ∞lgili hususta ek delil sunulmalƒ±dƒ±r."
        impact = 5

        for line in lines:
            if "Ba≈ülƒ±k" in line:
                parts = line.split(":", 1)
                if len(parts) > 1: title = parts[1].strip()
            elif "A√ßƒ±klama" in line:
                parts = line.split(":", 1)
                if len(parts) > 1: description = parts[1].strip()
            elif "Etki" in line:
                try:
                    # Sadece rakamlarƒ± al
                    impact = int("".join(filter(str.isdigit, line)))
                    # 10'dan b√ºy√ºkse (√∂rn 810) son basamaƒüƒ± al veya 10 yap
                    if impact > 10: impact = 5
                except:
                    impact = 5

        return StrengtheningAction(
            title=title,
            description=description,
            related_doubt=doubt,
            impact_score=impact
        )


class LegalUtils:
    @staticmethod
    def force_unlock_db():
        lock_file = os.path.join(LegalConfig.QDRANT_PATH, ".lock")
        if os.path.exists(lock_file):
            try:
                os.remove(lock_file);
                print("üîì Kƒ∞Lƒ∞T DOSYASI TEMƒ∞ZLENDƒ∞.")
            except:
                pass

    @staticmethod
    def extract_pdf_conclusion(file_path, char_limit=2500):
        try:
            if not os.path.exists(file_path): return "[Dosya bulunamadƒ±.]"
            doc = fitz.open(file_path)
            total_pages = len(doc)
            text = "";
            start_page = max(0, total_pages - 2)
            for i in range(start_page, total_pages): text += doc[i].get_text()
            doc.close();
            return text[-char_limit:]
        except Exception as e:
            return f"[Karar okunamadƒ±: {e}]"

    @staticmethod
    def clean_text(text):
        text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text


# --- V121: ADVANCED LOOP BREAKER ---
class LegalTextSanitizer:
    """V121: Geli≈ümi≈ü Tekrar Engelleyici (Madde Bazlƒ±)"""

    def __init__(self):
        self.seen_sentences = set()
        self.written_articles = set()  # YENƒ∞: Madde numaralarƒ±nƒ± takip et
        self.dropped_count = 0

    def enforce_no_repeat(self, text):
        PROTECTED_PREFIXES = (
            "‚ö†Ô∏è",
            "A.",
            "B.",
            "C.",
            "------------------------------------------------",
        )

        """Metindeki anlamsal tekrarlarƒ± ve aynƒ± kanun maddelerini temizler."""
        if not text: return ""

        lines = text.split("\n")
        cleaned_lines = []

        for line in lines:
            # 1. √ñNCE deƒüi≈ükeni tanƒ±mla
            clean_line = line.strip()

            # 2. SONRA kontrol et
            if clean_line.startswith(PROTECTED_PREFIXES):
                cleaned_lines.append(line)
                continue

            if len(clean_line) < 5:  # √áok kƒ±sa satƒ±rlarƒ± (bo≈üluk vb.) ge√ß
                cleaned_lines.append(line)
                continue

            # --- V121 G√úNCELLEME: Madde Numarasƒ± Kontrol√º ---
            article_match = re.search(
                r'(?:(TMK|HMK|BK|TBK|CMK)\s*)?(?:Madde|Md\.|m\.)\s*(\d+)',
                clean_line,
                re.IGNORECASE
            )
            if article_match:
                article_num = article_match.group(1)  # Sadece numarayƒ± al (√∂rn: "598")
                if article_num in self.written_articles:
                    self.dropped_count += 1
                    continue  # Aynƒ± madde numarasƒ± daha √∂nce yazƒ±ldƒ±ysa atla
                self.written_articles.add(article_num)
            # ------------------------------------------------

            # C√ºmlenin "√∂z√ºn√º" (ilk 80 karakter) anahtar yap
            # Bu sayede "Miras√ßƒ±lƒ±k belgesi..." ile "Miras√ßƒ±lƒ±k belgesinin..." aynƒ± sayƒ±lƒ±r
            key = re.sub(r'\s+', ' ', clean_line.lower())
            key = re.sub(r'[^\w\s]', '', key)[:80]

            if key in self.seen_sentences:
                self.dropped_count += 1
                continue  # BU SATIRI ATLA (TEKRAR)

            self.seen_sentences.add(key)
            cleaned_lines.append(line)

        return "\n".join(cleaned_lines)

    def reset(self):
        self.seen_sentences = set()
        self.written_articles = set()  # Reset i≈üleminde burayƒ± da temizle
        self.dropped_count = 0


# ==================================================
# 3Ô∏è‚É£ LEGAL AUDIT LOGGER
# ==================================================
class LegalAuditLogger:
    """
    Sistemin verdiƒüi t√ºm kararlarƒ±n izlenebilir, a√ßƒ±klanabilir ve UI-uyumlu log kaydƒ±.
    """

    def __init__(self, case_id: str | None = None):
        self.case_id = case_id or str(uuid.uuid4())
        self.started_at = time.time()
        self.logs: List[Dict[str, Any]] = []
        self._step_counter = 0

    def log_event(
            self,
            stage: str,
            title: str,
            description: str,
            inputs: Dict[str, Any] | None = None,
            outputs: Dict[str, Any] | None = None,
            score_impact: int | float | None = None,
            resulting_score: int | float | None = None,
            confidence: str | None = None,
    ):
        """
        Sistemdeki HER anlamlƒ± adƒ±m buradan ge√ßer
        """
        self._step_counter += 1

        event = {
            "step": self._step_counter,
            "timestamp": time.time(),
            "stage": stage,
            "title": title,
            "description": description,
            "inputs": inputs or {},
            "outputs": outputs or {},
        }

        if score_impact is not None:
            event["score_impact"] = score_impact

        if resulting_score is not None:
            event["resulting_score"] = resulting_score

        if confidence is not None:
            event["confidence"] = confidence

        self.logs.append(event)

    def export(self) -> Dict[str, Any]:
        """
        UI / API / Storage i√ßin tek JSON
        """
        return {
            "case_id": self.case_id,
            "started_at": self.started_at,
            "completed_at": time.time(),
            "timeline": self.logs,
        }


# ==================================================
# 4Ô∏è‚É£ ACTIONABLE RECOMMENDATION ENGINE
# ==================================================
class ActionableRecommendationEngine:
    # 1. Sabit Profil Haritasƒ± (Safety Layer)
    RECOMMENDATION_PROFILE = {
        "DELIL": {
            "evidence_type": ["tanƒ±k", "belge", "bilirki≈üi", "ke≈üif", "yemin"],
            "priority": "Y√úKSEK",
            "estimated_cost": "Orta",
            "time_impact": "Orta",
            "base_score_range": (5, 10)
        },
        "ICTIHAT": {
            "evidence_type": ["emsal karar", "HGK kararƒ±", "ƒ∞BK"],
            "priority": "ORTA",
            "estimated_cost": "D√º≈ü√ºk",
            "time_impact": "Kƒ±sa",
            "base_score_range": (3, 7)
        },
        "USUL": {
            "evidence_type": ["dilek√ße", "itiraz", "s√ºre tutum"],
            "priority": "Y√úKSEK",
            "estimated_cost": "D√º≈ü√ºk",
            "time_impact": "Kƒ±sa",
            "base_score_range": (2, 4)
        },
        "TALEP_DARALTMA": {
            "evidence_type": ["strateji"],
            "priority": "ORTA",
            "estimated_cost": "D√º≈ü√ºk",
            "time_impact": "Kƒ±sa",
            "base_score_range": (4, 6)
        }
    }

    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_concerns, query_text=""):
        recommendations = []
        for concern in judge_concerns:
            category = self._classify_concern(concern)
            if not category: category = "DELIL"

            profile = self.RECOMMENDATION_PROFILE.get(category, self.RECOMMENDATION_PROFILE["DELIL"])
            rec_text = self._generate_recommendation_text(concern, self._category_to_turkish(category))
            score_boost = random.randint(profile["base_score_range"][0], profile["base_score_range"][1])
            source_detail = self._infer_source(concern, query_text)

            recommendations.append({
                "action_id": str(uuid.uuid4()),
                "title": rec_text.split(".")[0][:80] + "...",
                "description": rec_text,
                "category": category,
                "focus": category,
                "evidence": {
                    "type": self._pick_evidence(profile["evidence_type"]),
                    "source": source_detail,
                    "count": self._estimate_count(category)
                },
                "priority": profile["priority"],
                "estimated_cost": profile["estimated_cost"],
                "time_impact": profile["time_impact"],
                "risk_reduction": {
                    "area": self._category_to_turkish(category),
                    "expected_score_increase": score_boost
                },
                "suggestion": rec_text,
                "if_not_done": self._generate_risk_note(concern),
                "why": concern
            })
        return recommendations

    def _infer_source(self, concern, query_text):
        concern_lower = concern.lower()
        query_lower = query_text.lower()

        if "miras" in query_lower or "veraset" in query_lower:
            if "sgk" in concern_lower or "i≈ü" in concern_lower:
                return {"entity": "N√ºfus M√ºd√ºrl√ºƒü√º / UYAP", "method": "Kayƒ±t Celbi", "responsible": "Mahkeme"}
            return {"entity": "N√ºfus M√ºd√ºrl√ºƒü√º (MERNƒ∞S)", "method": "M√ºzekkere/Sorgu", "responsible": "Mahkeme"}

        if "i≈ü" in concern_lower or "bordro" in concern_lower: return {"entity": "SGK ƒ∞l M√ºd√ºrl√ºƒü√º / ƒ∞≈üyeri",
                                                                       "method": "M√ºzekkere", "responsible": "Mahkeme"}
        if "banka" in concern_lower or "dekont" in concern_lower: return {"entity": "ƒ∞lgili Banka Genel M√ºd√ºrl√ºƒü√º",
                                                                          "method": "M√ºzekkere",
                                                                          "responsible": "Mahkeme"}
        if "rapor" in concern_lower or "teknik" in concern_lower: return {"entity": "Bilirki≈üi Heyeti",
                                                                          "method": "Ke≈üif/ƒ∞nceleme",
                                                                          "responsible": "Mahkeme"}
        if "tanƒ±k" in concern_lower or "g√∂rg√º" in concern_lower: return {"entity": "Tanƒ±klar",
                                                                         "method": "Duru≈ümada Dinletme",
                                                                         "responsible": "Avukat"}
        if "tapu" in concern_lower: return {"entity": "Tapu Sicil M√ºd√ºrl√ºƒü√º", "method": "M√ºzekkere",
                                            "responsible": "Mahkeme"}
        return {"entity": "Dosya Kapsamƒ±", "method": "ƒ∞nceleme", "responsible": "Avukat"}

    def _estimate_count(self, category):
        if category == "DELIL": return random.randint(2, 4)
        if category == "ICTIHAT": return 1
        return 1

    def _generate_risk_note(self, concern):
        return f"Bu husus giderilmezse '{concern[:40]}...' y√∂n√ºnden hakim teredd√ºd√º devam eder ve ispat y√ºk√º kar≈üƒ±lanamaz."

    def _classify_concern(self, concern_text):
        text = concern_text.lower()
        if any(k in text for k in
               ["delil", "ispat", "kanƒ±t", "tanƒ±k", "belge", "tespit", "bilirki≈üi", "rapor"]): return "DELIL"
        if any(k in text for k in ["i√ßtihat", "emsal", "yerle≈üik", "karar", "yargƒ±tay", "daire"]): return "ICTIHAT"
        if any(k in text for k in ["usul", "s√ºre", "ehliyet", "≈üekil", "g√∂rev", "yetki", "husumet"]): return "USUL"
        if any(k in text for k in ["talep", "fazla", "a≈üan", "kƒ±smi", "daraltma"]): return "TALEP_DARALTMA"
        return None

    def _category_to_turkish(self, category):
        return {"DELIL": "delil ve ispat", "ICTIHAT": "emsal i√ßtihat", "USUL": "usul hukuku",
                "TALEP_DARALTMA": "stratejik talep"}.get(category, "hukuki")

    def _generate_recommendation_text(self, concern, category_tr):
        prompt = f"""
BAƒûLAM: T√ºrk Hukuku (Yargƒ±tay/BAM uygulamasƒ±). Ba≈üka √ºlke veya sistem kullanma.
Bir avukata yol g√∂sterecek ≈üekilde, a≈üaƒüƒ±daki hakim teredd√ºd√ºne y√∂nelik {category_tr} odaklƒ± SOMUT bir aksiyon √∂nerisi yaz.
Hakim Teredd√ºd√º: "{concern}"
Kurallar: Tek bir c√ºmle yaz. Emir kipi kullan.
√áIKTI:
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "ƒ∞lgili hususta ek delil ve beyan sunulmalƒ±dƒ±r."

    def _pick_evidence(self, options):
        if not options: return "Genel"
        return random.choice(options)


# ==================================================
# 5Ô∏è‚É£ HAFIZA Y√ñNETƒ∞Cƒ∞Sƒ∞ (FULL INTEGRATED - V127 MASTER PROMPT)
# ==================================================
class LegalMemoryManager:
    # --- SIMULATION CONFIG ---
    MITIGATION_EFFECTS = {
        "DELIL": {"min": 5, "max": 10}, "BELGE": {"min": 5, "max": 10},
        "ICTIHAT": {"min": 3, "max": 7}, "ARGUMAN": {"min": 3, "max": 7},
        "TALEP_DARALTMA": {"min": 4, "max": 6}, "USUL": {"min": 2, "max": 4}
    }
    MAX_TOTAL_BOOST = 15
    MAX_SCORE = 95

    def __init__(self, client, embedder, llm):
        self.client = client
        self.embedder = embedder
        self.llm = llm
        self._init_memory_collections()
        self.last_consolidation_ts = self._load_state()
        self.domain_cache = {}
        self.last_recalled_query = None
        self.recommendation_engine = ActionableRecommendationEngine(llm)
        self.audit_logger = LegalAuditLogger()
        self.sanitizer = LegalTextSanitizer()  # V120 Sanitizer
        self.latest_ui_data = {}

    def _init_memory_collections(self):
        for name, col_name in LegalConfig.MEMORY_COLLECTIONS.items():
            if not self.client.collection_exists(col_name):
                print(f"üß† Hafƒ±za olu≈üturuluyor: {col_name}")
                self.client.create_collection(col_name, vectors_config=VectorParams(size=768, distance=Distance.COSINE))

    def _load_state(self):
        try:
            if os.path.exists(LegalConfig.STATE_FILE):
                with open(LegalConfig.STATE_FILE, 'r') as f:
                    data = json.load(f)
                    return data.get("last_consolidation", 0.0)
        except:
            pass
        return 0.0

    def _save_state(self):
        try:
            with open(LegalConfig.STATE_FILE, 'w') as f:
                json.dump({"last_consolidation": time.time()}, f)
        except:
            pass

    def _detect_polarity(self, principle_text):
        prompt = f"BAƒûLAM: T√ºrk Hukuku.\nƒ∞LKE: '{principle_text}'\nCEVAP (SADECE Bƒ∞Rƒ∞): [LEHINE] veya [ALEYHINE] veya [BELIRSIZ]"
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "LEHINE" in res: return "LEHINE"
            if "ALEYHINE" in res: return "ALEYHINE"
            return "BELIRSIZ"
        except:
            return "BELIRSIZ"

    def _detect_domain_from_query(self, query_text):
        if query_text in self.domain_cache: return self.domain_cache[query_text]
        prompt = f"Sorgu: \"{query_text}\"\nBu sorgu hangi hukuk dalƒ±na girer? SADECE TEK KELƒ∞ME CEVAP VER."
        try:
            domain = self.llm.invoke(prompt).content.strip().split()[0]
            self.domain_cache[query_text] = domain
            return domain
        except:
            return "Genel"

    def _extract_year_bucket(self, timestamp):
        year = datetime.fromtimestamp(timestamp).year
        if year <= 2018:
            return "2015-2018"
        elif year <= 2021:
            return "2019-2021"
        else:
            return "2022-2024"

    def _apply_time_decay(self, confidence, timestamp):
        if not timestamp: return confidence
        elapsed_months = (time.time() - timestamp) / (30 * 24 * 3600)
        return confidence * math.pow(LegalConfig.DECAY_RATE_PER_MONTH, elapsed_months)

    def _calculate_case_success_probability(self, principle_confidence, trend_direction, conflict, domain_match,
                                            polarity="LEHINE"):
        score = principle_confidence * 100
        if trend_direction == "up":
            score += 10
        elif trend_direction == "down":
            score -= 10
        if conflict: score -= 15
        if not domain_match: score -= 10
        if polarity == "BELIRSIZ": score -= 5

        if principle_confidence > 0.85 and polarity == "LEHINE":
            if score < 65: score = 75.0

        score = max(0, min(100, round(score, 1)))
        conf_level = "Y√ºksek" if score >= 70 else "Orta" if score >= 40 else "D√º≈ü√ºk"
        summary = "Ba≈üarƒ± ihtimali y√ºksek." if score >= 70 else "Riskli."
        return {"success_probability": score, "confidence_level": conf_level, "summary": summary}

    # --- V127: MASTER PROMPT GENERATOR ---
    def _build_master_prompt(self, role, domain, topic, analysis_type, memory_context, main_input, task_instruction):
        return f"""
SENƒ∞N ROL√úN: {role}

{LegalConfig.PROMPT_GUARD}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
ALLOWED SCOPE (ZORUNLU SINIRLAR)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Hukuk Alanƒ±: {domain}
- Odak Konu: {topic}
- ƒ∞nceleme T√ºr√º: {analysis_type}
- Yargƒ± √áer√ßevesi: T√ºrk Hukuku (Yargƒ±tay / BAM)

Bu analiz SADECE yukarƒ±daki scope ile sƒ±nƒ±rlƒ±dƒ±r.
Bu sƒ±nƒ±rlarƒ±n dƒ±≈üƒ±ndaki her konu otomatik olarak ANALƒ∞Z DI≈ûIDIR.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
YERLE≈ûƒ∞K HAFIZA / ƒ∞√áTƒ∞HAT BAƒûLAMI
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
{memory_context}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
OLAY / BELGE / TEREDD√úT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
{main_input}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
G√ñREV
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
{task_instruction}

√áIKTIYI OLU≈ûTURMADAN √ñNCE:
- Scope dƒ±≈üƒ±na √ßƒ±kƒ±p √ßƒ±kmadƒ±ƒüƒ±nƒ± kontrol et.
- Tekrar veya genelleme olup olmadƒ±ƒüƒ±nƒ± denetle.
- Hukuki rol√ºn√º ihlal edip etmediƒüini denetle.
"""

    # --- V127: PERSONA FUNCS UPDATED TO MASTER PROMPT ---

    def _generate_judge_doubts_v120(self, query, principle_text, domain="Genel"):
        """Hakimin ilk refleksini ve teredd√ºtlerini √ºretir (Master Prompt ile)."""
        task = """
Bu ilke ƒ±≈üƒ±ƒüƒ±nda, olayƒ± deƒüerlendirirken ya≈üadƒ±ƒüƒ±n EN FAZLA 3 TEMEL TEREDD√úT√ú (Doubts) listele.
Her teredd√ºt SOMUT olsun: delil eksikliƒüi, usul sorunu, emsal uyu≈ümazlƒ±ƒüƒ± gibi.
Teredd√ºtler kƒ±sa ve net olsun (maks 1 c√ºmle).
Ayrƒ±ca dosya hakkƒ±ndaki ƒ∞LK REFLEKSƒ∞Nƒ∞ (Red/Kabul Eƒüilimli) tek kelimeyle yaz.

√áIKTI FORMATI (JSON):
{
  "reflex": "RED Eƒûƒ∞Lƒ∞MLƒ∞ veya KABUL Eƒûƒ∞Lƒ∞MLƒ∞",
  "doubts": ["Teredd√ºt 1...", "Teredd√ºt 2...", "Teredd√ºt 3..."]
}
"""
        prompt = self._build_master_prompt(
            role="T√úRK HAKƒ∞Mƒ∞",
            domain=domain,
            topic=query,
            analysis_type="Hakim ƒ∞lk Deƒüerlendirmesi",
            memory_context=principle_text,
            main_input=query,
            task_instruction=task
        )

        try:
            res = self.llm.invoke(prompt).content.strip()
            # JSON temizliƒüi
            if "```json" in res:
                res = res.split("```json")[1].split("```")[0].strip()
            elif "```" in res:
                res = res.split("```")[1].split("```")[0].strip()
            return json.loads(res)
        except:
            return {"reflex": "BELƒ∞RSƒ∞Z",
                    "doubts": ["Dosya kapsamƒ±nda delil durumu", "Emsal kararƒ±n uygunluƒüu", "Usul eksiklikleri"]}

    def _generate_plaintiff_response_v120(self, doubts, principle_text, domain="Genel", query_text=""):
        doubts_text = "\n".join([f"- {d}" for d in doubts])
        combined_input = f"OLAY: {query_text}\n\nHAKƒ∞M TEREDD√úTLERƒ∞:\n{doubts_text}"

        task = """
G√ñREVƒ∞N:
- Her bir teredd√ºte AYRI AYRI cevap vermek.
- Hakimi kabul y√∂n√ºnde ikna etmeye √ßalƒ±≈ümak.

KURALLAR:
1. Her teredd√ºde AYRI AYRI cevap ver.
2. Cevabƒ±nda mutlaka varsa [MEVZUAT] veya [EMSAL KARAR] etiketli belgeye ATIF YAP (Madde no veya Karar no ver).
3. Genel hukuk anlatma, doƒürudan somut olaya ve m√ºvekkilin haklƒ±lƒ±ƒüƒ±na baƒüla.
4. Her cevap maks 3-4 c√ºmle olsun.

√áIKTI FORMATINI ASLA DEƒûƒ∞≈ûTƒ∞RME:

--------------------------------------------------
DAVACI VEKƒ∞Lƒ∞ DEƒûERLENDƒ∞RMESƒ∞
--------------------------------------------------
Teredd√ºt 1:
- Cevap:

Teredd√ºt 2:
- Cevap:

Teredd√ºt 3:
- Cevap:
"""
        prompt = self._build_master_prompt(
            role="DAVACI VEKƒ∞Lƒ∞",
            domain=domain,
            topic="Hakim Teredd√ºtlerini Giderme",
            analysis_type="Hukuki Arg√ºmantasyon",
            memory_context=principle_text,
            main_input=combined_input,
            task_instruction=task
        )

        try:
            raw = self.llm.invoke(prompt).content.strip()
            return self.sanitizer.enforce_no_repeat(raw)
        except:
            return "Davacƒ± vekili beyanƒ± olu≈üturulamadƒ±."

    def _generate_defendant_response_v120(self, doubts, principle_text, domain="Genel", query_text=""):
        doubts_text = "\n".join([f"- {d}" for d in doubts])
        combined_input = f"OLAY: {query_text}\n\nHAKƒ∞M TEREDD√úTLERƒ∞:\n{doubts_text}"

        task = """
G√ñREVƒ∞N:
- Hakimin teredd√ºtlerini DERƒ∞NLE≈ûTƒ∞RMEK.
- Kabul ihtimalini zayƒ±flatmak.

KURALLAR:
1. Her teredd√ºde AYRI AYRI cevap ver ve teredd√ºd√º derinle≈ütir.
2. Cevabƒ±nda mutlaka varsa [MEVZUAT] veya [EMSAL KARAR] eksikliƒüine veya aleyhe durumuna ATIF YAP.
3. Genel hukuk anlatma, somut olaydaki eksikliklere baƒüla.
4. Her cevap maks 3-4 c√ºmle olsun.

√áIKTI FORMATINI ASLA DEƒûƒ∞≈ûTƒ∞RME:

--------------------------------------------------
DAVALI VEKƒ∞Lƒ∞ DEƒûERLENDƒ∞RMESƒ∞
--------------------------------------------------
Teredd√ºt 1:
- Kar≈üƒ± Arg√ºman:

Teredd√ºt 2:
- Kar≈üƒ± Arg√ºman:

Teredd√ºt 3:
- Kar≈üƒ± Arg√ºman:
"""
        prompt = self._build_master_prompt(
            role="DAVALI (KAR≈ûI TARAF) VEKƒ∞Lƒ∞",
            domain=domain,
            topic="Teredd√ºtleri Derinle≈ütirme ve ƒ∞tiraz",
            analysis_type="Hukuki Arg√ºmantasyon",
            memory_context=principle_text,
            main_input=combined_input,
            task_instruction=task
        )

        try:
            raw = self.llm.invoke(prompt).content.strip()
            return self.sanitizer.enforce_no_repeat(raw)
        except:
            return "Davalƒ± vekili beyanƒ± olu≈üturulamadƒ±."

    def _generate_expert_response_v120(self, doubts, principle_text, domain="Genel", query_text=""):
        doubts_text = "\n".join([f"- {d}" for d in doubts])
        combined_input = f"OLAY: {query_text}\n\nHAKƒ∞M TEREDD√úTLERƒ∞:\n{doubts_text}"

        task = """
G√ñREVƒ∞N:
- Hukuki mantƒ±k zincirini kontrol etmek.

YANITLA:
- Teredd√ºtler hukuken yerinde mi?
- Davacƒ± cevaplarƒ± yeterli mi?
- Davalƒ± itirazlarƒ± hukuki mi?

√áIKTI FORMATINI ASLA DEƒûƒ∞≈ûTƒ∞RME:

--------------------------------------------------
Bƒ∞Lƒ∞RKƒ∞≈ûƒ∞ TESPƒ∞TLERƒ∞
--------------------------------------------------
Genel Hukuki Deƒüerlendirme:
- ...

Zayƒ±f Noktalar:
- ...

Tutarlƒ± Noktalar:
- ...
"""
        prompt = self._build_master_prompt(
            role="TARAFSIZ Bƒ∞Lƒ∞RKƒ∞≈ûƒ∞",
            domain=domain,
            topic="Hukuki Tutarlƒ±lƒ±k Denetimi",
            analysis_type="Bilirki≈üi M√ºtalaasƒ±",
            memory_context=principle_text,
            main_input=combined_input,
            task_instruction=task
        )

        try:
            raw = self.llm.invoke(prompt).content.strip()
            return self.sanitizer.enforce_no_repeat(raw)
        except:
            return "Bilirki≈üi raporu olu≈üturulamadƒ±."

    def _simulate_post_strengthening_score(self, base_score, recommendations):
        total_boost = 0
        seen_cats = {}
        for rec in recommendations:
            cat = rec.get("category", "DELIL")
            impact = rec['risk_reduction']['expected_score_increase']
            if cat in seen_cats: impact = int(impact * 0.6)
            seen_cats[cat] = True
            total_boost += impact

        return {"current_score": base_score, "projected_score": min(base_score + total_boost, self.MAX_SCORE),
                "total_boost": total_boost}

    # --- MAIN RECALL FUNCTION (V127 UPDATE) ---
    def recall_principles(self, query_text):
        try:
            # 1. AUDIT START
            self.audit_logger = LegalAuditLogger()
            self.sanitizer.reset()  # Reset memory for new query

            query_domain = self._detect_domain_from_query(query_text)
            vector = self.embedder.embed_query(query_text)
            hits = self.client.query_points(LegalConfig.MEMORY_COLLECTIONS["principle"], query=vector, limit=15).points

            processed_hits = []
            for h in hits:
                raw_conf = h.payload.get("confidence", 0.5)
                ts = h.payload.get("timestamp", time.time())
                domain = h.payload.get("domain", "Genel")
                evolution_note = h.payload.get("evolution_note", "")
                polarity = h.payload.get("polarity", "BELIRSIZ")
                final_conf = self._apply_time_decay(raw_conf, ts)
                if polarity == "BELIRSIZ": final_conf *= 0.8
                is_domain_match = (query_domain.lower() in domain.lower())

                if final_conf >= LegalConfig.MIN_CONFIDENCE_THRESHOLD:
                    trend_dir = "up" if "G√ú√áLENEN" in evolution_note else "down" if "ZAYIFLAYAN" in evolution_note else "stable"
                    item = {
                        "text": h.payload['principle'], "conf": final_conf, "domain": domain,
                        "conflict": h.payload.get("conflict_flag", False), "score": h.score,
                        "trend_dir": trend_dir, "domain_match": is_domain_match,
                        "evolution_note": evolution_note, "polarity": polarity,
                        "year_bucket": self._extract_year_bucket(ts)
                    }
                    processed_hits.append(item)

            sorted_hits = sorted(processed_hits, key=lambda x: x["score"], reverse=True)[:3]

            # AUDIT: PRINCIPLE ANALYSIS
            self.audit_logger.log_event(
                stage="principle_analysis", title="ƒ∞√ßtihatlar Analiz Edildi",
                description=f"{len(sorted_hits)} adet y√ºksek g√ºvenli ilke tespit edildi.",
                outputs={"domain": query_domain, "hit_count": len(sorted_hits)}
            )

            if not sorted_hits: return ""

            memory_text = f"\nüí° YERLE≈ûƒ∞K ƒ∞√áTƒ∞HAT HAFIZASI ({query_domain} Alanƒ±):\n"

            self.latest_ui_data = {
                "query": query_text, "domain": query_domain, "principles": [], "net_decision": {},
                "executive_summary": "", "audit_log": {}
            }

            for item in sorted_hits:
                # 2. Risk Analizi
                analysis = self._calculate_case_success_probability(
                    item["conf"], item["trend_dir"], item["conflict"], item["domain_match"], item["polarity"]
                )

                # --- V120: PERSONA Sƒ∞STEMƒ∞ ---
                # V127 UPDATE: Domain ve Query Text transfer edildi.

                # A. HAKƒ∞M REFLEKSƒ∞ VE TEREDD√úTLER (TRIGGER)
                # Yeni parametre eklendi: domain
                judge_data = self._generate_judge_doubts_v120(query_text, item['text'], domain=item['domain'])
                doubts = judge_data.get("doubts", [])
                reflex = judge_data.get("reflex", "BELƒ∞RSƒ∞Z")

                self.audit_logger.log_event(
                    stage="judge_analysis",
                    title="JUDGE ANALYSIS COMPLETED",
                    description=f"Hakim Refleksi: {reflex}",
                    outputs={"reflex": reflex, "doubt_count": len(doubts), "doubts": doubts}
                )

                # B. PERSONA PHASE (SIRALI AKI≈û)
                self.audit_logger.log_event(stage="persona_phase", title="PERSONA PHASE STARTED",
                                            description="Taraf vekilleri ve bilirki≈üi devreye giriyor.")

                # Davacƒ±
                # Yeni parametreler: domain, query_text
                plaintiff_text = self._generate_plaintiff_response_v120(doubts, item['text'], domain=item['domain'],
                                                                        query_text=query_text)
                self.audit_logger.log_event(
                    stage="plaintiff_arg", title="DAVACI VEKƒ∞Lƒ∞ DEƒûERLENDƒ∞RMESƒ∞",
                    description=f"Ele alƒ±nan teredd√ºt sayƒ±sƒ±: {len(doubts)}",
                    outputs={"full_text": plaintiff_text}
                )

                # Davalƒ±
                # Yeni parametreler: domain, query_text
                defendant_text = self._generate_defendant_response_v120(doubts, item['text'], domain=item['domain'],
                                                                        query_text=query_text)
                self.audit_logger.log_event(
                    stage="defendant_arg", title="DAVALI VEKƒ∞Lƒ∞ DEƒûERLENDƒ∞RMESƒ∞",
                    description="Kar≈üƒ± arg√ºmanlar ve usul itirazlarƒ± sunuldu.",
                    outputs={"full_text": defendant_text}
                )

                # Bilirki≈üi
                # Yeni parametreler: domain, query_text
                expert_text = self._generate_expert_response_v120(doubts, item['text'], domain=item['domain'],
                                                                  query_text=query_text)
                self.audit_logger.log_event(
                    stage="expert_arg", title="Bƒ∞Lƒ∞RKƒ∞≈ûƒ∞ TESPƒ∞TLERƒ∞",
                    description="Hukuki zincir ve tutarlƒ±lƒ±k kontrol√º yapƒ±ldƒ±.",
                    outputs={"full_text": expert_text}
                )

                self.audit_logger.log_event(stage="persona_completed", title="PERSONA PHASE COMPLETED",
                                            description="T√ºm taraflar dinlendi.")

                # C. ACTION ENGINE (Teredd√ºtler √ºzerinden √ßalƒ±≈üƒ±r)
                action_plan = self.recommendation_engine.generate(doubts, query_text)

                # D. SIMULATION
                simulation_result = self._simulate_post_strengthening_score(analysis['success_probability'],
                                                                            action_plan)

                # E. EXECUTIVE SUMMARY
                exec_summary = f"Hakim '{reflex}' eƒüilimindedir. {len(doubts)} temel teredd√ºt (√ñrn: {doubts[0]}) mevcuttur. Davacƒ± vekili bu hususlarƒ± gidermeye √ßalƒ±≈üsa da Davalƒ± taraf usul itirazlarƒ±nƒ± s√ºrd√ºrmektedir."

                # V120 SANITIZATION LOG
                self.audit_logger.log_event(
                    stage="output_sanitizer", title="OUTPUT SANITIZER APPLIED",
                    description=f"Tekrar eden paragraflar temizlendi.",
                    outputs={"repeated_paragraphs_removed": self.sanitizer.dropped_count}
                )

                # Store Complete Data (V120 Structure)
                self.latest_ui_data["principles"].append({
                    "text": item['text'], "trend_log": item['evolution_note'], "polarity": item['polarity'],
                    "conflict_flag": item['conflict'], "year_bucket": item['year_bucket'],
                    "score_data": analysis,
                    "personas_v120": {
                        "judge_reflex": reflex,
                        "doubts": doubts,
                        "plaintiff": plaintiff_text,
                        "defendant": defendant_text,
                        "expert": expert_text
                    },
                    # Backward compatibility dummy data
                    "personas": {"judge": str(doubts), "opponent": defendant_text, "opponent_title": "Davalƒ±",
                                 "expert": expert_text, "devil": "N/A"},
                    "conflict_analysis": {"conflict_level": "N/A", "conflict_score": 0, "summary": []},
                    "reasoned_verdict": f"HAKƒ∞Mƒ∞N GE√áƒ∞Cƒ∞ KANAATƒ∞: {reflex}. Gerek√ße: {doubts}",
                    "action_plan": action_plan,
                    "simulation": simulation_result
                })
                self.latest_ui_data["executive_summary"] = exec_summary
                self.latest_ui_data["net_decision"] = {"decision": reflex}

                memory_text += f"- [{item['domain']}] {item['text']}\n"
                memory_text += f"  ‚öñÔ∏è REFLEKS: {reflex} | ‚ö†Ô∏è Teredd√ºt: {len(doubts)} adet\n"

            # V120: Audit Log Export
            self.latest_ui_data["audit_log"] = self.audit_logger.export()

            return memory_text
        except Exception as e:
            print(f"Hata: {e}")
            return ""

    # --- MATEMATƒ∞KSEL YARDIMCILAR (TAM) ---
    def _cosine_similarity(self, v1, v2):
        dot = sum(a * b for a, b in zip(v1, v2))
        mag1 = math.sqrt(sum(a * a for a in v1))
        mag2 = math.sqrt(sum(b * b for b in v2))
        if mag1 == 0 or mag2 == 0: return 0.0
        return dot / (mag1 * mag2)

    def _calculate_vector_mean(self, vectors):
        if not vectors: return []
        dim = len(vectors[0])
        mean = [0.0] * dim
        for v in vectors:
            for i in range(dim):
                mean[i] += v[i]
        return [x / len(vectors) for x in mean]

    def _cluster_reasonings(self, items, threshold=0.86):
        clusters = []
        for item in items:
            added = False
            for c in clusters:
                if self._cosine_similarity(item['vector'], c['centroid']) >= threshold:
                    c['members'].append(item)
                    all_vecs = [m['vector'] for m in c['members']]
                    c['centroid'] = self._calculate_vector_mean(all_vecs)
                    added = True
                    break
            if not added:
                clusters.append({'members': [item], 'centroid': item['vector']})
        return [c['members'] for c in clusters]

    def _calculate_principle_confidence(self, cluster):
        count = len(cluster)
        count_score = min(1.0, count / 10)
        return 0.7 + (count_score * 0.3)

    def _analyze_trend_momentum(self, trend_dict):
        if not trend_dict: return "Veri Yetersiz"
        return "ƒ∞stikrarlƒ± Seyir"

    # --- ESKƒ∞ SAVE FONKSƒ∞YONLARI (TAM & EKSƒ∞KSƒ∞Z) ---
    def calculate_memory_consensus(self, source_name, current_decision, vector_score):
        try:
            f = Filter(must=[FieldCondition(key="source", match=MatchValue(value=source_name))])
            p, _ = self.client.scroll("judge_memory_v1", scroll_filter=f, limit=20)
            if not p:
                if vector_score > 0.8: return 1.10
                return 1.0

            match_c = sum(1 for x in p if x.payload.get("decision") == current_decision)
            if len(p) == 0: return 1.0
            ratio = match_c / len(p)

            if ratio > 0.8: return 1.15
            if ratio < 0.2: return 0.85
            return 1.0
        except:
            return 1.0

    def save_decision(self, query, doc_name, decision, reason, doc_type):
        try:
            vec = self.embedder.embed_query(f"{query} {doc_name} {decision} {reason}")
            payload = {
                "query": query, "source": doc_name, "decision": decision,
                "reason": reason, "doc_type": doc_type,
                "timestamp": time.time(), "created_at": datetime.now().isoformat(), "id": str(uuid.uuid4())
            }
            self.client.upsert("judge_memory_v1", [PointStruct(id=payload['id'], vector=vec, payload=payload)])
        except:
            pass

    # --- KONSOLƒ∞DASYON (TAM) ---
    def consolidate_principles_v79(self):
        print("\nüî• ƒ∞√áTƒ∞HAT Mƒ∞MARI: Artƒ±mlƒ± Konsolidasyon (V120)...")
        try:
            time_filter = Filter(must=[FieldCondition(key="timestamp", range=Range(gt=self.last_consolidation_ts))])
            points, _ = self.client.scroll(LegalConfig.MEMORY_COLLECTIONS["decision"], scroll_filter=time_filter,
                                           limit=200)

            candidates = []
            for p in points:
                if (p.payload.get('doc_type') == 'EMSAL KARAR' and len(
                        p.payload.get('reason', '')) > 30 and p.payload.get('decision') == 'KABUL'):
                    candidates.append({
                        "reason": p.payload['reason'], "id": p.id,
                        "source": p.payload.get('source', 'Bilinmeyen'),
                        "timestamp": p.payload.get('timestamp', time.time()),
                        "decision": p.payload.get('decision'), "vector": None
                    })

            if len(candidates) < 3:
                print("   ‚ÑπÔ∏è Yeterli yeni veri yok.")
                return

            print(f"   üîç {len(candidates)} adet YENƒ∞ gerek√ße analiz ediliyor...")
            texts = [c["reason"] for c in candidates]
            vectors = self.embedder.embed_documents(texts)
            for i, v in enumerate(vectors): candidates[i]["vector"] = v
            clusters = self._cluster_reasonings(candidates, threshold=0.86)

            for cluster in clusters:
                if len(cluster) < 3: continue

                # K√ºme Gerek√ßelerini Birle≈ütir
                reasonings_text = "\n".join([f"- {c['reason']}" for c in cluster])
                prompt = f"""
G√ñREV: A≈üaƒüƒ±daki mahkeme gerek√ßelerini analiz et.
1. Ortak hukuki ilkeyi TEK C√úMLEDE √∂zetle.
2. Bu konunun ait olduƒüu Hukuk Dalƒ±nƒ± (Miras, Ceza, Bor√ßlar vb.) belirle.

GEREK√áELER:
{reasonings_text}

FORMAT:
ƒ∞LKE: [ƒ∞lke C√ºmlesi]
ALAN: [Hukuk Dalƒ±]
"""
                res = self.llm.invoke(prompt).content.strip()
                principle_match = re.search(r"ƒ∞LKE:\s*(.*)", res)
                domain_match = re.search(r"ALAN:\s*(.*)", res)

                if principle_match:
                    principle_text = principle_match.group(1)
                    domain_text = domain_match.group(1) if domain_match else "Genel"
                    conf = self._calculate_principle_confidence(cluster)
                    source_ids = [c['id'] for c in cluster]

                    self._save_principle_v79(principle_text, conf, source_ids, domain_text, cluster)

            self._save_state()
            print("‚úÖ Konsolidasyon tamamlandƒ±.")
        except Exception as e:
            print(f"Hata: {e}")

    def _save_principle_v79(self, text, confidence, source_ids, domain, cluster_data):
        try:
            vec = self.embedder.embed_query(text)
            polarity = self._detect_polarity(text)
            hits = self.client.query_points("principle_memory_v1", query=vec, limit=10, score_threshold=0.80).points

            conflict = False
            trend = Counter()
            p_stats = {"LEHINE": 0, "ALEYHINE": 0, "BELIRSIZ": 0}

            # Conflict Check
            if polarity in p_stats: p_stats[polarity] += 1
            for h in hits:
                p = h.payload.get("polarity", "BELIRSIZ")
                if p in p_stats: p_stats[p] += 1
                if (p == "LEHINE" and polarity == "ALEYHINE") or (
                        p == "ALEYHINE" and polarity == "LEHINE"): conflict = True

            # Trend Check
            for c in cluster_data:
                bucket = self._extract_year_bucket(c.get("timestamp", time.time()))
                trend[(bucket, c.get("decision", "KABUL"))] += 1

            trend_dict = {}
            for (b, d), count in trend.items():
                if b not in trend_dict: trend_dict[b] = {"KABUL": 0, "RED": 0}
                trend_dict[b][d] = count

            evolution = self._analyze_trend_momentum(trend_dict)

            payload = {
                "principle": text, "confidence": confidence, "domain": domain,
                "polarity": polarity, "trend": trend_dict, "conflict_flag": conflict,
                "source_count": len(source_ids), "source_ids": source_ids, "evolution_note": evolution,
                "generated_by": "consolidation_v120", "timestamp": time.time(), "created_at": datetime.now().isoformat()
            }
            self.client.upsert("principle_memory_v1", [PointStruct(id=str(uuid.uuid4()), vector=vec, payload=payload)])
        except:
            pass


# ==================================================
# 7Ô∏è‚É£ YENƒ∞ ARA√áLAR: REASONING & STRATEGY (RESTORED)
# ==================================================
class WhiteLabelConfig:
    def __init__(self, firm_name="LEGAL OS", logo_path=None, footer_text="Otomatik Analiz Raporu", color=(0, 0, 0)):
        self.firm_name = firm_name
        self.logo_path = logo_path
        self.footer_text = footer_text
        self.color = color


class AuditTimelineBuilder:
    @staticmethod
    def build(audit_logs):
        timeline = []
        last_score = None
        logs_list = audit_logs.get("timeline", []) if isinstance(audit_logs, dict) else audit_logs
        for idx, log in enumerate(logs_list):
            score = log.get("resulting_score")
            if score is None: continue
            delta = None
            if last_score is not None: delta = round(score - last_score, 1)
            timeline.append({"step": idx + 1, "stage": log.get("title", "ƒ∞≈ülem"), "score": score, "delta": delta})
            last_score = score
        return timeline


class ScoreExplanationEngine:
    @staticmethod
    def generate(timeline):
        if not timeline: return "Yeterli veri yok."
        increases = [t for t in timeline if t["delta"] and t["delta"] > 0]
        decreases = [t for t in timeline if t["delta"] and t["delta"] < 0]
        parts = []
        if decreases:
            worst = min(decreases, key=lambda x: x["delta"])
            parts.append(f"Ba≈üarƒ± olasƒ±lƒ±ƒüƒ±, '{worst['stage']}' a≈üamasƒ±nda %{abs(worst['delta'])} d√º≈üm√º≈üt√ºr.")
        if increases:
            best = max(increases, key=lambda x: x["delta"])
            parts.append(
                f"Ancak '{best['stage']}' a≈üamasƒ±nda stratejik deƒüerlendirme ile %{best['delta']} artƒ±≈ü saƒülanmƒ±≈ütƒ±r.")
        return " ".join(parts) if parts else "Skor duraƒüan seyretmi≈ütir."


class JudgeReasoningGenerator:
    """V125: Dinamik Hakim Rol√º Atamasƒ±"""

    def __init__(self, llm):
        self.llm = llm

    def generate(self, audit_logs, story=None, context_str=None):
        logs_list = audit_logs.get("timeline", []) if isinstance(audit_logs, dict) else audit_logs
        summary_lines = [f"- {log['description']}" for log in logs_list if "description" in log]
        audit_summary = "\n".join(summary_lines)

        # 1. DAVA T√úR√ú TESPƒ∞Tƒ∞ (Meta-Data √áƒ±karƒ±mƒ±)
        dava_turu = "GENEL"
        if story:
            s_lower = story.lower()
            if any(k in s_lower for k in ["veraset", "miras", "tereke", "vasiyet", "√∂l√ºnce"]):
                dava_turu = "SULH HUKUK (Mƒ∞RAS)"
            elif any(k in s_lower for k in ["i≈ü√ßi", "kƒ±dem", "ihbar", "fesih", "i≈üveren"]):
                dava_turu = "ƒ∞≈û MAHKEMESƒ∞"
            elif any(k in s_lower for k in ["bo≈üanma", "nafaka", "velayet", "e≈ü"]):
                dava_turu = "Aƒ∞LE MAHKEMESƒ∞"
            elif any(k in s_lower for k in ["ceza", "su√ß", "sanƒ±k", "hapis"]):
                dava_turu = "CEZA MAHKEMESƒ∞"
            elif any(k in s_lower for k in ["ticaret", "≈üirket", "bono", "√ßek"]):
                dava_turu = "Tƒ∞CARET MAHKEMESƒ∞"

        # 2. HAKƒ∞M ROL√úN√úN BELƒ∞RLENMESƒ∞
        hakim_rolu = "ƒ∞LGƒ∞Lƒ∞ MAHKEME HAKƒ∞Mƒ∞"
        if "Mƒ∞RAS" in dava_turu:
            hakim_rolu = "SULH HUKUK HAKƒ∞Mƒ∞"
        elif "ƒ∞≈û" in dava_turu:
            hakim_rolu = "ƒ∞≈û MAHKEMESƒ∞ HAKƒ∞Mƒ∞"
        elif "Aƒ∞LE" in dava_turu:
            hakim_rolu = "Aƒ∞LE MAHKEMESƒ∞ HAKƒ∞Mƒ∞"
        elif "CEZA" in dava_turu:
            hakim_rolu = "ASLƒ∞YE CEZA HAKƒ∞Mƒ∞"
        elif "Tƒ∞CARET" in dava_turu:
            hakim_rolu = "ASLƒ∞YE Tƒ∞CARET HAKƒ∞Mƒ∞"

        prompt = f"""
SEN Bƒ∞R {hakim_rolu} OLARAK KARAR GEREK√áESƒ∞ YAZIYORSUN.
{LegalConfig.PROMPT_GUARD}

OLAY √ñZETƒ∞: {story if story else 'Dosya kapsamƒ±'}
MEVZUAT, EMSAL VE DELƒ∞LLER: {context_str if context_str else audit_summary}

G√ñREVƒ∞N:
Karar gerek√ßeni ≈üu yapƒ± ile yaz (resmi √ºslup, yakla≈üƒ±k 250-350 kelime):

1. Dosya kapsamƒ±na giren delillerin ve toplanan t√ºm kanƒ±tlarƒ±n √∂zeti (tanƒ±k beyanlarƒ±, bilirki≈üi raporu, belgeler vb. somut olarak belirt).
2. Taraflarƒ±n iddialarƒ± ve savunmalarƒ±nƒ±n kƒ±sa √∂zeti.
3. Hukuki deƒüerlendirme: ƒ∞lgili kanun maddeleri, Yargƒ±tay i√ßtihatlarƒ± ve emsal kararlara somut atƒ±f yaparak olayƒ±n nasƒ±l deƒüerlendirildiƒüi.
4. Hakim olarak kar≈üƒ±la≈ütƒ±ƒüƒ±n teredd√ºtler (maksimum 2-3 tane, somut) ve bunlarƒ±n nasƒ±l giderildiƒüi.
5. Sonu√ß: Davanƒ±n kabul√º/reddi/kƒ±smen kabul√º, ek delil istenmesi vb. net h√ºk√ºm.

Bu kararƒ±n kesin h√ºk√ºm etkisi olmadƒ±ƒüƒ±nƒ± ve kanun yoluna a√ßƒ±k olduƒüunu belirt.
Somut olayla baƒülantƒ±lƒ±, soyut genel ifadelerden ka√ßƒ±n. Ger√ßek bir hakim karar gerek√ßesi gibi doƒüal ve akƒ±cƒ± olsun.
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "Gerek√ße olu≈üturulamadƒ±."


class AppealArgumentGenerator:
    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_reasoning):
        prompt = f"""
SEN KIDEMLI BIR AVUKATSIN.
{LegalConfig.PROMPT_GUARD}

Asagida bir hakimin karar gerekcesi yer almaktadir.
Bu gerekceden hareketle, UST MAHKEMEYE sunulmak uzere itiraz argumanlari yaz.

KURALLAR:
- Hakime saygi dili kullan
- "eksik inceleme", "yanlis takdir", "delillerin birlikte degerlendirilmemesi" kaliplari kullan
- Madde madde yaz (Max 5 madde)

HAKIM GEREKCESI:
{judge_reasoning}
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "ƒ∞tiraz arg√ºmanlarƒ± olu≈üturulamadƒ±."


class AppealPetitionGenerator:
    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_reasoning, case_topic):
        prompt = f"""
BAƒûLAM: T√ºrk Hukuku. BAM / Yargƒ±tay uygulamasƒ±.
SEN: Kƒ±demli bir avukatsƒ±n.
{LegalConfig.PROMPT_GUARD}

A≈üaƒüƒ±da yer alan hakim gerek√ßesine kar≈üƒ±, √ºst mahkemeye sunulmak √ºzere
RESMƒ∞, KURUMSAL ve HUKUKƒ∞ Dƒ∞LDE tam bir ƒ∞Tƒ∞RAZ / ƒ∞STƒ∞NAF / TEMYƒ∞Z Dƒ∞LEK√áESƒ∞ taslaƒüƒ± yaz.

KURALLAR:
- Hakime saygƒ±lƒ± dil kullan.
- "Eksik inceleme", "yanlƒ±≈ü takdir", "hukuka aykƒ±rƒ±lƒ±k" kalƒ±plarƒ± yer alsƒ±n.
- Madde numaralarƒ± kullan.

ZORUNLU UNSURLAR:
- Mahkeme adƒ±, dosya no (√∂rnek: ... Mahkemesi, 2024/... E.)
- Kararƒ±n √∂zeti
- Somut itiraz nedenleri (eksik inceleme, yanlƒ±≈ü hukuk uygulamasƒ± vb.)
- Hangi TMK maddesi veya Yargƒ±tay i√ßtihadƒ±nƒ±n yanlƒ±≈ü uygulandƒ±ƒüƒ±
- ƒ∞stemin net ifadesi
- Avukat imzasƒ± kƒ±smƒ±nƒ± bƒ±rak

ZORUNLU BA≈ûLIKLAR:
1. KARARIN √ñZETƒ∞
2. ƒ∞Tƒ∞RAZ NEDENLERƒ∞
3. HUKUKƒ∞ DEƒûERLENDƒ∞RME
4. SONU√á VE ƒ∞STEM

DOSYA KONUSU: {case_topic}
HAKƒ∞M GEREK√áESƒ∞: {judge_reasoning}

√áIKTI (Sadece Dilek√ße Metni):
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "Dilek√ße olu≈üturulamadƒ±."


class AppealActionMapper:
    def __init__(self, llm):
        self.llm = llm

    def map_arguments(self, appeal_text):
        actions = []
        arguments = [a.strip() for a in appeal_text.split("\n") if re.match(r"^\d+\.", a.strip())][:5]

        for arg in arguments:
            prompt = f"""
SEN KIDEMLI BIR AVUKATSIN.
Asagidaki itiraz argumanindan hareketle, avukatin fiilen yapmasi gereken SOMUT bir aksiyon tanimla.
JSON formatinda ver.

ALANLAR: title, evidence_type (tanƒ±k/belge/bilirki≈üi/i√ßtihat), source, estimated_time, estimated_cost, risk_if_missing

ITIRAZ ARGUMANI: {arg}
"""
            try:
                res = self.llm.invoke(prompt).content.strip()
                if "```json" in res:
                    res = res.split("```json")[1].split("```")[0].strip()
                elif "```" in res:
                    res = res.split("```json")[1].split("```")[0].strip()

                action = json.loads(res)
                action["action_id"] = str(uuid.uuid4())
                action["linked_argument"] = arg
                actions.append(action)
            except:
                continue
        return actions


class CorporateCover:
    @staticmethod
    def add(pdf, case_id, version="V120"):
        pdf.add_page()
        pdf.set_font("DejaVu", "B", 24)
        pdf.ln(60)
        pdf.cell(0, 10, "LEGAL OS", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", size=14)
        pdf.cell(0, 10, "Yapay Zeka Destekli Hukuki Analiz Raporu", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(30)
        pdf.set_font("DejaVu", "B", 10)
        pdf.cell(0, 8, f"DOSYA KIMLIGI: {case_id}", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", "", 10)
        pdf.cell(0, 8, f"RAPOR TARIHI: {datetime.now().strftime('%d.%m.%Y %H:%M')}", align="C", new_x=XPos.LMARGIN,
                 new_y=YPos.NEXT)
        pdf.cell(0, 8, f"SISTEM SURUMU: {version}", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(50)
        pdf.set_font("DejaVu", "I", 8)
        pdf.multi_cell(0, 5,
                       "YASAL UYARI: Bu rapor, yapay zeka algoritmalari kullanilarak uretilmistir. Hukuki tavsiye niteliginde olmayip, karar destek amaclidir.",
                       align="C")


# ==================================================
# 8Ô∏è‚É£ ARAMA MOTORU SINIFI (SEARCH ENGINE)
# ==================================================
class LegalSearchEngine:
    def __init__(self):
        self.config = LegalConfig()
        self.dense_embedder = OllamaEmbeddings(model=self.config.EMBEDDING_MODEL)
        self.client = None
        atexit.register(self.close)

    def connect_db(self):
        if self.client is not None: return True
        print("   üîå Veritabanƒ± baƒülantƒ±sƒ± ba≈ülatƒ±lƒ±yor...")
        LegalUtils.force_unlock_db()
        try:
            self.client = QdrantClient(path=self.config.QDRANT_PATH)
            print("   ‚úÖ Veritabanƒ± baƒülantƒ±sƒ± BA≈ûARILI.")
            return True
        except Exception as e:
            print(f"\n‚ùå VERƒ∞TABANI HATASI: {e}")
            return False

    def close(self):
        if self.client:
            try:
                self.client.close()
                self.client = None
                print("\nüîí Veritabanƒ± baƒülantƒ±sƒ± g√ºvenli ≈üekilde kapatƒ±ldƒ±.")
            except:
                pass

    def run_indexing(self):
        if not self.connect_db(): return False

        for key, config in self.config.SOURCES.items():
            collection_name = config["collection"];
            folder_path = config["folder"]
            print(f"   üëâ Koleksiyon kontrol ediliyor: {config['desc']}...")

            if not os.path.exists(folder_path):
                os.makedirs(folder_path);
                print(f"      ‚ö†Ô∏è Klas√∂r olu≈üturuldu: {folder_path}");
                continue

            if not self.client.collection_exists(collection_name):
                print(f"      ‚öôÔ∏è '{collection_name}' olu≈üturuluyor...")
                self.client.create_collection(collection_name,
                                              vectors_config=VectorParams(size=768, distance=Distance.COSINE))

            print(f"      üîç Mevcut dosyalar taranƒ±yor...")
            indexed_files = set()
            offset = None
            while True:
                points, offset = self.client.scroll(collection_name, limit=100, with_payload=True, with_vectors=False,
                                                    offset=offset)
                for p in points:
                    if 'source' in p.payload: indexed_files.add(p.payload['source'])
                if offset is None: break

            files_on_disk = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]
            new_files = [f for f in files_on_disk if f not in indexed_files]

            if not new_files: print(f"      ‚úÖ {config['desc']} g√ºncel ({len(files_on_disk)} dosya)."); continue
            print(f"      ‚ôªÔ∏è {config['desc']} i√ßin {len(new_files)} yeni dosya i≈üleniyor...")

            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            all_texts = [];
            all_metadatas = []

            for filename in new_files:
                try:
                    loader = PyMuPDFLoader(os.path.join(folder_path, filename))
                    docs = loader.load()
                    chunks = text_splitter.split_documents(docs)
                    for c in chunks:
                        clean_content = LegalUtils.clean_text(c.page_content)
                        all_texts.append(clean_content)
                        all_metadatas.append(
                            {"source": filename, "type": config['desc'], "page": c.metadata.get("page", 0) + 1})
                    print(f"      üìÑ Okundu: {filename}")
                except Exception as e:
                    print(f"      ‚ö†Ô∏è Hata: {filename} - {e}")

            if not all_texts: continue
            print(f"      üöÄ Vekt√∂rle≈ütiriliyor ({len(all_texts)} par√ßa)...")

            num_cores = cpu_count();
            batch_size = (len(all_texts) // num_cores) + 1;
            batches = []
            for i in range(0, len(all_texts), batch_size): batches.append(
                (all_texts[i:i + batch_size], self.config.EMBEDDING_MODEL))

            all_vectors = []
            try:
                with Pool(processes=num_cores) as pool:
                    results = pool.map(worker_embed_batch_global, batches)
                    for res in results: all_vectors.extend(res)
            except Exception as e:
                print(f"‚ùå ƒ∞≈ülemci Hatasƒ±: {e}");
                return False

            print(f"      üíæ Kaydediliyor...");
            points = []
            for i, (vec, meta, txt) in enumerate(zip(all_vectors, all_metadatas, all_texts)):
                payload = {"page_content": txt, "source": meta["source"], "page": meta["page"], "type": meta["type"]}
                point_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, txt + meta["source"] + collection_name))
                points.append(PointStruct(id=point_id, vector=vec, payload=payload))

            batch_size_upload = 64
            for i in range(0, len(points), batch_size_upload): self.client.upsert(collection_name,
                                                                                  points[i:i + batch_size_upload])

        print("‚úÖ ƒ∞ndeksleme Tamamlandƒ±.");
        return True

    def retrieve_raw_candidates(self, full_query):
        print("\nüîç Belgeler Taranƒ±yor (Dual Search - A≈üama 1: Geni≈ü Havuz)...")
        try:
            query_vector = self.dense_embedder.embed_query(full_query)
        except Exception as e:
            print(f"‚ùå Embedding Hatasƒ±: {e}");
            return []

        all_candidates = []
        for key, config in self.config.SOURCES.items():
            try:
                results = self.client.query_points(collection_name=config["collection"], query=query_vector,
                                                   limit=self.config.SEARCH_LIMIT_PER_SOURCE).points
                for hit in results:
                    if 'type' not in hit.payload: hit.payload['type'] = config['desc']
                    all_candidates.append(hit)
            except:
                pass

        unique_docs = {}
        for hit in all_candidates:
            if hit.score < self.config.SCORE_THRESHOLD: continue
            key = f"{hit.payload['source']}_{hit.payload['page']}"
            if key not in unique_docs or hit.score > unique_docs[key].score: unique_docs[key] = hit

        # V101: KOTA Sƒ∞STEMƒ∞ UYGULAMASI
        emsal_hits = []
        mevzuat_hits = []

        for hit in unique_docs.values():
            if hit.payload.get('type') == 'MEVZUAT':
                mevzuat_hits.append(hit)
            else:
                emsal_hits.append(hit)

        emsal_hits.sort(key=lambda x: x.score, reverse=True)
        mevzuat_hits.sort(key=lambda x: x.score, reverse=True)

        limit = self.config.LLM_RERANK_LIMIT
        statute_quota = 3
        precedent_quota = limit - statute_quota

        final_candidates = emsal_hits[:precedent_quota] + mevzuat_hits[:statute_quota]

        if len(mevzuat_hits) < statute_quota:
            needed = limit - len(final_candidates)
            if needed > 0:
                extras = emsal_hits[precedent_quota: precedent_quota + needed]
                final_candidates.extend(extras)

        if not final_candidates: print("üî¥ Uygun belge bulunamadƒ±."); return []
        print(f"   ‚úÖ {len(final_candidates)} potansiyel belge bulundu. Yargƒ±ca g√∂nderiliyor...")
        return final_candidates


# ==================================================
# 9Ô∏è‚É£ YARGI√á VE MUHAKEME SINIFI (JUDGE)
# ==================================================
class LegalJudge:
    """
        BU SINIF KARAR VERMEZ.
        JudgeCore tarafƒ±ndan √ºretilmi≈ü eƒüilimi,
        hukuki rapor diline √ßevirir.
    """

    def __init__(self, memory_manager=None):
        # V120: Global Config Kullanƒ±mƒ±
        self.llm = ChatOllama(
            model=LegalConfig.LLM_MODEL,
            temperature=LegalConfig.LLM_CONFIG["temperature"],
            top_p=LegalConfig.LLM_CONFIG["top_p"],
            # Diƒüer parametreler LangChain entegrasyonuna g√∂re kwargs olarak ge√ßilebilir
            # ancak temel olarak temp ve top_p yeterlidir.
        )
        self.memory = memory_manager
        self.sanitizer = LegalTextSanitizer()

    # üî® Commit 5.3: Build Query Context (Single Source)
    def build_query_context(self, story, topic, negatives) -> QueryContext:
        """
        Ham kullanƒ±cƒ± girdilerini alƒ±r, hukuk alanƒ±nƒ± tespit eder ve
        tek bir QueryContext nesnesi olarak paketler.
        """
        # Hukuk Alanƒ± Tespiti (Memory varsa oradan, yoksa basit√ße 'Genel')
        domain = "Genel"
        if self.memory:
            # Domain tespiti i√ßin memory_manager i√ßindeki fonksiyonu kullanƒ±yoruz
            domain = self.memory._detect_domain_from_query(f"{story} {topic}")

        ctx = QueryContext(
            query_text=story,
            topic=topic,
            detected_domain=domain,
            negative_scope=negatives,
            allowed_sources=["mevzuat", "emsal"],
            allow_analogy=False,
            allow_speculation=False,
            allow_soft_language=False
        )

        # G√ºvenlik kemerini baƒüla
        ctx.assert_hard_limits()

        return ctx

    def validate_user_input(self, story, topic):
        prompt = f"""
G√ñREV: Metnin tamamen anlamsƒ±z rastgele tu≈ülama (gibberish) olup olmadƒ±ƒüƒ±nƒ± tespit et.
METƒ∞N: "{story} {topic}"
ANALƒ∞Z KURALLARI:
1. "araba", "miras" gibi tek kelimelik girdiler [GE√áERLƒ∞].
2. Sadece "asdasd", "lkgjdf" gibi rastgele tu≈ülamalar [GE√áERSƒ∞Z].
CEVAP (SADECE Bƒ∞Rƒ∞): [GE√áERLƒ∞] veya [GE√áERSƒ∞Z]
"""
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "GE√áERSƒ∞Z" in res: return False
            return True
        except:
            return True

    def generate_expanded_queries(self, story, topic):
        print("   ‚Ü≥ üß† Sorgu Geni≈ületiliyor...")
        try:
            prompt = f"G√ñREV: Hukuki terimler.\nOLAY: {story}\nODAK: {topic}\n3 kƒ±sa c√ºmle."
            res = self.llm.invoke(prompt).content
            return [line.strip() for line in res.splitlines() if len(line) > 5][:3]
        except:
            return [story]

    # [YENƒ∞ EKLENEN METOT]
    def _build_scope_block(self, topic, negatives=None):
        scope = f"""
ALLOWED SCOPE (ZORUNLU):
- Analiz SADECE ≈üu konu ile sƒ±nƒ±rlƒ± olacak: {topic}
- T√ºrk Hukuku (Yargƒ±tay/BAM uygulamasƒ±)
- Somut olay ve delil odaklƒ± deƒüerlendirme
"""
        if negatives:
            scope += "\nIMPLICITLY EXCLUDED (Bu alanlar analiz dƒ±≈üƒ±dƒ±r):\n"
            for n in negatives:
                scope += f"- {n}\n"

        scope += "\nBu sƒ±nƒ±rlarƒ±n DI≈ûINA √áIKMA.\n"
        return scope

    def _check_relevance_judge_smart(self, user_query, user_filter, negative_keywords, document_text, source_name,
                                     doc_type="EMSAL"):
        found_negative = None
        if negative_keywords:
            doc_lower = document_text.lower()
            for bad in negative_keywords:
                if re.search(rf"\b{re.escape(bad)}\b", doc_lower): found_negative = bad; break

        if found_negative:
            prompt = f"HUKUK√áU. Sorgu: '{user_query}'. Yasaklƒ±: '{found_negative}'. Uygun mu? [RED]/[KABUL]."
            res = self.llm.invoke(prompt).content.strip()
            if "RED" in res: return False, f"‚õî YASAKLI: {res}"

        memory_context = ""
        if self.memory:
            memory_context = self.memory.recall_principles(user_query)

        # [YENƒ∞] Scope bloƒüunun olu≈üturulmasƒ±
        scope_block = self._build_scope_block(user_filter, negative_keywords)

        # V102: DOC TYPE SPECIFIC PROMPT
        if doc_type == "MEVZUAT":
            focus_instruction = "G√ñREV: Bu kanun maddesi, yukarƒ±daki olaya HUKUKƒ∞ DAYANAK (Kanuni Temel) te≈ükil ediyor mu?\nBenzerlik arama, uygulanabilirlik ara."
        else:
            focus_instruction = "G√ñREV: Bu emsal karar, yukarƒ±daki olayla √ñRG√ú VE SONU√á bakƒ±mƒ±ndan BENZER mi?\nOlay benzerliƒüi ara."

        prompt_gen = f"""
SEN KIDEMLI BIR HUKUKCUSSUN.

{scope_block}

{memory_context}

Sorgu: "{user_query}"
Belge ({doc_type}): "{document_text[:700]}..."

{focus_instruction}

SADECE Bƒ∞Rƒ∞Nƒ∞ SE√á: [√áOK BENZER/UYGUN], [BENZER/UYGUN], [ZAYIF/ALAKASIZ]
Altƒ±na tek c√ºmlelik gerek√ße yaz.
"""
        res = self.llm.invoke(prompt_gen).content.strip()
        is_ok = ("√áOK BENZER" in res) or ("BENZER" in res) or ("UYGUN" in res) or ("KABUL" in res)
        return is_ok, res

    def _assign_document_role(self, user_query, document_text):
        prompt = f"""
SEN HUKUK√áUSUN.
Sorgu: "{user_query}"
Belge: "{document_text[:800]}..."
G√ñREV: Bu belge hukuki analizde nasƒ±l kullanƒ±lmalƒ±?
1. [DOƒûRUDAN DELƒ∞L]: Olay √∂rg√ºs√º birebir √∂rt√º≈ü√ºyor.
2. [EMSAL ƒ∞LKE]: Olay farklƒ± ama hukuk kuralƒ± uygulanabilir.
SADECE ≈ûUNLARDAN Bƒ∞Rƒ∞Nƒ∞ SE√á:
[DOƒûRUDAN DELƒ∞L] veya [EMSAL ƒ∞LKE]
"""
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "DOƒûRUDAN" in res: return "[DOƒûRUDAN DELƒ∞L]"
            return "[EMSAL ƒ∞LKE]"
        except:
            return "[EMSAL ƒ∞LKE]"

    def evaluate_candidates(self, candidates, story, topic, negatives):
        print("\n‚öñÔ∏è  Akƒ±llƒ± Yargƒ±√ß Deƒüerlendiriyor (V120: Corporate Intelligence):")
        valid_docs = []

        for hit in candidates:
            doc_text = hit.payload['page_content']
            source = hit.payload['source']
            page = hit.payload['page']
            type_desc = hit.payload['type']

            is_ok, reason = self._check_relevance_judge_smart(story, topic, negatives, doc_text, source, type_desc)

            consensus_multiplier = 1.0
            if self.memory:
                consensus_decision = "KABUL" if is_ok else "RED"
                consensus_multiplier = self.memory.calculate_memory_consensus(source, consensus_decision, hit.score)

            base_score = min(max(hit.score, 0), 1) * 100
            norm_score = min(base_score * consensus_multiplier, 100.0)

            icon = "‚úÖ" if is_ok else "‚ùå"

            if self.memory:
                decision_tag = "KABUL" if is_ok else "RED"
                self.memory.save_decision(f"{story} {topic}", source, decision_tag, reason, type_desc)

            if is_ok:
                role = self._assign_document_role(story, doc_text)

                log_score = f"%{norm_score:.1f}"
                if consensus_multiplier > 1.1:
                    log_score += " (‚¨ÜÔ∏è Y√úKSEK G√úVEN)"
                elif consensus_multiplier < 1.0:
                    log_score += " (‚¨áÔ∏è Rƒ∞SKLƒ∞)"

                print(f"{icon} [{type_desc}] {source:<20} | G√ºven: {log_score} | Rol: {role}")

                extra_context = ""
                if type_desc == "EMSAL KARAR":
                    real_path = os.path.join(LegalConfig.SOURCES["emsal"]["folder"], source)
                    verdict = LegalUtils.extract_pdf_conclusion(real_path)
                    extra_context = f"\n\nüõë [OTOMATƒ∞K EKLENEN KARAR SONUCU ({source})]:\n{verdict}\nüõë KARAR SONU."

                valid_docs.append({
                    "source": source, "page": page, "type": type_desc, "role": role,
                    "text": doc_text + extra_context, "score": norm_score, "reason": reason
                })
            else:
                print(f"{icon} [{type_desc}] {source:<20} | G√ºven: %{norm_score:.1f}")

        return valid_docs

    # [V128 EKLENTƒ∞Sƒ∞] PDF ƒ∞√ßin Emsal A√ßƒ±klama Kartlarƒ±
    def explain_precedents_for_pdf(self, accepted_docs, topic):
        print("\nüìù PDF ƒ∞√ßin Emsal Kartlarƒ± Hazƒ±rlanƒ±yor...")
        cards = []

        # Sadece kabul edilen ve anlamlƒ± rol√º olan belgeleri se√ßiyoruz
        targets = [d for d in accepted_docs if d.get("role") in ["[EMSAL ƒ∞LKE]", "[DOƒûRUDAN DELƒ∞L]"]]

        for doc in targets:
            prompt = f"""
SEN Bƒ∞R T√úRK HUKUK√áUSUSUN.
Ama bu bir KARAR deƒüil, PDF RAPOR A√áIKLAMASIDIR.

KONU: {topic}

BELGE:
- Dosya: {doc['source']}
- Sayfa: {doc['page']}
- Rol: {doc['role']}
- Gerek√ße: {doc.get('reason', '')}

METƒ∞N PAR√áASI:
\"\"\"{doc['text'][:800]}...\"\"\"

G√ñREV:
Bu belgenin neden bu dosya a√ßƒ±sƒ±ndan √∂nemli olduƒüunu,
avukatƒ±n veya m√ºvekkilin rahat√ßa okuyabileceƒüi ≈üekilde a√ßƒ±kla.

KURALLAR:
- Hukuki uydurma YAPMA
- Genel ders anlatƒ±mƒ± YAPMA
- Hakim gibi h√ºk√ºm kurma
- 1 paragrafƒ± ge√ßme
- "Bu belge √∂nemlidir" diye ba≈ülama, direkt i√ßeriƒüe gir.

√áIKTI FORMATI:
**Gerek√ße:** [A√ßƒ±klama]
**ƒ∞√ßerik:** [√ñzet]
"""
            try:
                explanation = self.llm.invoke(prompt).content.strip()
                cards.append({
                    "filename": doc["source"],
                    "page": doc["page"],
                    "role": doc["role"],
                    "content": explanation
                })
            except Exception as e:
                print(f"‚ö†Ô∏è Kart olu≈üturma hatasƒ±: {e}")

        return cards

    # -------------------------------------------------------------------------
    # D√úZELTME 1: JudgeReflex parametresi eklendi ve Prompt kƒ±sƒ±tlandƒ±
    # -------------------------------------------------------------------------
    def generate_final_opinion(self, story, topic, context_str, judge_reflex=None):
        print("\nüßë‚Äç‚öñÔ∏è  AVUKAT YAZIYOR (V120: Final Output)...")

        # Eƒüer JudgeCore sonucu geldiyse prompt'a g√∂m√ºyoruz
        decision_lock = ""
        if judge_reflex:
            decision_lock = f"""
        üõë KESƒ∞N TALƒ∞MAT (JUDGE CORE LOCK):
        Sistem tarafƒ±ndan yapƒ±lan matematiksel analiz sonucunda:
        1. HAKƒ∞M Eƒûƒ∞Lƒ∞Mƒ∞: "{judge_reflex.tendency}" olarak tespit edilmi≈ütir.
        2. DOSYA G√ú√á SKORU: {judge_reflex.score}/100
        3. TESPƒ∞T EDƒ∞LEN TEREDD√úTLER: {', '.join(judge_reflex.doubts)}

        G√ñREVƒ∞N:
        YENƒ∞DEN H√úK√úM KURMAK DEƒûƒ∞L, YUKARIDAKƒ∞ "{judge_reflex.tendency}" HAKƒ∞M Eƒûƒ∞Lƒ∞Mƒ∞Nƒ∞
        hukuki riskler ve gerek√ßeler √ßer√ßevesinde deƒüerlendir.
        Bu bir nihai karar deƒüildir..
        Analizini bu kararƒ± destekleyecek veya bu kararƒ±n risklerini a√ßƒ±klayacak ≈üekilde yap.
        
        ‚ö†Ô∏è UYARI:
        Bu metin mahkeme kararƒ± deƒüildir.
        Hakimin ilk deƒüerlendirme eƒüilimini yansƒ±tan bir analiz raporudur.
        """

        system_content = f"""SEN, T√úRK MAHKEMESƒ∞NDE G√ñREVLƒ∞ Bƒ∞R HAKƒ∞M RAPORT√ñR√úS√úN.
H√úKM√ú SEN VERMƒ∞YORSUN; VERƒ∞LMƒ∞≈û H√úKM√úN GEREK√áESƒ∞Nƒ∞ YAZIYORSUN.
{LegalConfig.PROMPT_GUARD}

üõë KRƒ∞Tƒ∞K VE ZORUNLU KURAL:
BU Sƒ∞STEM SADECE T√úRK√áE √áALI≈ûIR. 

{decision_lock}

HER NE OLURSA OLSUN √áIKTIYI SADECE VE SADECE **T√úRK√áE** Dƒ∞Lƒ∞NDE VER.
(RESPONSE MUST BE ONLY IN TURKISH LANGUAGE. DO NOT USE CHINESE OR ENGLISH.)

G√∂revin:
- Taraflarƒ± savunmak DEƒûƒ∞L
- JudgeCore tarafƒ±ndan belirlenen eƒüilim doƒürultusunda
  RED riskinin nedenleri ve azaltma yollarƒ±nƒ± deƒüerlendir.

NORMLAR Hƒ∞YERAR≈ûƒ∞Sƒ∞ (ZORUNLU):
- [MEVZUAT] etiketli metinler KANUN maddesidir (TMK, BK vb.). Bunlarƒ± kesin kural olarak sun.
- [EMSAL KARAR] etiketli metinler YARGITAY uygulamasƒ±dƒ±r. Bunlarƒ± "yorum ve uygulama" olarak sun.

√ñN KABULLER:
1. Veraset ilamƒ± √ßeki≈ümesiz yargƒ± i≈üidir.
2. √áeki≈ümesiz yargƒ± kararlarƒ± maddi anlamda kesin h√ºk√ºm olu≈üturmaz.
3. Hakim her zaman √∂nce RED ihtimalini deƒüerlendirir.
4. Usul eksikliƒüi varsa ESASA Gƒ∞Rƒ∞LMEZ.
5. Analiz b√∂l√ºm√ºnde en fazla 5 belge kullan.
6. Her belge en fazla 3 c√ºmleyle √∂zetlenir.
7. Aynƒ± belge ikinci kez yazƒ±lamaz.


SANA SAƒûLANAN BELGELER ETƒ∞KETLƒ∞Dƒ∞R:
- [MEVZUAT]
- [EMSAL KARAR]

BELGE DI≈ûINA √áIKMA.
YENƒ∞ EMSAL UYDURMA.
GENEL HUKUK ANLATISI YAPMA.

----------------------------------------------------------------
A≈ûAMA 1 ‚Äî JUDGE CORE DEƒûERLENDƒ∞RMESƒ∞Nƒ∞N HUKUKƒ∞ OKUMASI
----------------------------------------------------------------
UYARI:
Bu a≈üamada YENƒ∞ bir deƒüerlendirme yapma.
Sadece JudgeCore tarafƒ±ndan tespit edilen teredd√ºtleri hukuki dile √ßevir.
Yeni teredd√ºt ekleme.

A≈üaƒüƒ±daki sorularƒ± KENDƒ∞N i√ßin cevapla ve analizini buna g√∂re yap:

- Dosya usulden reddedilebilir mi?
- Hakimin temel teredd√ºt noktalarƒ± neler?
- Sunulan emsal kararlar:
  - Yerle≈üik mi?
  - G√ºncel mi?
  - Somut olayla birebir mi?
- Bu dosyada hakimin takdir alanƒ± var mƒ±?

----------------------------------------------------------------
A≈ûAMA 2 ‚Äî YAPILANDIRILMI≈û HUKUKƒ∞ RAPOR
----------------------------------------------------------------

√áIKTIYI A≈ûAƒûIDAKƒ∞ BA≈ûLIKLARLA VE AYNI SIRAYLA VER.
BA≈ûLIKLARI VE SIRAYI ASLA DEƒûƒ∞≈ûTƒ∞RME.

------------------------------------------------------------
A. MEVZUAT DAYANAKLARI
------------------------------------------------------------
Burada:
- SADECE [MEVZUAT] etiketli belgeleri kullan.
- ƒ∞lgili kanun maddelerini KISA ve NET ≈üekilde √∂zetle.
- Somut olayla doƒürudan baƒülantƒ±yƒ± belirt.
- Yorum yapma, normu a√ßƒ±kla.
- Aynƒ± kanun maddesini birden fazla kez √∂zetleme.
- Her madde numarasƒ±nƒ± sadece bir kez belirt.

------------------------------------------------------------
B. ƒ∞LGƒ∞Lƒ∞ EMSAL KARARLAR (ZORUNLU B√ñL√úM)
------------------------------------------------------------
Burada:
- SADECE [EMSAL KARAR] etiketli belgeleri kullan. En az 2 emsal karar √ñZETLE.
- Her emsal i√ßin:
  - Karar numarasƒ± / tarihi (varsa)
  - Yargƒ±tay dairesi
  - ROL‚Äô√ºn√º belirt (EMSAL ƒ∞LKE / DESTEKLEYƒ∞Cƒ∞ / AYIRT EDƒ∞LEBƒ∞Lƒ∞R)
  - Hakimin bakƒ±≈ü a√ßƒ±sƒ±ndan kƒ±sa GEREK√áE yaz (2-3 c√ºmle)
- Eƒüer emsal yoksa "Somut olayla doƒürudan ilgili g√ºncel emsal karar tespit edilememi≈ütir." yaz.

------------------------------------------------------------
C. SONU√á VE HUKUKƒ∞ TAVSƒ∞YE
------------------------------------------------------------
Burada:
- Kullanƒ±cƒ±nƒ±n anlattƒ±ƒüƒ± somut olaya g√∂re konu≈ü.
- Bulunan emsaller ve mevzuata dayanarak:
  - Dosyanƒ±n ZAYIF y√∂nlerini a√ßƒ±kla
  - G√º√ßlendirilmesi gereken noktalarƒ± belirt
  - Net bir yol haritasƒ± √ßiz (ne yapƒ±lmalƒ± / ne yapƒ±lmamalƒ±)
- ‚Äú≈ûu yapƒ±lƒ±rsa RED riski azalƒ±r‚Äù mantƒ±ƒüƒ±yla yaz.
- Dosyanƒ±n kabul edilme ihtimalini d√º≈ü√ºk/orta/y√ºksek olarak belirt.
- Red riskini azaltmak i√ßin 2-3 somut aksiyon √∂ner.

----------------------------------------------------------------
YASAKLAR:
- Genel hukuk anlatƒ±sƒ±
- Akademik a√ßƒ±klama
- Aynƒ± fikri tekrar etmek
- Belge dƒ±≈üƒ± yorum

SADECE BU DOSYAYI VE SAƒûLANAN BELGELERƒ∞ DEƒûERLENDƒ∞R. CEVABI T√úRK√áE YAZ.
"""

        system_content += "\nSOMUT ATIF ZORUNLULUƒûU: Her emsal/mevzuat atfƒ±nƒ± karar numarasƒ±yla yap (√∂rneƒüin, 'Yargƒ±tay 14. HD 2015/2278 E. kararƒ±nda ƒ±skatƒ±n veraset ilamƒ±nda ≈üerh d√º≈ü√ºlmesi gerektiƒüi belirtilmi≈ütir'). allow_soft_language=False: Subjektif ifadeler yasak."

        user_content = f"""A≈üaƒüƒ±daki "DELƒ∞LLER" listesinde sunulan belgeleri kullanarak olayƒ± analiz et.
OLAY: "{story}"
ODAK: "{topic}"
DELƒ∞LLER:
{context_str}
ANALƒ∞Zƒ∞ BA≈ûLAT (T√úRK√áE):"""

        messages = [SystemMessage(content=system_content), HumanMessage(content=user_content)]

        full_res = ""
        for chunk in self.llm.stream(messages):
            c = chunk.content;
            full_res += c;
            print(c, end="", flush=True)
        print("\n")

        # V120 SANITIZATION
        cleaned_res = self.sanitizer.enforce_no_repeat(full_res)

        if judge_reflex and not _contains_decision(cleaned_res, judge_reflex.tendency):
            cleaned_res = (
                    f"‚ö†Ô∏è JUDGE CORE Eƒûƒ∞Lƒ∞Mƒ∞: {judge_reflex.tendency}\n\n"
                    + cleaned_res
            )

        return cleaned_res


# ==================================================
# üîü RAPORLAMA SINIFI (V120 - ROBUST FONT LOADER)
# ==================================================
class BrandedPDFGenerator(FPDF):
    def __init__(self, branding):
        super().__init__()
        self.branding = branding
        self.font_loaded = False

        # Font Yollarƒ± (√ñncelik Sƒ±rasƒ±)
        possible_paths = [
            "fonts/DejaVuSans.ttf",  # 1. Yerel klas√∂r
            os.path.join(LegalConfig.DRIVE_ROOT, "fonts/DejaVuSans.ttf"),  # 2. Drive klas√∂r√º
            "/content/drive/MyDrive/HukAI/fonts/DejaVuSans.ttf"  # 3. Tam yol (Hardcoded)
        ]

        font_path = None
        for p in possible_paths:
            if os.path.exists(p):
                font_path = p
                break

        # Font Y√ºkleme Denemesi
        if font_path:
            try:
                self.add_font("DejaVu", "", font_path)
                # Bold i√ßin de aynƒ±sƒ±nƒ± veya regular'ƒ± kullan
                bold_path = font_path.replace("Sans.ttf", "Sans-Bold.ttf")
                if os.path.exists(bold_path):
                    self.add_font("DejaVu", "B", bold_path)
                    self.add_font("DejaVu", "BI", bold_path)
                else:
                    self.add_font("DejaVu", "B", font_path)  # Fallback
                    self.add_font("DejaVu", "BI", font_path)  # Fallback

                self.add_font("DejaVu", "I", font_path)
                self.font_loaded = True
                print(f"‚úÖ PDF Fontu Y√ºklendi: {font_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è Font y√ºkleme hatasƒ±: {e}")
        else:
            print(f"‚ö†Ô∏è UYARI: DejaVuSans.ttf bulunamadƒ±! T√ºrk√ße karakterler bozuk √ßƒ±kabilir.")
            print(
                f"   L√ºtfen ≈üu dosyayƒ± indirip 'HukAI/fonts' klas√∂r√ºne koyun: https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans.ttf")

    def header(self):
        if self.branding.logo_path and os.path.exists(self.branding.logo_path):
            self.image(self.branding.logo_path, x=10, y=8, w=30)

        # Font Se√ßimi
        font = "DejaVu" if self.font_loaded else "helvetica"

        self.set_font(font, "B", 12)
        self.set_text_color(*self.branding.color)
        self.cell(0, 10, self.branding.firm_name, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')
        self.set_draw_color(200, 200, 200)
        self.line(10, 25, 200, 25)
        self.ln(15)
        self.set_text_color(0, 0, 0)

    def footer(self):
        self.set_y(-15)
        font = "DejaVu" if self.font_loaded else "helvetica"
        self.set_font(font, 'I', 8)
        self.set_text_color(128, 128, 128)
        self.cell(0, 10, f'{self.branding.footer_text} | Sayfa {self.page_no()}', align='C')


# ==================================================
# 1Ô∏è‚É£2Ô∏è‚É£ Pipeline
# ==================================================
class LegalEvaluationPipeline:
    def __init__(self, judge_core, logic_engine):
        self.judge_core = judge_core
        self.logic_engine = logic_engine

    def run(self, decision_context, persona_outputs):
        # 1Ô∏è‚É£ Deterministik ilk deƒüerlendirme
        initial_reflex = self.judge_core.evaluate(decision_context)

        print(f"   ‚öñÔ∏è  √ñN YARGI√á REFLEKSƒ∞: {initial_reflex.tendency} (Skor: {initial_reflex.score})")

        if initial_reflex.score < 30:
            raise RuntimeError(
                f"Dosya hukuki olarak zayƒ±f (Skor: {initial_reflex.score}). Hakim ilk refleksi RED y√∂n√ºnde. L√ºtfen daha g√º√ßl√º delil veya emsal ile tekrar deneyin.")

        # 2Ô∏è‚É£ Mantƒ±k motoru ile d√ºzeltme
        final_reflex = self.logic_engine.run_logic(
            initial_reflex=initial_reflex,
            persona_outputs=persona_outputs
        )

        return final_reflex



# ==================================================
# ANA UYGULAMA (MAIN APP)
# ==================================================
class LegalApp:
    def __init__(self):
        print("üöÄ LEGAL SUITE V128 (Precedent Layer Added)...")
        self.search_engine = LegalSearchEngine()

        if self.search_engine.connect_db():
            self.memory_manager = LegalMemoryManager(
                self.search_engine.client,
                self.search_engine.dense_embedder,
                ChatOllama(model=LegalConfig.LLM_MODEL, temperature=0.1)
            )
        else:
            self.memory_manager = None

        self.judge = LegalJudge(memory_manager=self.memory_manager)
        # [YENƒ∞] Mantƒ±k Motorunu Ba≈ülat
        self.logic_engine = LegalDecisionLogic()

    def run(self):
        if not self.search_engine.run_indexing():
            self.search_engine.close()
            sys.exit()

        if self.memory_manager:
            self.memory_manager.consolidate_principles_v79()

        print("\n‚úÖ Sƒ∞STEM HAZIR. (√áƒ±kƒ±≈ü: 'q')")

        try:
            while True:
                print("-" * 60)
                story = input("üìù Olay: ");
                if story == 'q': break
                topic = input("üéØ Odak: ")
                neg_input = input("üö´ Yasaklƒ±: ")
                negatives = [w.strip().lower() for w in neg_input.split(",")] if neg_input else []

                print("   üõ°Ô∏è Girdi kontrol ediliyor...")
                if not self.judge.validate_user_input(story, topic):
                    print("   ‚ùå UYARI: Girdi anlamsƒ±z. L√ºtfen mantƒ±klƒ± bir olay giriniz.")
                    continue

                # üî® Commit 5.3: Single Source of Truth
                # Artƒ±k daƒüƒ±nƒ±k deƒüi≈ükenler yerine "QueryContext" nesnesi olu≈üturuyoruz.
                ctx = self.judge.build_query_context(story, topic, negatives)
                print(f"   ‚úì Baƒülam Olu≈üturuldu: {ctx.detected_domain}")

                expanded = self.judge.generate_expanded_queries(ctx.query_text, ctx.topic)
                full_query = f"{ctx.query_text} {ctx.topic} " + " ".join(expanded)
                print(f"   ‚úì Sorgu: {len(full_query)} karakter")

                candidates = self.search_engine.retrieve_raw_candidates(full_query)
                if not candidates: continue

                # Mevcut fonksiyonlara ctx i√ßinden okuyarak g√∂nderiyoruz (Geri uyumluluk)
                valid_docs = self.judge.evaluate_candidates(candidates, ctx.query_text, ctx.topic, ctx.negative_scope)
                if not valid_docs: print("üî¥ Yargƒ±√ß hepsini eledi."); continue

                # [V128 EKLENTƒ∞Sƒ∞] PDF Katmanƒ± i√ßin Veri Hazƒ±rlƒ±ƒüƒ±
                # Ana motor etkilenmez, sadece PDF'e gidecek 'precedent_cards' hazƒ±rlanƒ±r.
                precedent_cards = self.judge.explain_precedents_for_pdf(valid_docs, ctx.topic)

                context_str = ""
                doc_scan_log = []
                for i, d in enumerate(valid_docs):
                    doc_scan_log.append({
                        "source": d['source'], "page": d['page'],
                        "role": d['role'], "reason": d['reason']
                    })

                    # V122 G√úNCELLEME: Emsal ve Mevzuat Ayrƒ±mƒ±
                    is_emsal = "EMSAL" in d['type'].upper()
                    doc_label = "[EMSAL KARAR]" if is_emsal else "[MEVZUAT]"
                    char_limit = 1000 if is_emsal else 800

                    context_str += f"""
                        BELGE #{i + 1}
                        ETƒ∞KET: {doc_label}
                        KAYNAK: {d['source']}
                        T√úR: {d['type']}
                        ROL: {d['role']}
                        YARGI√á GEREK√áESƒ∞: {d['reason']}
                        ƒ∞√áERƒ∞K: {d['text'][:char_limit]}...
                        =========================================
                        """

                current_personas = {}
                mem_principles = []
                if self.memory_manager:
                    # 1. Fonksiyonu √ßalƒ±≈ütƒ±r (String d√∂ner, bunu deƒüi≈ükene atamana gerek yok)
                    self.memory_manager.recall_principles(full_query)

                    # 2. Veriyi 'latest_ui_data' i√ßinden √ßek (S√∂zl√ºk buradadƒ±r)
                    ui_data = self.memory_manager.latest_ui_data

                    # 3. ≈ûimdi .get() kullanabilirsin
                    if ui_data and ui_data.get("principles"):
                        mem_principles = ui_data["principles"]

                        p_data = mem_principles[0]
                        if "personas_v120" in p_data:
                            current_personas = p_data["personas_v120"]
                        else:
                            current_personas = p_data.get("personas", [])

                # üî® Commit 5.4: Decision Context Entegrasyonu
                # Arama ve hafƒ±za sonu√ßlarƒ±nƒ± ortak bir yargƒ±sal zeminde birle≈ütiriyoruz.
                decision_context = DecisionBuilder.build_decision_context_from_valid_docs(valid_docs)
                decision_context = DecisionBuilder.enrich_decision_context_with_memory(decision_context, mem_principles)

                if not decision_context.has_minimum_legal_basis():
                    print("üî¥ KRƒ∞Tƒ∞K UYARI: Yeterli hukuki belge veya ilke bulunamadƒ±. Analiz durduruluyor.")
                    continue

                # üî® Commit 5.5: Judge Core (Deterministik Akƒ±l)
                # LLM'e gitmeden √∂nce dosyanƒ±n g√ºc√ºn√º matematiksel olarak √∂l√ß√ºyoruz.

                judge_core_instance = JudgeCore()
                reflex = judge_core_instance.evaluate(decision_context)

                print(f"   ‚öñÔ∏è  √ñN YARGI√á REFLEKSƒ∞: {reflex.tendency} (Skor: {reflex.score})")

                if reflex.score < 30:
                    print(f"üî¥ Dosya hukuki olarak √ßok zayƒ±f (Skor: {reflex.score}). Analiz durduruluyor.")
                    continue

                # üî® Commit 5.6: Persona Engine (Kontroll√º LLM)
                # Hakim teredd√ºtlerine cevap veren yeni persona motoru
                llm_for_persona = ChatOllama(model=LegalConfig.LLM_MODEL, temperature=0.7)  # Biraz daha yaratƒ±cƒ±
                persona_engine = PersonaEngine(llm_for_persona)

                persona_outputs = persona_engine.run(ctx, decision_context, reflex)

                # =========================================================
                # üß† ADIM 1-8: MANTIK MOTORU VE SKOR D√úZELTME
                # =========================================================
                # LLM'in √ºrettiƒüi metinlere bakarak kararƒ± matematiksel olarak g√ºncelle
                # reflex nesnesini EZƒ∞YORUZ (Overwrite)
                reflex = self.logic_engine.run_logic(
                    initial_reflex=reflex,
                    persona_outputs=persona_outputs
                )
                # PDF Raporu i√ßin persona verilerini g√ºncelle
                # (Eski hafƒ±za verilerini ezerek g√ºncel duruma g√∂re cevap veriyoruz)
                current_personas = {
                    "judge_reflex": reflex.tendency,
                    "doubts": reflex.doubts,
                    "plaintiff": next((p.response for p in persona_outputs if "DAVACI" in p.role), "Beyan yok"),
                    "defendant": next((p.response for p in persona_outputs if "DAVALI" in p.role), "Beyan yok"),
                    "expert": next((p.response for p in persona_outputs if "Bƒ∞Lƒ∞RKƒ∞≈ûƒ∞" in p.role), "Beyan yok")
                }

                # üî® Commit 5.7: Action Engine (Somut G√º√ßlendirme)
                action_engine = ActionEngine(llm_for_persona)  # Reuse LLM
                strengthening_actions = action_engine.run(reflex, persona_outputs)

                # Avukat Masasƒ± (Konsol √áƒ±ktƒ±sƒ±)
                if strengthening_actions:
                    print(f"\n   üõ†Ô∏è  G√ú√áLENDƒ∞RME AKSƒ∞YONLARI ({len(strengthening_actions)} Adet):")
                    for act in strengthening_actions:
                        print(f"      üîπ [{act.impact_score}/10] {act.title}: {act.description[:100]}...")

                full_advice = self.judge.generate_final_opinion(ctx.query_text, ctx.topic, context_str,judge_reflex=reflex)

                # =========================================================
                # üöÄ COMMIT 6.0 ENTEGRASYONU: RAPOR ORKESTRASYONU
                # =========================================================

                print("\nüñ®Ô∏è  Raporlama S√ºreci Ba≈ülatƒ±lƒ±yor...")

                # 1. Orkestrat√∂r√º Hazƒ±rla
                # ƒ∞sterseniz buraya ClientSummaryPDF() de ekleyebilirsiniz listeye.
                report_orchestrator = ReportOrchestrator(
                    reporters=[
                        LegacyPDFReport(),  # pdf_reports.py i√ßindeki basit legacy
                        JudicialPDFReport()  # pdf_reports.py i√ßindeki geli≈ümi≈ü judicial
                    ]
                )

                # 2. T√ºm Raporlarƒ± Tek Seferde √úret
                # Not: decision_context (d_ctx) i√ßinden documents listesini √ßekiyoruz.
                pdf_paths = report_orchestrator.generate_all(
                    context=ctx,  # QueryContext
                    judge_reflex=reflex,  # JudgeReflex (Commit 5.5)
                    persona_outputs=persona_outputs,  # List[PersonaResponse] (Commit 5.6)
                    actions=strengthening_actions,  # List[StrengtheningAction] (Commit 5.7)
                    documents=decision_context.documents  # DecisionContext (Commit 5.4)
                )

                # 3. Sonu√ßlarƒ± Bildir
                for path in pdf_paths:
                    print(f"   ‚úÖ Rapor √úretildi: {path}")

                # 4. M√º≈üteri √ñzeti (Opsiyonel - Veri varsa)
                # Not: client_summary objesi ≈üu an kodda √ºretilmiyor,
                # eƒüer √ºretirseniz burayƒ± a√ßabilirsiniz.
                """
                client_pdf = ClientSummaryPDF()
                client_pdf.generate(client_summary=client_summary_objesi)
                """

                # 5. Konsol Tablosu (Commit 5.2)
                audit_dump = {}
                if self.memory_manager and hasattr(self.memory_manager, 'latest_ui_data'):
                    audit_dump = self.memory_manager.latest_ui_data.get("audit_log", {})

                print("\nüìä ƒ∞≈ûLEM ZAMAN √áƒ∞ZELGESƒ∞:")
                for log in audit_dump.get("timeline", []):
                    print(f"   {log['timestamp']} | {log['title']} ‚Üí {log['description']}")

        except KeyboardInterrupt:
            print("\nüëã Program durduruldu.")
        except Exception as e:
            print(f"\n‚ö†Ô∏è Hata: {e}")
        finally:
            self.search_engine.close()


if __name__ == "__main__":
    freeze_support()
    app = LegalApp()
    app.run()