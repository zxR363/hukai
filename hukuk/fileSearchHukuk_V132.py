import sys
import os
import re
import uuid
import time
import shutil
import atexit
import json
import random
import math
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime
from multiprocessing import Pool, cpu_count, freeze_support
from dataclasses import dataclass, field
from collections import Counter

# --------------------------------------------------
# ğŸ“¦ IMPORTLAR
# --------------------------------------------------
import fitz  # PyMuPDF
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_core.messages import SystemMessage, HumanMessage
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance, Filter, FieldCondition, MatchValue, Range
from fpdf import FPDF
from fpdf.enums import XPos, YPos
from langchain_community.document_loaders import PyMuPDFLoader


# PDF CIKTILARI Mevcut importlarÄ±n altÄ±na ekleyin
from pdf_reports import (
    LegacyPDFReport,
    JudicialPDFReport,
    ClientSummaryPDF,  # EÄŸer kullanacaksanÄ±z
    ReportOrchestrator
)


# UTF-8 AyarÄ±
# sys.stdout.reconfigure(encoding="utf-8")


# ==================================================
# 1ï¸âƒ£ KONFÄ°GÃœRASYON VE BAÄLAM SINIFLARI
# ==================================================

# ğŸ”¨ Commit 5.3: Query Context (Single Source of Truth)
@dataclass
class QueryContext:
    """
    Sistemde TEK baÄŸlayÄ±cÄ± baÄŸlam nesnesi.
    TÃ¼m modÃ¼ller yalnÄ±zca bunu referans alÄ±r.
    """
    # KullanÄ±cÄ± girdisi
    query_text: str

    # Hukuki baÄŸlam
    topic: str
    detected_domain: str  # Ã¶rn: "miras", "icra", "ceza"

    # Kapsam sÄ±nÄ±rlarÄ±
    negative_scope: List[str]
    allowed_sources: List[str] = None

    # Sistem iÃ§i bayraklar
    allow_analogy: bool = False
    allow_speculation: bool = False
    allow_soft_language: bool = False

    # ğŸ†• EKLENECEK SATIR (Guard BayraÄŸÄ±)
    judge_evaluated: bool = False

    def assert_hard_limits(self):
        """
        Hukuki gÃ¼venlik kemeri.
        """
        if self.allow_speculation:
            raise ValueError("Speculation is forbidden in legal analysis.")

        if self.allow_analogy:
            raise ValueError("Analogy is forbidden unless explicitly enabled.")


# ğŸ”¨ Commit 5.4: Decision Context (YargÄ±sal Zemin)
@dataclass
class DecisionContext:
    """
    Hakim ve LLM iÃ§in ortak, temiz ve sÃ¼zÃ¼lmÃ¼ÅŸ karar zemini.
    Bu nesne oluÅŸmadan LLM Ã‡AÄRILAMAZ.
    """

    # Kaynaklar
    documents: List[Dict[str, Any]] = field(default_factory=list)
    principles: List[Dict[str, Any]] = field(default_factory=list)

    # Analitik katman
    relevance_scores: Dict[str, float] = field(default_factory=dict)
    conflicts: List[str] = field(default_factory=list)

    def has_minimum_legal_basis(self) -> bool:
        """
        Hukuki tartÄ±ÅŸma yapÄ±labilmesi iÃ§in asgari eÅŸik.
        """
        return bool(self.documents) or bool(self.principles)


# ğŸ”¨ Commit 5.5: Judge Reflex (Refleks Veri YapÄ±sÄ±)
@dataclass
class JudgeReflex:
    """
    Hakimin ilk refleksi.
    """
    tendency: str  # "KABUL" | "RED" | "TEREDDÃœT"
    score: int  # 0â€“100
    doubts: List[str]  # Hakimin kafasÄ±na takÄ±lanlar


# ğŸ”¨ Commit 5.6: Persona Response (Persona Ã‡Ä±ktÄ± Modeli)
@dataclass
class PersonaResponse:
    role: str  # DAVACI | DAVALI | BILIRKISI
    response: str
    addressed_doubts: List[str]


# ğŸ”¨ Commit 5.7: Strengthening Action (Aksiyon Modeli)
@dataclass
class StrengtheningAction:
    title: str
    description: str
    related_doubt: str
    impact_score: int  # 1â€“10 arasÄ± katkÄ± puanÄ±


@dataclass
class LegalConfig:
    # Google Drive Ana Yolu (HukAI KlasÃ¶rÃ¼)
    # DRIVE_ROOT = "/content/drive/MyDrive/HukAI"
    DRIVE_ROOT = os.path.dirname(os.path.abspath(__file__))

    SOURCES = {
        "mevzuat": {
            "folder": os.path.join(DRIVE_ROOT, "mevzuatlar"),
            "collection": "legal_statutes_v48",
            "desc": "MEVZUAT"
        },
        "emsal": {
            "folder": os.path.join(DRIVE_ROOT, "belgeler"),
            "collection": "legal_precedents_v48",
            "desc": "EMSAL KARAR"
        }
    }

    MEMORY_COLLECTIONS = {
        "decision": "judge_memory_v1",
        "principle": "principle_memory_v1"
    }

    # VeritabanÄ±nÄ± da HukAI iÃ§ine kaydediyoruz (KalÄ±cÄ± HafÄ±za)
    QDRANT_PATH = os.path.join(DRIVE_ROOT, "qdrant_db_master")

    # Sistem durum dosyasÄ± da burada
    STATE_FILE = os.path.join(DRIVE_ROOT, "system_state.json")

    EMBEDDING_MODEL = "nomic-embed-text"
    LLM_MODEL = "qwen2.5"

    # V120: YENÄ° LLM PARAMETRELERÄ° (GLOBAL KALÄ°TE KONTROL)
    LLM_CONFIG = {
        "temperature": 0.4,
        "top_p": 0.9,
        "repeat_penalty": 1.2,  # frequency_penalty karÅŸÄ±lÄ±ÄŸÄ± (Ollama/Llama)
        "num_predict": 1200  # max_tokens karÅŸÄ±lÄ±ÄŸÄ±
    }

    # V124: GÃœÃ‡LENDÄ°RÄ°LMÄ°Å PROMPT GUARD
    PROMPT_GUARD = """
ZORUNLU YAZIM VE AKIL YÃœRÃœTME KURALLARI:

1. SADECE verilen olay, scope ve hukuki baÄŸlam iÃ§inde kal.
2. Genel hukuk bilgisi, Ã¶ÄŸretici anlatÄ±m veya akademik aÃ§Ä±klama YAPMA.
3. â€œGenel olarakâ€, â€œÃ§oÄŸunluklaâ€, â€œdoktrindeâ€ gibi belirsiz ifadeler KULLANMA.
4. AynÄ± hukuki ilkeyi veya TMK/YargÄ±tay maddesini BÄ°R KEZ aÃ§Ä±kla.
5. AynÄ± dÃ¼ÅŸÃ¼nceyi farklÄ± kelimelerle TEKRAR ETME.
6. Somut olayla baÄŸlantÄ±sÄ± olmayan hiÃ§bir bilgi EKLEME.
7. Emsal yoksa uydurma; belirsizlik varsa AÃ‡IKÃ‡A belirt.
8. DeÄŸer yargÄ±sÄ±, ahlaki yorum, sosyal politika yorumu YAPMA.
9. â€œBu durumda karar verilmelidirâ€ gibi HÃœKÃœM KURAN ifadeler kullanma.
10. Hakim, avukat veya bilirkiÅŸi rolÃ¼ dÄ±ÅŸÄ±nda dÃ¼ÅŸÃ¼nme.
11. Ã‡Ä±ktÄ±, gerÃ§ek bir mahkeme dosyasÄ±na girebilecek ciddiyette olsun.
12. Bu kurallarÄ±n dÄ±ÅŸÄ±na Ã§Ä±kma; Ã§Ä±ktÄ±yÄ± bu kurallara gÃ¶re DENETLE.
13.Her belge yalnÄ±zca bir kez Ã¶zetlenir.Ã–zet, sorgudaki somut olayla doÄŸrudan baÄŸ kurmak zorundadÄ±r.
"Bu belge, sorgudaki [X] durumuna ÅŸu ÅŸekilde uygulanÄ±r: ..." formatÄ± zorunludur.
14.Belge â†’ Hukuki Ä°lke â†’ Somut Olay â†’ Dosyaya Etki zinciri kurulmadan belge kullanÄ±lamaz.
"""

    # --- V120: CORE RULE REGISTRY (YAML SIMULATION) ---
    # Harici dosya okuma mantÄ±ÄŸÄ± eklendiÄŸinde burasÄ± fallback olur.
    CORE_RULES_DB = {
        "miras_hukuku": {
            "description": "Miras ve Ã§ekiÅŸmesiz yargÄ± iÅŸleri",
            "rules": [
                {
                    "id": "CR_MIRAS_001",
                    "rule": "Veraset ilamÄ± Ã§ekiÅŸmesiz yargÄ± iÅŸidir.",
                    "effect": "Maddi anlamda kesin hÃ¼kÃ¼m oluÅŸturmaz.",
                    "applies_to": ["judge", "risk", "persona"]
                },
                {
                    "id": "CR_MIRAS_002",
                    "rule": "MirasÃ§Ä±lÄ±k belgesi aksi ispat edilinceye kadar geÃ§erlidir.",
                    "effect": "Ä°ptal davasÄ± aÃ§Ä±labilir.",
                    "applies_to": ["judge"]
                }
            ]
        },
        "ceza_hukuku": {
            "description": "Ceza yargÄ±lamasÄ±na iliÅŸkin temel ilkeler",
            "rules": [
                {
                    "id": "CR_CEZA_001",
                    "rule": "ÅÃ¼pheden sanÄ±k yararlanÄ±r (In Dubio Pro Reo).",
                    "effect": "Delil yetersizliÄŸi halinde beraat esastÄ±r.",
                    "applies_to": ["judge", "risk"]
                },
                {
                    "id": "CR_CEZA_002",
                    "rule": "Ceza hukukunda kÄ±yas yasaÄŸÄ± esastÄ±r.",
                    "effect": "Kanunsuz suÃ§ ve ceza olmaz, aleyhe yorum yapÄ±lamaz.",
                    "applies_to": ["judge"]
                }
            ]
        },
        "is_hukuku": {
            "description": "Ä°ÅŸ hukuku ve iÅŸÃ§i-iÅŸveren iliÅŸkileri",
            "rules": [
                {
                    "id": "CR_IS_001",
                    "rule": "Ä°ÅŸ hukukunda iÅŸÃ§i lehine yorum ilkesi esastÄ±r.",
                    "effect": "Mevzuat boÅŸluklarÄ±nda iÅŸÃ§i yararÄ± gÃ¶zetilir.",
                    "applies_to": ["judge", "persona"]
                }
            ]
        },
        "genel_hukuk": {
            "description": "Genel hukuk ilkeleri",
            "rules": [
                {
                    "id": "CR_GENEL_001",
                    "rule": "Ä°ddia eden iddiasÄ±nÄ± ispatla mÃ¼kelleftir.",
                    "effect": "Ä°spat yÃ¼kÃ¼ kural olarak davacÄ±dadÄ±r.",
                    "applies_to": ["judge", "risk"]
                }
            ]
        }
    }

    SEARCH_LIMIT_PER_SOURCE = 60
    SCORE_THRESHOLD = 0.35
    LLM_RERANK_LIMIT = 10

    DECAY_RATE_PER_MONTH = 0.98
    PRINCIPLE_MERGE_THRESHOLD = 0.90
    MIN_CONFIDENCE_THRESHOLD = 0.55


# ==================================================
# 2ï¸âƒ£ YARDIMCI ARAÃ‡LAR (STATIC)
# ==================================================
def _contains_decision(text: str, decision: str) -> bool:
    text = text.upper()
    decision = decision.upper()

    if decision == "KABUL":
        return "KABUL" in text or "KABUL EDÄ°L" in text
    if decision == "RED":
        return "RED" in text or "REDDEDÄ°L" in text
    return False

def worker_embed_batch_global(args):
    """Multiprocessing iÃ§in global kalmalÄ±."""
    texts, model_name = args
    try:
        embedder = OllamaEmbeddings(model=model_name)
        return embedder.embed_documents(texts)
    except Exception as e:
        print(f"âš ï¸ Batch hatasÄ± (atlanÄ±yor): {e}")
        return []


# ğŸ”¨ Commit 5.4: Decision Builder (AdaptÃ¶r)
class DecisionBuilder:
    """
    Sistemin farklÄ± Ã§Ä±ktÄ±larÄ±ndan DecisionContext inÅŸa eden yardÄ±mcÄ± sÄ±nÄ±f.
    """

    @staticmethod
    def build_decision_context_from_valid_docs(valid_docs: list) -> DecisionContext:
        """
        LegalJudge tarafÄ±ndan filtrelenmiÅŸ 'valid_docs' listesini alÄ±r.
        """
        context = DecisionContext()

        for doc in valid_docs:
            # ID yoksa geÃ§ici Ã¼ret, varsa kullan
            doc_id = str(uuid.uuid4())

            context.documents.append({
                "id": doc_id,
                "type": doc.get("type"),  # EMSAL / MEVZUAT
                "source": doc.get("source"),
                "confidence": doc.get("score"),  # Judge skoru (0-100)
                "content": doc.get("text"),
                "role": doc.get("role"),
                "reason": doc.get("reason")
            })

            context.relevance_scores[doc_id] = doc.get("score", 0.0)

        return context

    @staticmethod
    def enrich_decision_context_with_memory(context: DecisionContext, memory_principles: list) -> DecisionContext:
        """
        HafÄ±zadan gelen ilkeleri Context'e ekler.
        """
        if not memory_principles:
            return context

        for principle in memory_principles:
            context.principles.append({
                "principle": principle.get("text"),
                "confidence": principle.get("score_data", {}).get("success_probability", 0),
                "source": "memory_v1",
                "trend": principle.get("trend_log", "")
            })

        return context


# ğŸ”¨ Commit 5.5: Judge Core (Deterministik AkÄ±l)
class JudgeCore:
    """
    LLM'siz, deterministik hakim muhakemesi.
    """

    def evaluate(self, decision_context: DecisionContext) -> JudgeReflex:
        score = 0
        doubts = []

        # 1ï¸âƒ£ Belgelerden gelen gÃ¼Ã§
        for doc in decision_context.documents:
            # Skorlar 0-100 arasÄ±nda geliyordu, burada normalize edip topluyoruz
            conf = doc.get("confidence", 0)
            if conf >= 90:
                score += 15
            elif conf >= 80:
                score += 10
            elif conf >= 70:
                score += 5
            else:
                doubts.append(
                    f"DÃ¼ÅŸÃ¼k gÃ¼venli belge: {doc.get('source')}"
                )

        # 2ï¸âƒ£ Hukuki ilkeler
        for principle in decision_context.principles:
            conf = principle.get("confidence", 0)  # 0-100 arasÄ± success probability
            if conf >= 85:
                score += 10
            elif conf < 60:
                doubts.append(
                    "ZayÄ±f iÃ§tihat/ilke tespiti"
                )

        # 3ï¸âƒ£ Skoru sÄ±nÄ±rla
        score = min(score, 100)

        # 4ï¸âƒ£ Hakim refleksi
        if score >= 70:
            tendency = "KABUL"
        elif score <= 40:
            tendency = "RED"
        else:
            tendency = "TEREDDÃœT"

        return JudgeReflex(
            tendency=tendency,
            score=score,
            doubts=doubts
        )


# ğŸ”¨ Commit 5.6: Persona Engine (KontrollÃ¼ LLM)
class PersonaEngine:
    """
    LLM kontrollÃ¼ persona simÃ¼lasyonu.
    Hakimin tereddÃ¼tlerine cevap Ã¼retir.
    """

    def __init__(self, llm):
        self.llm = llm
        self.current_doubts = []

    def run(
            self,
            context: QueryContext,
            decision_context: DecisionContext,
            judge_reflex: JudgeReflex
    ) -> List[PersonaResponse]:

        self.current_doubts = judge_reflex.doubts
        if not self.current_doubts:
            # TereddÃ¼t yoksa standart bir baÅŸlangÄ±Ã§ ata
            self.current_doubts = ["DosyanÄ±n esasÄ±na iliÅŸkin genel delil durumu", "Hukuki tavsif"]

        print(f"   ğŸ—£ï¸  Persona TartÄ±ÅŸmasÄ± BaÅŸlatÄ±lÄ±yor ({len(self.current_doubts)} TereddÃ¼t)...")
        responses = []

        responses.append(
            self._invoke_persona(
                role="DAVACI VEKÄ°LÄ°",
                instruction="Hakimin tereddÃ¼tlerini gider, davanÄ±n kabulÃ¼ iÃ§in argÃ¼man Ã¼ret."
            )
        )

        responses.append(
            self._invoke_persona(
                role="DAVALI VEKÄ°LÄ°",
                instruction="Hakimin tereddÃ¼tlerini derinleÅŸtir, davanÄ±n reddi iÃ§in itiraz et."
            )
        )

        responses.append(
            self._invoke_persona(
                role="BÄ°LÄ°RKÄ°ÅÄ°",
                instruction="TereddÃ¼tlerin hukuki tutarlÄ±lÄ±ÄŸÄ±nÄ± ve delil zincirini denetle."
            )
        )

        return responses

    def _invoke_persona(self, role: str, instruction: str) -> PersonaResponse:
        prompt = f"""
        ROL: {role}
        BAÄLAM: TÃ¼rk Hukuku.
        {LegalConfig.PROMPT_GUARD}

        GÃ–REV:
        {instruction}

        HAKÄ°MÄ°N SOMUT TEREDDÃœTLERÄ°:
        {self._format_doubts()}

        SINIRLAR:
        - Yeni hukuki kural Ã¼retme.
        - Hakim kararÄ±nÄ± deÄŸiÅŸtirmeye Ã§alÄ±ÅŸma (Sadece ikna et/eleÅŸtir).
        - Skor veya oran verme.
        - Sadece yukarÄ±daki tereddÃ¼tlere odaklan.

        Ã‡IKTI:
        - Net, hukuki dilde, maksimum 2 paragraf.
        """

        try:
            result = self.llm.invoke(prompt).content.strip()
        except:
            result = f"{role}: Beyan oluÅŸturulamadÄ±."

        return PersonaResponse(
            role=role,
            response=result,
            addressed_doubts=self.current_doubts
        )

    def _format_doubts(self):
        return "\n".join(f"- {d}" for d in self.current_doubts)


# ğŸ”¨ Commit 5.7: Action Engine
class ActionEngine:
    """
    Hakim tereddÃ¼tlerini azaltmaya yÃ¶nelik
    somut hukuki aksiyonlar Ã¼retir.
    """

    def __init__(self, llm):
        self.llm = llm

    def run(
            self,
            judge_reflex: JudgeReflex,
            persona_outputs: List[PersonaResponse]
    ) -> List[StrengtheningAction]:

        if not judge_reflex.doubts:
            return []

        actions = []

        for doubt in judge_reflex.doubts:
            action = self._generate_action(doubt, persona_outputs)
            if action:
                actions.append(action)

        return actions

    def _generate_action(
            self,
            doubt: str,
            persona_outputs: List[PersonaResponse]
    ) -> StrengtheningAction:

        persona_context = "\n\n".join(
            f"{p.role}: {p.response}"
            for p in persona_outputs
            # EÄŸer persona cevabÄ±nda bu doubt geÃ§iyorsa al, yoksa hepsini al (basit eÅŸleÅŸme)
            if True
        )

        prompt = f"""
        HAKÄ°M TEREDDÃœDÃœ:
        {doubt}

        PERSONA DEÄERLENDÄ°RMELERÄ°:
        {persona_context}

        GÃ–REV:
        Bu tereddÃ¼dÃ¼ azaltmak iÃ§in yapÄ±labilecek
        TEK ve SOMUT hukuki aksiyonu yaz.

        SINIRLAR:
        - Tavsiye tonu kullanma
        - Genel laf Ã¼retme
        - En fazla 3 cÃ¼mle

        FORMAT:
        BaÅŸlÄ±k:
        AÃ§Ä±klama:
        Etki PuanÄ± (1-10):
        """

        try:
            result = self.llm.invoke(prompt).content
            return self._parse_action(result, doubt)
        except:
            return None

    def _parse_action(self, text: str, doubt: str) -> StrengtheningAction:
        lines = text.splitlines()

        title = "Ek Delil Sunumu"
        description = "Ä°lgili hususta ek delil sunulmalÄ±dÄ±r."
        impact = 5

        for line in lines:
            if "BaÅŸlÄ±k" in line:
                parts = line.split(":", 1)
                if len(parts) > 1: title = parts[1].strip()
            elif "AÃ§Ä±klama" in line:
                parts = line.split(":", 1)
                if len(parts) > 1: description = parts[1].strip()
            elif "Etki" in line:
                try:
                    # Sadece rakamlarÄ± al
                    impact = int("".join(filter(str.isdigit, line)))
                    # 10'dan bÃ¼yÃ¼kse (Ã¶rn 810) son basamaÄŸÄ± al veya 10 yap
                    if impact > 10: impact = 5
                except:
                    impact = 5

        return StrengtheningAction(
            title=title,
            description=description,
            related_doubt=doubt,
            impact_score=impact
        )


class LegalUtils:
    @staticmethod
    def force_unlock_db():
        lock_file = os.path.join(LegalConfig.QDRANT_PATH, ".lock")
        if os.path.exists(lock_file):
            try:
                os.remove(lock_file);
                print("ğŸ”“ KÄ°LÄ°T DOSYASI TEMÄ°ZLENDÄ°.")
            except:
                pass

    @staticmethod
    def extract_pdf_conclusion(file_path, char_limit=2500):
        try:
            if not os.path.exists(file_path): return "[Dosya bulunamadÄ±.]"
            doc = fitz.open(file_path)
            total_pages = len(doc)
            text = "";
            start_page = max(0, total_pages - 2)
            for i in range(start_page, total_pages): text += doc[i].get_text()
            doc.close();
            return text[-char_limit:]
        except Exception as e:
            return f"[Karar okunamadÄ±: {e}]"

    @staticmethod
    def clean_text(text):
        text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text


# --- V121: ADVANCED LOOP BREAKER ---
class LegalTextSanitizer:
    """V121: GeliÅŸmiÅŸ Tekrar Engelleyici (Madde BazlÄ±)"""

    def __init__(self):
        self.seen_sentences = set()
        self.written_articles = set()  # YENÄ°: Madde numaralarÄ±nÄ± takip et
        self.dropped_count = 0

    def enforce_no_repeat(self, text):

        PROTECTED_PREFIXES = (
            "âš ï¸",
            "A.",
            "B.",
            "C.",
            "------------------------------------------------",
        )

        """Metindeki anlamsal tekrarlarÄ± ve aynÄ± kanun maddelerini temizler."""
        if not text: return ""

        # Markdown baÅŸlÄ±klarÄ±nÄ± koru, iÃ§eriÄŸi satÄ±r satÄ±r bÃ¶l
        lines = text.split("\n")
        cleaned_lines = []

        for line in lines:
            if clean_line.startswith(PROTECTED_PREFIXES):
                cleaned_lines.append(line)
                continue

            clean_line = line.strip()
            if len(clean_line) < 5:  # Ã‡ok kÄ±sa satÄ±rlarÄ± (boÅŸluk vb.) geÃ§
                cleaned_lines.append(line)
                continue

            # --- V121 GÃœNCELLEME: Madde NumarasÄ± KontrolÃ¼ ---
            # "Madde 598", "Md. 598", "TMK m. 598" gibi yapÄ±larÄ± yakalar.
            article_match = re.search(
                r'(?:(TMK|HMK|BK|TBK|CMK)\s*)?(?:Madde|Md\.|m\.)\s*(\d+)',
                clean_line,
                re.IGNORECASE
            )
            if article_match:
                article_num = article_match.group(1)  # Sadece numarayÄ± al (Ã¶rn: "598")
                if article_num in self.written_articles:
                    self.dropped_count += 1
                    continue  # AynÄ± madde numarasÄ± daha Ã¶nce yazÄ±ldÄ±ysa atla
                self.written_articles.add(article_num)
            # ------------------------------------------------

            # CÃ¼mlenin "Ã¶zÃ¼nÃ¼" (ilk 80 karakter) anahtar yap
            # Bu sayede "MirasÃ§Ä±lÄ±k belgesi..." ile "MirasÃ§Ä±lÄ±k belgesinin..." aynÄ± sayÄ±lÄ±r
            key = re.sub(r'\s+', ' ', clean_line.lower())
            key = re.sub(r'[^\w\s]', '', key)[:80]

            if key in self.seen_sentences:
                self.dropped_count += 1
                continue  # BU SATIRI ATLA (TEKRAR)

            self.seen_sentences.add(key)
            cleaned_lines.append(line)

        return "\n".join(cleaned_lines)

    def reset(self):
        self.seen_sentences = set()
        self.written_articles = set()  # Reset iÅŸleminde burayÄ± da temizle
        self.dropped_count = 0


# ==================================================
# 3ï¸âƒ£ LEGAL AUDIT LOGGER
# ==================================================
class LegalAuditLogger:
    """
    Sistemin verdiÄŸi tÃ¼m kararlarÄ±n izlenebilir, aÃ§Ä±klanabilir ve UI-uyumlu log kaydÄ±.
    """

    def __init__(self, case_id: str | None = None):
        self.case_id = case_id or str(uuid.uuid4())
        self.started_at = time.time()
        self.logs: List[Dict[str, Any]] = []
        self._step_counter = 0

    def log_event(
            self,
            stage: str,
            title: str,
            description: str,
            inputs: Dict[str, Any] | None = None,
            outputs: Dict[str, Any] | None = None,
            score_impact: int | float | None = None,
            resulting_score: int | float | None = None,
            confidence: str | None = None,
    ):
        """
        Sistemdeki HER anlamlÄ± adÄ±m buradan geÃ§er
        """
        self._step_counter += 1

        event = {
            "step": self._step_counter,
            "timestamp": time.time(),
            "stage": stage,
            "title": title,
            "description": description,
            "inputs": inputs or {},
            "outputs": outputs or {},
        }

        if score_impact is not None:
            event["score_impact"] = score_impact

        if resulting_score is not None:
            event["resulting_score"] = resulting_score

        if confidence is not None:
            event["confidence"] = confidence

        self.logs.append(event)

    def export(self) -> Dict[str, Any]:
        """
        UI / API / Storage iÃ§in tek JSON
        """
        return {
            "case_id": self.case_id,
            "started_at": self.started_at,
            "completed_at": time.time(),
            "timeline": self.logs,
        }


# ==================================================
# 4ï¸âƒ£ ACTIONABLE RECOMMENDATION ENGINE
# ==================================================
class ActionableRecommendationEngine:
    # 1. Sabit Profil HaritasÄ± (Safety Layer)
    RECOMMENDATION_PROFILE = {
        "DELIL": {
            "evidence_type": ["tanÄ±k", "belge", "bilirkiÅŸi", "keÅŸif", "yemin"],
            "priority": "YÃœKSEK",
            "estimated_cost": "Orta",
            "time_impact": "Orta",
            "base_score_range": (5, 10)
        },
        "ICTIHAT": {
            "evidence_type": ["emsal karar", "HGK kararÄ±", "Ä°BK"],
            "priority": "ORTA",
            "estimated_cost": "DÃ¼ÅŸÃ¼k",
            "time_impact": "KÄ±sa",
            "base_score_range": (3, 7)
        },
        "USUL": {
            "evidence_type": ["dilekÃ§e", "itiraz", "sÃ¼re tutum"],
            "priority": "YÃœKSEK",
            "estimated_cost": "DÃ¼ÅŸÃ¼k",
            "time_impact": "KÄ±sa",
            "base_score_range": (2, 4)
        },
        "TALEP_DARALTMA": {
            "evidence_type": ["strateji"],
            "priority": "ORTA",
            "estimated_cost": "DÃ¼ÅŸÃ¼k",
            "time_impact": "KÄ±sa",
            "base_score_range": (4, 6)
        }
    }

    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_concerns, query_text=""):
        recommendations = []
        for concern in judge_concerns:
            category = self._classify_concern(concern)
            if not category: category = "DELIL"

            profile = self.RECOMMENDATION_PROFILE.get(category, self.RECOMMENDATION_PROFILE["DELIL"])
            rec_text = self._generate_recommendation_text(concern, self._category_to_turkish(category))
            score_boost = random.randint(profile["base_score_range"][0], profile["base_score_range"][1])
            source_detail = self._infer_source(concern, query_text)

            recommendations.append({
                "action_id": str(uuid.uuid4()),
                "title": rec_text.split(".")[0][:80] + "...",
                "description": rec_text,
                "category": category,
                "focus": category,
                "evidence": {
                    "type": self._pick_evidence(profile["evidence_type"]),
                    "source": source_detail,
                    "count": self._estimate_count(category)
                },
                "priority": profile["priority"],
                "estimated_cost": profile["estimated_cost"],
                "time_impact": profile["time_impact"],
                "risk_reduction": {
                    "area": self._category_to_turkish(category),
                    "expected_score_increase": score_boost
                },
                "suggestion": rec_text,
                "if_not_done": self._generate_risk_note(concern),
                "why": concern
            })
        return recommendations

    def _infer_source(self, concern, query_text):
        concern_lower = concern.lower()
        query_lower = query_text.lower()

        if "miras" in query_lower or "veraset" in query_lower:
            if "sgk" in concern_lower or "iÅŸ" in concern_lower:
                return {"entity": "NÃ¼fus MÃ¼dÃ¼rlÃ¼ÄŸÃ¼ / UYAP", "method": "KayÄ±t Celbi", "responsible": "Mahkeme"}
            return {"entity": "NÃ¼fus MÃ¼dÃ¼rlÃ¼ÄŸÃ¼ (MERNÄ°S)", "method": "MÃ¼zekkere/Sorgu", "responsible": "Mahkeme"}

        if "iÅŸ" in concern_lower or "bordro" in concern_lower: return {"entity": "SGK Ä°l MÃ¼dÃ¼rlÃ¼ÄŸÃ¼ / Ä°ÅŸyeri",
                                                                       "method": "MÃ¼zekkere", "responsible": "Mahkeme"}
        if "banka" in concern_lower or "dekont" in concern_lower: return {"entity": "Ä°lgili Banka Genel MÃ¼dÃ¼rlÃ¼ÄŸÃ¼",
                                                                          "method": "MÃ¼zekkere",
                                                                          "responsible": "Mahkeme"}
        if "rapor" in concern_lower or "teknik" in concern_lower: return {"entity": "BilirkiÅŸi Heyeti",
                                                                          "method": "KeÅŸif/Ä°nceleme",
                                                                          "responsible": "Mahkeme"}
        if "tanÄ±k" in concern_lower or "gÃ¶rgÃ¼" in concern_lower: return {"entity": "TanÄ±klar",
                                                                         "method": "DuruÅŸmada Dinletme",
                                                                         "responsible": "Avukat"}
        if "tapu" in concern_lower: return {"entity": "Tapu Sicil MÃ¼dÃ¼rlÃ¼ÄŸÃ¼", "method": "MÃ¼zekkere",
                                            "responsible": "Mahkeme"}
        return {"entity": "Dosya KapsamÄ±", "method": "Ä°nceleme", "responsible": "Avukat"}

    def _estimate_count(self, category):
        if category == "DELIL": return random.randint(2, 4)
        if category == "ICTIHAT": return 1
        return 1

    def _generate_risk_note(self, concern):
        return f"Bu husus giderilmezse '{concern[:40]}...' yÃ¶nÃ¼nden hakim tereddÃ¼dÃ¼ devam eder ve ispat yÃ¼kÃ¼ karÅŸÄ±lanamaz."

    def _classify_concern(self, concern_text):
        text = concern_text.lower()
        if any(k in text for k in
               ["delil", "ispat", "kanÄ±t", "tanÄ±k", "belge", "tespit", "bilirkiÅŸi", "rapor"]): return "DELIL"
        if any(k in text for k in ["iÃ§tihat", "emsal", "yerleÅŸik", "karar", "yargÄ±tay", "daire"]): return "ICTIHAT"
        if any(k in text for k in ["usul", "sÃ¼re", "ehliyet", "ÅŸekil", "gÃ¶rev", "yetki", "husumet"]): return "USUL"
        if any(k in text for k in ["talep", "fazla", "aÅŸan", "kÄ±smi", "daraltma"]): return "TALEP_DARALTMA"
        return None

    def _category_to_turkish(self, category):
        return {"DELIL": "delil ve ispat", "ICTIHAT": "emsal iÃ§tihat", "USUL": "usul hukuku",
                "TALEP_DARALTMA": "stratejik talep"}.get(category, "hukuki")

    def _generate_recommendation_text(self, concern, category_tr):
        prompt = f"""
BAÄLAM: TÃ¼rk Hukuku (YargÄ±tay/BAM uygulamasÄ±). BaÅŸka Ã¼lke veya sistem kullanma.
Bir avukata yol gÃ¶sterecek ÅŸekilde, aÅŸaÄŸÄ±daki hakim tereddÃ¼dÃ¼ne yÃ¶nelik {category_tr} odaklÄ± SOMUT bir aksiyon Ã¶nerisi yaz.
Hakim TereddÃ¼dÃ¼: "{concern}"
Kurallar: Tek bir cÃ¼mle yaz. Emir kipi kullan.
Ã‡IKTI:
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "Ä°lgili hususta ek delil ve beyan sunulmalÄ±dÄ±r."

    def _pick_evidence(self, options):
        if not options: return "Genel"
        return random.choice(options)


# ==================================================
# 5ï¸âƒ£ HAFIZA YÃ–NETÄ°CÄ°SÄ° (FULL INTEGRATED - V127 MASTER PROMPT)
# ==================================================
class LegalMemoryManager:
    # --- SIMULATION CONFIG ---
    MITIGATION_EFFECTS = {
        "DELIL": {"min": 5, "max": 10}, "BELGE": {"min": 5, "max": 10},
        "ICTIHAT": {"min": 3, "max": 7}, "ARGUMAN": {"min": 3, "max": 7},
        "TALEP_DARALTMA": {"min": 4, "max": 6}, "USUL": {"min": 2, "max": 4}
    }
    MAX_TOTAL_BOOST = 15
    MAX_SCORE = 95

    def __init__(self, client, embedder, llm):
        self.client = client
        self.embedder = embedder
        self.llm = llm
        self._init_memory_collections()
        self.last_consolidation_ts = self._load_state()
        self.domain_cache = {}
        self.last_recalled_query = None
        self.recommendation_engine = ActionableRecommendationEngine(llm)
        self.audit_logger = LegalAuditLogger()
        self.sanitizer = LegalTextSanitizer()  # V120 Sanitizer
        self.latest_ui_data = {}

    def _init_memory_collections(self):
        for name, col_name in LegalConfig.MEMORY_COLLECTIONS.items():
            if not self.client.collection_exists(col_name):
                print(f"ğŸ§  HafÄ±za oluÅŸturuluyor: {col_name}")
                self.client.create_collection(col_name, vectors_config=VectorParams(size=768, distance=Distance.COSINE))

    def _load_state(self):
        try:
            if os.path.exists(LegalConfig.STATE_FILE):
                with open(LegalConfig.STATE_FILE, 'r') as f:
                    data = json.load(f)
                    return data.get("last_consolidation", 0.0)
        except:
            pass
        return 0.0

    def _save_state(self):
        try:
            with open(LegalConfig.STATE_FILE, 'w') as f:
                json.dump({"last_consolidation": time.time()}, f)
        except:
            pass

    def _detect_polarity(self, principle_text):
        prompt = f"BAÄLAM: TÃ¼rk Hukuku.\nÄ°LKE: '{principle_text}'\nCEVAP (SADECE BÄ°RÄ°): [LEHINE] veya [ALEYHINE] veya [BELIRSIZ]"
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "LEHINE" in res: return "LEHINE"
            if "ALEYHINE" in res: return "ALEYHINE"
            return "BELIRSIZ"
        except:
            return "BELIRSIZ"

    def _detect_domain_from_query(self, query_text):
        if query_text in self.domain_cache: return self.domain_cache[query_text]
        prompt = f"Sorgu: \"{query_text}\"\nBu sorgu hangi hukuk dalÄ±na girer? SADECE TEK KELÄ°ME CEVAP VER."
        try:
            domain = self.llm.invoke(prompt).content.strip().split()[0]
            self.domain_cache[query_text] = domain
            return domain
        except:
            return "Genel"

    def _extract_year_bucket(self, timestamp):
        year = datetime.fromtimestamp(timestamp).year
        if year <= 2018:
            return "2015-2018"
        elif year <= 2021:
            return "2019-2021"
        else:
            return "2022-2024"

    def _apply_time_decay(self, confidence, timestamp):
        if not timestamp: return confidence
        elapsed_months = (time.time() - timestamp) / (30 * 24 * 3600)
        return confidence * math.pow(LegalConfig.DECAY_RATE_PER_MONTH, elapsed_months)

    def _calculate_case_success_probability(self, principle_confidence, trend_direction, conflict, domain_match,
                                            polarity="LEHINE"):
        score = principle_confidence * 100
        if trend_direction == "up":
            score += 10
        elif trend_direction == "down":
            score -= 10
        if conflict: score -= 15
        if not domain_match: score -= 10
        if polarity == "BELIRSIZ": score -= 5

        if principle_confidence > 0.85 and polarity == "LEHINE":
            if score < 65: score = 75.0

        score = max(0, min(100, round(score, 1)))
        conf_level = "YÃ¼ksek" if score >= 70 else "Orta" if score >= 40 else "DÃ¼ÅŸÃ¼k"
        summary = "BaÅŸarÄ± ihtimali yÃ¼ksek." if score >= 70 else "Riskli."
        return {"success_probability": score, "confidence_level": conf_level, "summary": summary}

    # --- V127: MASTER PROMPT GENERATOR ---
    def _build_master_prompt(self, role, domain, topic, analysis_type, memory_context, main_input, task_instruction):
        return f"""
SENÄ°N ROLÃœN: {role}

{LegalConfig.PROMPT_GUARD}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ALLOWED SCOPE (ZORUNLU SINIRLAR)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Hukuk AlanÄ±: {domain}
- Odak Konu: {topic}
- Ä°nceleme TÃ¼rÃ¼: {analysis_type}
- YargÄ± Ã‡erÃ§evesi: TÃ¼rk Hukuku (YargÄ±tay / BAM)

Bu analiz SADECE yukarÄ±daki scope ile sÄ±nÄ±rlÄ±dÄ±r.
Bu sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±ndaki her konu otomatik olarak ANALÄ°Z DIÅIDIR.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
YERLEÅÄ°K HAFIZA / Ä°Ã‡TÄ°HAT BAÄLAMI
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{memory_context}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OLAY / BELGE / TEREDDÃœT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{main_input}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GÃ–REV
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{task_instruction}

Ã‡IKTIYI OLUÅTURMADAN Ã–NCE:
- Scope dÄ±ÅŸÄ±na Ã§Ä±kÄ±p Ã§Ä±kmadÄ±ÄŸÄ±nÄ± kontrol et.
- Tekrar veya genelleme olup olmadÄ±ÄŸÄ±nÄ± denetle.
- Hukuki rolÃ¼nÃ¼ ihlal edip etmediÄŸini denetle.
"""

    # --- V127: PERSONA FUNCS UPDATED TO MASTER PROMPT ---

    def _generate_judge_doubts_v120(self, query, principle_text, domain="Genel"):
        """Hakimin ilk refleksini ve tereddÃ¼tlerini Ã¼retir (Master Prompt ile)."""
        task = """
Bu ilke Ä±ÅŸÄ±ÄŸÄ±nda, olayÄ± deÄŸerlendirirken yaÅŸadÄ±ÄŸÄ±n EN FAZLA 3 TEMEL TEREDDÃœTÃœ (Doubts) listele.
Her tereddÃ¼t SOMUT olsun: delil eksikliÄŸi, usul sorunu, emsal uyuÅŸmazlÄ±ÄŸÄ± gibi.
TereddÃ¼tler kÄ±sa ve net olsun (maks 1 cÃ¼mle).
AyrÄ±ca dosya hakkÄ±ndaki Ä°LK REFLEKSÄ°NÄ° (Red/Kabul EÄŸilimli) tek kelimeyle yaz.

Ã‡IKTI FORMATI (JSON):
{
  "reflex": "RED EÄÄ°LÄ°MLÄ° veya KABUL EÄÄ°LÄ°MLÄ°",
  "doubts": ["TereddÃ¼t 1...", "TereddÃ¼t 2...", "TereddÃ¼t 3..."]
}
"""
        prompt = self._build_master_prompt(
            role="TÃœRK HAKÄ°MÄ°",
            domain=domain,
            topic=query,
            analysis_type="Hakim Ä°lk DeÄŸerlendirmesi",
            memory_context=principle_text,
            main_input=query,
            task_instruction=task
        )

        try:
            res = self.llm.invoke(prompt).content.strip()
            # JSON temizliÄŸi
            if "```json" in res:
                res = res.split("```json")[1].split("```")[0].strip()
            elif "```" in res:
                res = res.split("```")[1].split("```")[0].strip()
            return json.loads(res)
        except:
            return {"reflex": "BELÄ°RSÄ°Z",
                    "doubts": ["Dosya kapsamÄ±nda delil durumu", "Emsal kararÄ±n uygunluÄŸu", "Usul eksiklikleri"]}

    def _generate_plaintiff_response_v120(self, doubts, principle_text, domain="Genel", query_text=""):
        doubts_text = "\n".join([f"- {d}" for d in doubts])
        combined_input = f"OLAY: {query_text}\n\nHAKÄ°M TEREDDÃœTLERÄ°:\n{doubts_text}"

        task = """
GÃ–REVÄ°N:
- Her bir tereddÃ¼te AYRI AYRI cevap vermek.
- Hakimi kabul yÃ¶nÃ¼nde ikna etmeye Ã§alÄ±ÅŸmak.

KURALLAR:
1. Her tereddÃ¼de AYRI AYRI cevap ver.
2. CevabÄ±nda mutlaka varsa [MEVZUAT] veya [EMSAL KARAR] etiketli belgeye ATIF YAP (Madde no veya Karar no ver).
3. Genel hukuk anlatma, doÄŸrudan somut olaya ve mÃ¼vekkilin haklÄ±lÄ±ÄŸÄ±na baÄŸla.
4. Her cevap maks 3-4 cÃ¼mle olsun.

Ã‡IKTI FORMATINI ASLA DEÄÄ°ÅTÄ°RME:

--------------------------------------------------
DAVACI VEKÄ°LÄ° DEÄERLENDÄ°RMESÄ°
--------------------------------------------------
TereddÃ¼t 1:
- Cevap:

TereddÃ¼t 2:
- Cevap:

TereddÃ¼t 3:
- Cevap:
"""
        prompt = self._build_master_prompt(
            role="DAVACI VEKÄ°LÄ°",
            domain=domain,
            topic="Hakim TereddÃ¼tlerini Giderme",
            analysis_type="Hukuki ArgÃ¼mantasyon",
            memory_context=principle_text,
            main_input=combined_input,
            task_instruction=task
        )

        try:
            raw = self.llm.invoke(prompt).content.strip()
            return self.sanitizer.enforce_no_repeat(raw)
        except:
            return "DavacÄ± vekili beyanÄ± oluÅŸturulamadÄ±."

    def _generate_defendant_response_v120(self, doubts, principle_text, domain="Genel", query_text=""):
        doubts_text = "\n".join([f"- {d}" for d in doubts])
        combined_input = f"OLAY: {query_text}\n\nHAKÄ°M TEREDDÃœTLERÄ°:\n{doubts_text}"

        task = """
GÃ–REVÄ°N:
- Hakimin tereddÃ¼tlerini DERÄ°NLEÅTÄ°RMEK.
- Kabul ihtimalini zayÄ±flatmak.

KURALLAR:
1. Her tereddÃ¼de AYRI AYRI cevap ver ve tereddÃ¼dÃ¼ derinleÅŸtir.
2. CevabÄ±nda mutlaka varsa [MEVZUAT] veya [EMSAL KARAR] eksikliÄŸine veya aleyhe durumuna ATIF YAP.
3. Genel hukuk anlatma, somut olaydaki eksikliklere baÄŸla.
4. Her cevap maks 3-4 cÃ¼mle olsun.

Ã‡IKTI FORMATINI ASLA DEÄÄ°ÅTÄ°RME:

--------------------------------------------------
DAVALI VEKÄ°LÄ° DEÄERLENDÄ°RMESÄ°
--------------------------------------------------
TereddÃ¼t 1:
- KarÅŸÄ± ArgÃ¼man:

TereddÃ¼t 2:
- KarÅŸÄ± ArgÃ¼man:

TereddÃ¼t 3:
- KarÅŸÄ± ArgÃ¼man:
"""
        prompt = self._build_master_prompt(
            role="DAVALI (KARÅI TARAF) VEKÄ°LÄ°",
            domain=domain,
            topic="TereddÃ¼tleri DerinleÅŸtirme ve Ä°tiraz",
            analysis_type="Hukuki ArgÃ¼mantasyon",
            memory_context=principle_text,
            main_input=combined_input,
            task_instruction=task
        )

        try:
            raw = self.llm.invoke(prompt).content.strip()
            return self.sanitizer.enforce_no_repeat(raw)
        except:
            return "DavalÄ± vekili beyanÄ± oluÅŸturulamadÄ±."

    def _generate_expert_response_v120(self, doubts, principle_text, domain="Genel", query_text=""):
        doubts_text = "\n".join([f"- {d}" for d in doubts])
        combined_input = f"OLAY: {query_text}\n\nHAKÄ°M TEREDDÃœTLERÄ°:\n{doubts_text}"

        task = """
GÃ–REVÄ°N:
- Hukuki mantÄ±k zincirini kontrol etmek.

YANITLA:
- TereddÃ¼tler hukuken yerinde mi?
- DavacÄ± cevaplarÄ± yeterli mi?
- DavalÄ± itirazlarÄ± hukuki mi?

Ã‡IKTI FORMATINI ASLA DEÄÄ°ÅTÄ°RME:

--------------------------------------------------
BÄ°LÄ°RKÄ°ÅÄ° TESPÄ°TLERÄ°
--------------------------------------------------
Genel Hukuki DeÄŸerlendirme:
- ...

ZayÄ±f Noktalar:
- ...

TutarlÄ± Noktalar:
- ...
"""
        prompt = self._build_master_prompt(
            role="TARAFSIZ BÄ°LÄ°RKÄ°ÅÄ°",
            domain=domain,
            topic="Hukuki TutarlÄ±lÄ±k Denetimi",
            analysis_type="BilirkiÅŸi MÃ¼talaasÄ±",
            memory_context=principle_text,
            main_input=combined_input,
            task_instruction=task
        )

        try:
            raw = self.llm.invoke(prompt).content.strip()
            return self.sanitizer.enforce_no_repeat(raw)
        except:
            return "BilirkiÅŸi raporu oluÅŸturulamadÄ±."

    def _simulate_post_strengthening_score(self, base_score, recommendations):
        total_boost = 0
        seen_cats = {}
        for rec in recommendations:
            cat = rec.get("category", "DELIL")
            impact = rec['risk_reduction']['expected_score_increase']
            if cat in seen_cats: impact = int(impact * 0.6)
            seen_cats[cat] = True
            total_boost += impact

        return {"current_score": base_score, "projected_score": min(base_score + total_boost, self.MAX_SCORE),
                "total_boost": total_boost}

    # --- MAIN RECALL FUNCTION (V127 UPDATE) ---
    def recall_principles(self, query_text):
        try:
            # 1. AUDIT START
            self.audit_logger = LegalAuditLogger()
            self.sanitizer.reset()  # Reset memory for new query

            query_domain = self._detect_domain_from_query(query_text)
            vector = self.embedder.embed_query(query_text)
            hits = self.client.query_points(LegalConfig.MEMORY_COLLECTIONS["principle"], query=vector, limit=15).points

            processed_hits = []
            for h in hits:
                raw_conf = h.payload.get("confidence", 0.5)
                ts = h.payload.get("timestamp", time.time())
                domain = h.payload.get("domain", "Genel")
                evolution_note = h.payload.get("evolution_note", "")
                polarity = h.payload.get("polarity", "BELIRSIZ")
                final_conf = self._apply_time_decay(raw_conf, ts)
                if polarity == "BELIRSIZ": final_conf *= 0.8
                is_domain_match = (query_domain.lower() in domain.lower())

                if final_conf >= LegalConfig.MIN_CONFIDENCE_THRESHOLD:
                    trend_dir = "up" if "GÃœÃ‡LENEN" in evolution_note else "down" if "ZAYIFLAYAN" in evolution_note else "stable"
                    item = {
                        "text": h.payload['principle'], "conf": final_conf, "domain": domain,
                        "conflict": h.payload.get("conflict_flag", False), "score": h.score,
                        "trend_dir": trend_dir, "domain_match": is_domain_match,
                        "evolution_note": evolution_note, "polarity": polarity,
                        "year_bucket": self._extract_year_bucket(ts)
                    }
                    processed_hits.append(item)

            sorted_hits = sorted(processed_hits, key=lambda x: x["score"], reverse=True)[:3]

            # AUDIT: PRINCIPLE ANALYSIS
            self.audit_logger.log_event(
                stage="principle_analysis", title="Ä°Ã§tihatlar Analiz Edildi",
                description=f"{len(sorted_hits)} adet yÃ¼ksek gÃ¼venli ilke tespit edildi.",
                outputs={"domain": query_domain, "hit_count": len(sorted_hits)}
            )

            if not sorted_hits: return ""

            memory_text = f"\nğŸ’¡ YERLEÅÄ°K Ä°Ã‡TÄ°HAT HAFIZASI ({query_domain} AlanÄ±):\n"

            self.latest_ui_data = {
                "query": query_text, "domain": query_domain, "principles": [], "net_decision": {},
                "executive_summary": "", "audit_log": {}
            }

            for item in sorted_hits:
                # 2. Risk Analizi
                analysis = self._calculate_case_success_probability(
                    item["conf"], item["trend_dir"], item["conflict"], item["domain_match"], item["polarity"]
                )

                # --- V120: PERSONA SÄ°STEMÄ° ---
                # V127 UPDATE: Domain ve Query Text transfer edildi.

                # A. HAKÄ°M REFLEKSÄ° VE TEREDDÃœTLER (TRIGGER)
                # Yeni parametre eklendi: domain
                judge_data = self._generate_judge_doubts_v120(query_text, item['text'], domain=item['domain'])
                doubts = judge_data.get("doubts", [])
                reflex = judge_data.get("reflex", "BELÄ°RSÄ°Z")

                self.audit_logger.log_event(
                    stage="judge_analysis",
                    title="JUDGE ANALYSIS COMPLETED",
                    description=f"Hakim Refleksi: {reflex}",
                    outputs={"reflex": reflex, "doubt_count": len(doubts), "doubts": doubts}
                )

                # B. PERSONA PHASE (SIRALI AKIÅ)
                self.audit_logger.log_event(stage="persona_phase", title="PERSONA PHASE STARTED",
                                            description="Taraf vekilleri ve bilirkiÅŸi devreye giriyor.")

                # DavacÄ±
                # Yeni parametreler: domain, query_text
                plaintiff_text = self._generate_plaintiff_response_v120(doubts, item['text'], domain=item['domain'],
                                                                        query_text=query_text)
                self.audit_logger.log_event(
                    stage="plaintiff_arg", title="DAVACI VEKÄ°LÄ° DEÄERLENDÄ°RMESÄ°",
                    description=f"Ele alÄ±nan tereddÃ¼t sayÄ±sÄ±: {len(doubts)}",
                    outputs={"full_text": plaintiff_text}
                )

                # DavalÄ±
                # Yeni parametreler: domain, query_text
                defendant_text = self._generate_defendant_response_v120(doubts, item['text'], domain=item['domain'],
                                                                        query_text=query_text)
                self.audit_logger.log_event(
                    stage="defendant_arg", title="DAVALI VEKÄ°LÄ° DEÄERLENDÄ°RMESÄ°",
                    description="KarÅŸÄ± argÃ¼manlar ve usul itirazlarÄ± sunuldu.",
                    outputs={"full_text": defendant_text}
                )

                # BilirkiÅŸi
                # Yeni parametreler: domain, query_text
                expert_text = self._generate_expert_response_v120(doubts, item['text'], domain=item['domain'],
                                                                  query_text=query_text)
                self.audit_logger.log_event(
                    stage="expert_arg", title="BÄ°LÄ°RKÄ°ÅÄ° TESPÄ°TLERÄ°",
                    description="Hukuki zincir ve tutarlÄ±lÄ±k kontrolÃ¼ yapÄ±ldÄ±.",
                    outputs={"full_text": expert_text}
                )

                self.audit_logger.log_event(stage="persona_completed", title="PERSONA PHASE COMPLETED",
                                            description="TÃ¼m taraflar dinlendi.")

                # C. ACTION ENGINE (TereddÃ¼tler Ã¼zerinden Ã§alÄ±ÅŸÄ±r)
                action_plan = self.recommendation_engine.generate(doubts, query_text)

                # D. SIMULATION
                simulation_result = self._simulate_post_strengthening_score(analysis['success_probability'],
                                                                            action_plan)

                # E. EXECUTIVE SUMMARY
                exec_summary = f"Hakim '{reflex}' eÄŸilimindedir. {len(doubts)} temel tereddÃ¼t (Ã–rn: {doubts[0]}) mevcuttur. DavacÄ± vekili bu hususlarÄ± gidermeye Ã§alÄ±ÅŸsa da DavalÄ± taraf usul itirazlarÄ±nÄ± sÃ¼rdÃ¼rmektedir."

                # V120 SANITIZATION LOG
                self.audit_logger.log_event(
                    stage="output_sanitizer", title="OUTPUT SANITIZER APPLIED",
                    description=f"Tekrar eden paragraflar temizlendi.",
                    outputs={"repeated_paragraphs_removed": self.sanitizer.dropped_count}
                )

                # Store Complete Data (V120 Structure)
                self.latest_ui_data["principles"].append({
                    "text": item['text'], "trend_log": item['evolution_note'], "polarity": item['polarity'],
                    "conflict_flag": item['conflict'], "year_bucket": item['year_bucket'],
                    "score_data": analysis,
                    "personas_v120": {
                        "judge_reflex": reflex,
                        "doubts": doubts,
                        "plaintiff": plaintiff_text,
                        "defendant": defendant_text,
                        "expert": expert_text
                    },
                    # Backward compatibility dummy data
                    "personas": {"judge": str(doubts), "opponent": defendant_text, "opponent_title": "DavalÄ±",
                                 "expert": expert_text, "devil": "N/A"},
                    "conflict_analysis": {"conflict_level": "N/A", "conflict_score": 0, "summary": []},
                    "reasoned_verdict": f"HAKÄ°MÄ°N GEÃ‡Ä°CÄ° KANAATÄ°: {reflex}. GerekÃ§e: {doubts}",
                    "action_plan": action_plan,
                    "simulation": simulation_result
                })
                self.latest_ui_data["executive_summary"] = exec_summary
                self.latest_ui_data["net_decision"] = {"decision": reflex}

                memory_text += f"- [{item['domain']}] {item['text']}\n"
                memory_text += f"  âš–ï¸ REFLEKS: {reflex} | âš ï¸ TereddÃ¼t: {len(doubts)} adet\n"

            # V120: Audit Log Export
            self.latest_ui_data["audit_log"] = self.audit_logger.export()

            return memory_text
        except Exception as e:
            print(f"Hata: {e}")
            return ""

    # --- MATEMATÄ°KSEL YARDIMCILAR (TAM) ---
    def _cosine_similarity(self, v1, v2):
        dot = sum(a * b for a, b in zip(v1, v2))
        mag1 = math.sqrt(sum(a * a for a in v1))
        mag2 = math.sqrt(sum(b * b for b in v2))
        if mag1 == 0 or mag2 == 0: return 0.0
        return dot / (mag1 * mag2)

    def _calculate_vector_mean(self, vectors):
        if not vectors: return []
        dim = len(vectors[0])
        mean = [0.0] * dim
        for v in vectors:
            for i in range(dim):
                mean[i] += v[i]
        return [x / len(vectors) for x in mean]

    def _cluster_reasonings(self, items, threshold=0.86):
        clusters = []
        for item in items:
            added = False
            for c in clusters:
                if self._cosine_similarity(item['vector'], c['centroid']) >= threshold:
                    c['members'].append(item)
                    all_vecs = [m['vector'] for m in c['members']]
                    c['centroid'] = self._calculate_vector_mean(all_vecs)
                    added = True
                    break
            if not added:
                clusters.append({'members': [item], 'centroid': item['vector']})
        return [c['members'] for c in clusters]

    def _calculate_principle_confidence(self, cluster):
        count = len(cluster)
        count_score = min(1.0, count / 10)
        return 0.7 + (count_score * 0.3)

    def _analyze_trend_momentum(self, trend_dict):
        if not trend_dict: return "Veri Yetersiz"
        return "Ä°stikrarlÄ± Seyir"

    # --- ESKÄ° SAVE FONKSÄ°YONLARI (TAM & EKSÄ°KSÄ°Z) ---
    def calculate_memory_consensus(self, source_name, current_decision, vector_score):
        try:
            f = Filter(must=[FieldCondition(key="source", match=MatchValue(value=source_name))])
            p, _ = self.client.scroll("judge_memory_v1", scroll_filter=f, limit=20)
            if not p:
                if vector_score > 0.8: return 1.10
                return 1.0

            match_c = sum(1 for x in p if x.payload.get("decision") == current_decision)
            if len(p) == 0: return 1.0
            ratio = match_c / len(p)

            if ratio > 0.8: return 1.15
            if ratio < 0.2: return 0.85
            return 1.0
        except:
            return 1.0

    def save_decision(self, query, doc_name, decision, reason, doc_type):
        try:
            vec = self.embedder.embed_query(f"{query} {doc_name} {decision} {reason}")
            payload = {
                "query": query, "source": doc_name, "decision": decision,
                "reason": reason, "doc_type": doc_type,
                "timestamp": time.time(), "created_at": datetime.now().isoformat(), "id": str(uuid.uuid4())
            }
            self.client.upsert("judge_memory_v1", [PointStruct(id=payload['id'], vector=vec, payload=payload)])
        except:
            pass

    # --- KONSOLÄ°DASYON (TAM) ---
    def consolidate_principles_v79(self):
        print("\nğŸ”¥ Ä°Ã‡TÄ°HAT MÄ°MARI: ArtÄ±mlÄ± Konsolidasyon (V120)...")
        try:
            time_filter = Filter(must=[FieldCondition(key="timestamp", range=Range(gt=self.last_consolidation_ts))])
            points, _ = self.client.scroll(LegalConfig.MEMORY_COLLECTIONS["decision"], scroll_filter=time_filter,
                                           limit=200)

            candidates = []
            for p in points:
                if (p.payload.get('doc_type') == 'EMSAL KARAR' and len(
                        p.payload.get('reason', '')) > 30 and p.payload.get('decision') == 'KABUL'):
                    candidates.append({
                        "reason": p.payload['reason'], "id": p.id,
                        "source": p.payload.get('source', 'Bilinmeyen'),
                        "timestamp": p.payload.get('timestamp', time.time()),
                        "decision": p.payload.get('decision'), "vector": None
                    })

            if len(candidates) < 3:
                print("   â„¹ï¸ Yeterli yeni veri yok.")
                return

            print(f"   ğŸ” {len(candidates)} adet YENÄ° gerekÃ§e analiz ediliyor...")
            texts = [c["reason"] for c in candidates]
            vectors = self.embedder.embed_documents(texts)
            for i, v in enumerate(vectors): candidates[i]["vector"] = v
            clusters = self._cluster_reasonings(candidates, threshold=0.86)

            for cluster in clusters:
                if len(cluster) < 3: continue

                # KÃ¼me GerekÃ§elerini BirleÅŸtir
                reasonings_text = "\n".join([f"- {c['reason']}" for c in cluster])
                prompt = f"""
GÃ–REV: AÅŸaÄŸÄ±daki mahkeme gerekÃ§elerini analiz et.
1. Ortak hukuki ilkeyi TEK CÃœMLEDE Ã¶zetle.
2. Bu konunun ait olduÄŸu Hukuk DalÄ±nÄ± (Miras, Ceza, BorÃ§lar vb.) belirle.

GEREKÃ‡ELER:
{reasonings_text}

FORMAT:
Ä°LKE: [Ä°lke CÃ¼mlesi]
ALAN: [Hukuk DalÄ±]
"""
                res = self.llm.invoke(prompt).content.strip()
                principle_match = re.search(r"Ä°LKE:\s*(.*)", res)
                domain_match = re.search(r"ALAN:\s*(.*)", res)

                if principle_match:
                    principle_text = principle_match.group(1)
                    domain_text = domain_match.group(1) if domain_match else "Genel"
                    conf = self._calculate_principle_confidence(cluster)
                    source_ids = [c['id'] for c in cluster]

                    self._save_principle_v79(principle_text, conf, source_ids, domain_text, cluster)

            self._save_state()
            print("âœ… Konsolidasyon tamamlandÄ±.")
        except Exception as e:
            print(f"Hata: {e}")

    def _save_principle_v79(self, text, confidence, source_ids, domain, cluster_data):
        try:
            vec = self.embedder.embed_query(text)
            polarity = self._detect_polarity(text)
            hits = self.client.query_points("principle_memory_v1", query=vec, limit=10, score_threshold=0.80).points

            conflict = False
            trend = Counter()
            p_stats = {"LEHINE": 0, "ALEYHINE": 0, "BELIRSIZ": 0}

            # Conflict Check
            if polarity in p_stats: p_stats[polarity] += 1
            for h in hits:
                p = h.payload.get("polarity", "BELIRSIZ")
                if p in p_stats: p_stats[p] += 1
                if (p == "LEHINE" and polarity == "ALEYHINE") or (
                        p == "ALEYHINE" and polarity == "LEHINE"): conflict = True

            # Trend Check
            for c in cluster_data:
                bucket = self._extract_year_bucket(c.get("timestamp", time.time()))
                trend[(bucket, c.get("decision", "KABUL"))] += 1

            trend_dict = {}
            for (b, d), count in trend.items():
                if b not in trend_dict: trend_dict[b] = {"KABUL": 0, "RED": 0}
                trend_dict[b][d] = count

            evolution = self._analyze_trend_momentum(trend_dict)

            payload = {
                "principle": text, "confidence": confidence, "domain": domain,
                "polarity": polarity, "trend": trend_dict, "conflict_flag": conflict,
                "source_count": len(source_ids), "source_ids": source_ids, "evolution_note": evolution,
                "generated_by": "consolidation_v120", "timestamp": time.time(), "created_at": datetime.now().isoformat()
            }
            self.client.upsert("principle_memory_v1", [PointStruct(id=str(uuid.uuid4()), vector=vec, payload=payload)])
        except:
            pass


# ==================================================
# 7ï¸âƒ£ YENÄ° ARAÃ‡LAR: REASONING & STRATEGY (RESTORED)
# ==================================================
class WhiteLabelConfig:
    def __init__(self, firm_name="LEGAL OS", logo_path=None, footer_text="Otomatik Analiz Raporu", color=(0, 0, 0)):
        self.firm_name = firm_name
        self.logo_path = logo_path
        self.footer_text = footer_text
        self.color = color


class AuditTimelineBuilder:
    @staticmethod
    def build(audit_logs):
        timeline = []
        last_score = None
        logs_list = audit_logs.get("timeline", []) if isinstance(audit_logs, dict) else audit_logs
        for idx, log in enumerate(logs_list):
            score = log.get("resulting_score")
            if score is None: continue
            delta = None
            if last_score is not None: delta = round(score - last_score, 1)
            timeline.append({"step": idx + 1, "stage": log.get("title", "Ä°ÅŸlem"), "score": score, "delta": delta})
            last_score = score
        return timeline


class ScoreExplanationEngine:
    @staticmethod
    def generate(timeline):
        if not timeline: return "Yeterli veri yok."
        increases = [t for t in timeline if t["delta"] and t["delta"] > 0]
        decreases = [t for t in timeline if t["delta"] and t["delta"] < 0]
        parts = []
        if decreases:
            worst = min(decreases, key=lambda x: x["delta"])
            parts.append(f"BaÅŸarÄ± olasÄ±lÄ±ÄŸÄ±, '{worst['stage']}' aÅŸamasÄ±nda %{abs(worst['delta'])} dÃ¼ÅŸmÃ¼ÅŸtÃ¼r.")
        if increases:
            best = max(increases, key=lambda x: x["delta"])
            parts.append(
                f"Ancak '{best['stage']}' aÅŸamasÄ±nda stratejik deÄŸerlendirme ile %{best['delta']} artÄ±ÅŸ saÄŸlanmÄ±ÅŸtÄ±r.")
        return " ".join(parts) if parts else "Skor duraÄŸan seyretmiÅŸtir."


class JudgeReasoningGenerator:
    """V125: Dinamik Hakim RolÃ¼ AtamasÄ±"""

    def __init__(self, llm):
        self.llm = llm

    def generate(self, audit_logs, story=None, context_str=None):
        logs_list = audit_logs.get("timeline", []) if isinstance(audit_logs, dict) else audit_logs
        summary_lines = [f"- {log['description']}" for log in logs_list if "description" in log]
        audit_summary = "\n".join(summary_lines)

        # 1. DAVA TÃœRÃœ TESPÄ°TÄ° (Meta-Data Ã‡Ä±karÄ±mÄ±)
        dava_turu = "GENEL"
        if story:
            s_lower = story.lower()
            if any(k in s_lower for k in ["veraset", "miras", "tereke", "vasiyet", "Ã¶lÃ¼nce"]):
                dava_turu = "SULH HUKUK (MÄ°RAS)"
            elif any(k in s_lower for k in ["iÅŸÃ§i", "kÄ±dem", "ihbar", "fesih", "iÅŸveren"]):
                dava_turu = "Ä°Å MAHKEMESÄ°"
            elif any(k in s_lower for k in ["boÅŸanma", "nafaka", "velayet", "eÅŸ"]):
                dava_turu = "AÄ°LE MAHKEMESÄ°"
            elif any(k in s_lower for k in ["ceza", "suÃ§", "sanÄ±k", "hapis"]):
                dava_turu = "CEZA MAHKEMESÄ°"
            elif any(k in s_lower for k in ["ticaret", "ÅŸirket", "bono", "Ã§ek"]):
                dava_turu = "TÄ°CARET MAHKEMESÄ°"

        # 2. HAKÄ°M ROLÃœNÃœN BELÄ°RLENMESÄ°
        hakim_rolu = "Ä°LGÄ°LÄ° MAHKEME HAKÄ°MÄ°"
        if "MÄ°RAS" in dava_turu:
            hakim_rolu = "SULH HUKUK HAKÄ°MÄ°"
        elif "Ä°Å" in dava_turu:
            hakim_rolu = "Ä°Å MAHKEMESÄ° HAKÄ°MÄ°"
        elif "AÄ°LE" in dava_turu:
            hakim_rolu = "AÄ°LE MAHKEMESÄ° HAKÄ°MÄ°"
        elif "CEZA" in dava_turu:
            hakim_rolu = "ASLÄ°YE CEZA HAKÄ°MÄ°"
        elif "TÄ°CARET" in dava_turu:
            hakim_rolu = "ASLÄ°YE TÄ°CARET HAKÄ°MÄ°"

        prompt = f"""
SEN BÄ°R {hakim_rolu} OLARAK KARAR GEREKÃ‡ESÄ° YAZIYORSUN.
{LegalConfig.PROMPT_GUARD}

OLAY Ã–ZETÄ°: {story if story else 'Dosya kapsamÄ±'}
MEVZUAT, EMSAL VE DELÄ°LLER: {context_str if context_str else audit_summary}

GÃ–REVÄ°N:
Karar gerekÃ§eni ÅŸu yapÄ± ile yaz (resmi Ã¼slup, yaklaÅŸÄ±k 250-350 kelime):

1. Dosya kapsamÄ±na giren delillerin ve toplanan tÃ¼m kanÄ±tlarÄ±n Ã¶zeti (tanÄ±k beyanlarÄ±, bilirkiÅŸi raporu, belgeler vb. somut olarak belirt).
2. TaraflarÄ±n iddialarÄ± ve savunmalarÄ±nÄ±n kÄ±sa Ã¶zeti.
3. Hukuki deÄŸerlendirme: Ä°lgili kanun maddeleri, YargÄ±tay iÃ§tihatlarÄ± ve emsal kararlara somut atÄ±f yaparak olayÄ±n nasÄ±l deÄŸerlendirildiÄŸi.
4. Hakim olarak karÅŸÄ±laÅŸtÄ±ÄŸÄ±n tereddÃ¼tler (maksimum 2-3 tane, somut) ve bunlarÄ±n nasÄ±l giderildiÄŸi.
5. SonuÃ§: DavanÄ±n kabulÃ¼/reddi/kÄ±smen kabulÃ¼, ek delil istenmesi vb. net hÃ¼kÃ¼m.

Bu kararÄ±n kesin hÃ¼kÃ¼m etkisi olmadÄ±ÄŸÄ±nÄ± ve kanun yoluna aÃ§Ä±k olduÄŸunu belirt.
Somut olayla baÄŸlantÄ±lÄ±, soyut genel ifadelerden kaÃ§Ä±n. GerÃ§ek bir hakim karar gerekÃ§esi gibi doÄŸal ve akÄ±cÄ± olsun.
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "GerekÃ§e oluÅŸturulamadÄ±."


class AppealArgumentGenerator:
    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_reasoning):
        prompt = f"""
SEN KIDEMLI BIR AVUKATSIN.
{LegalConfig.PROMPT_GUARD}

Asagida bir hakimin karar gerekcesi yer almaktadir.
Bu gerekceden hareketle, UST MAHKEMEYE sunulmak uzere itiraz argumanlari yaz.

KURALLAR:
- Hakime saygi dili kullan
- "eksik inceleme", "yanlis takdir", "delillerin birlikte degerlendirilmemesi" kaliplari kullan
- Madde madde yaz (Max 5 madde)

HAKIM GEREKCESI:
{judge_reasoning}
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "Ä°tiraz argÃ¼manlarÄ± oluÅŸturulamadÄ±."


class AppealPetitionGenerator:
    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_reasoning, case_topic):
        prompt = f"""
BAÄLAM: TÃ¼rk Hukuku. BAM / YargÄ±tay uygulamasÄ±.
SEN: KÄ±demli bir avukatsÄ±n.
{LegalConfig.PROMPT_GUARD}

AÅŸaÄŸÄ±da yer alan hakim gerekÃ§esine karÅŸÄ±, Ã¼st mahkemeye sunulmak Ã¼zere
RESMÄ°, KURUMSAL ve HUKUKÄ° DÄ°LDE tam bir Ä°TÄ°RAZ / Ä°STÄ°NAF / TEMYÄ°Z DÄ°LEKÃ‡ESÄ° taslaÄŸÄ± yaz.

KURALLAR:
- Hakime saygÄ±lÄ± dil kullan.
- "Eksik inceleme", "yanlÄ±ÅŸ takdir", "hukuka aykÄ±rÄ±lÄ±k" kalÄ±plarÄ± yer alsÄ±n.
- Madde numaralarÄ± kullan.

ZORUNLU UNSURLAR:
- Mahkeme adÄ±, dosya no (Ã¶rnek: ... Mahkemesi, 2024/... E.)
- KararÄ±n Ã¶zeti
- Somut itiraz nedenleri (eksik inceleme, yanlÄ±ÅŸ hukuk uygulamasÄ± vb.)
- Hangi TMK maddesi veya YargÄ±tay iÃ§tihadÄ±nÄ±n yanlÄ±ÅŸ uygulandÄ±ÄŸÄ±
- Ä°stemin net ifadesi
- Avukat imzasÄ± kÄ±smÄ±nÄ± bÄ±rak

ZORUNLU BAÅLIKLAR:
1. KARARIN Ã–ZETÄ°
2. Ä°TÄ°RAZ NEDENLERÄ°
3. HUKUKÄ° DEÄERLENDÄ°RME
4. SONUÃ‡ VE Ä°STEM

DOSYA KONUSU: {case_topic}
HAKÄ°M GEREKÃ‡ESÄ°: {judge_reasoning}

Ã‡IKTI (Sadece DilekÃ§e Metni):
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "DilekÃ§e oluÅŸturulamadÄ±."


class AppealActionMapper:
    def __init__(self, llm):
        self.llm = llm

    def map_arguments(self, appeal_text):
        actions = []
        arguments = [a.strip() for a in appeal_text.split("\n") if re.match(r"^\d+\.", a.strip())][:5]

        for arg in arguments:
            prompt = f"""
SEN KIDEMLI BIR AVUKATSIN.
Asagidaki itiraz argumanindan hareketle, avukatin fiilen yapmasi gereken SOMUT bir aksiyon tanimla.
JSON formatinda ver.

ALANLAR: title, evidence_type (tanÄ±k/belge/bilirkiÅŸi/iÃ§tihat), source, estimated_time, estimated_cost, risk_if_missing

ITIRAZ ARGUMANI: {arg}
"""
            try:
                res = self.llm.invoke(prompt).content.strip()
                if "```json" in res:
                    res = res.split("```json")[1].split("```")[0].strip()
                elif "```" in res:
                    res = res.split("```json")[1].split("```")[0].strip()

                action = json.loads(res)
                action["action_id"] = str(uuid.uuid4())
                action["linked_argument"] = arg
                actions.append(action)
            except:
                continue
        return actions


class CorporateCover:
    @staticmethod
    def add(pdf, case_id, version="V120"):
        pdf.add_page()
        pdf.set_font("DejaVu", "B", 24)
        pdf.ln(60)
        pdf.cell(0, 10, "LEGAL OS", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", size=14)
        pdf.cell(0, 10, "Yapay Zeka Destekli Hukuki Analiz Raporu", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(30)
        pdf.set_font("DejaVu", "B", 10)
        pdf.cell(0, 8, f"DOSYA KIMLIGI: {case_id}", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", "", 10)
        pdf.cell(0, 8, f"RAPOR TARIHI: {datetime.now().strftime('%d.%m.%Y %H:%M')}", align="C", new_x=XPos.LMARGIN,
                 new_y=YPos.NEXT)
        pdf.cell(0, 8, f"SISTEM SURUMU: {version}", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(50)
        pdf.set_font("DejaVu", "I", 8)
        pdf.multi_cell(0, 5,
                       "YASAL UYARI: Bu rapor, yapay zeka algoritmalari kullanilarak uretilmistir. Hukuki tavsiye niteliginde olmayip, karar destek amaclidir.",
                       align="C")


# ==================================================
# 8ï¸âƒ£ ARAMA MOTORU SINIFI (SEARCH ENGINE)
# ==================================================
class LegalSearchEngine:
    def __init__(self):
        self.config = LegalConfig()
        self.dense_embedder = OllamaEmbeddings(model=self.config.EMBEDDING_MODEL)
        self.client = None
        atexit.register(self.close)

    def connect_db(self):
        if self.client is not None: return True
        print("   ğŸ”Œ VeritabanÄ± baÄŸlantÄ±sÄ± baÅŸlatÄ±lÄ±yor...")
        LegalUtils.force_unlock_db()
        try:
            self.client = QdrantClient(path=self.config.QDRANT_PATH)
            print("   âœ… VeritabanÄ± baÄŸlantÄ±sÄ± BAÅARILI.")
            return True
        except Exception as e:
            print(f"\nâŒ VERÄ°TABANI HATASI: {e}")
            return False

    def close(self):
        if self.client:
            try:
                self.client.close()
                self.client = None
                print("\nğŸ”’ VeritabanÄ± baÄŸlantÄ±sÄ± gÃ¼venli ÅŸekilde kapatÄ±ldÄ±.")
            except:
                pass

    def run_indexing(self):
        if not self.connect_db(): return False

        for key, config in self.config.SOURCES.items():
            collection_name = config["collection"];
            folder_path = config["folder"]
            print(f"   ğŸ‘‰ Koleksiyon kontrol ediliyor: {config['desc']}...")

            if not os.path.exists(folder_path):
                os.makedirs(folder_path);
                print(f"      âš ï¸ KlasÃ¶r oluÅŸturuldu: {folder_path}");
                continue

            if not self.client.collection_exists(collection_name):
                print(f"      âš™ï¸ '{collection_name}' oluÅŸturuluyor...")
                self.client.create_collection(collection_name,
                                              vectors_config=VectorParams(size=768, distance=Distance.COSINE))

            print(f"      ğŸ” Mevcut dosyalar taranÄ±yor...")
            indexed_files = set()
            offset = None
            while True:
                points, offset = self.client.scroll(collection_name, limit=100, with_payload=True, with_vectors=False,
                                                    offset=offset)
                for p in points:
                    if 'source' in p.payload: indexed_files.add(p.payload['source'])
                if offset is None: break

            files_on_disk = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]
            new_files = [f for f in files_on_disk if f not in indexed_files]

            if not new_files: print(f"      âœ… {config['desc']} gÃ¼ncel ({len(files_on_disk)} dosya)."); continue
            print(f"      â™»ï¸ {config['desc']} iÃ§in {len(new_files)} yeni dosya iÅŸleniyor...")

            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            all_texts = [];
            all_metadatas = []

            for filename in new_files:
                try:
                    loader = PyMuPDFLoader(os.path.join(folder_path, filename))
                    docs = loader.load()
                    chunks = text_splitter.split_documents(docs)
                    for c in chunks:
                        clean_content = LegalUtils.clean_text(c.page_content)
                        all_texts.append(clean_content)
                        all_metadatas.append(
                            {"source": filename, "type": config['desc'], "page": c.metadata.get("page", 0) + 1})
                    print(f"      ğŸ“„ Okundu: {filename}")
                except Exception as e:
                    print(f"      âš ï¸ Hata: {filename} - {e}")

            if not all_texts: continue
            print(f"      ğŸš€ VektÃ¶rleÅŸtiriliyor ({len(all_texts)} parÃ§a)...")

            num_cores = cpu_count();
            batch_size = (len(all_texts) // num_cores) + 1;
            batches = []
            for i in range(0, len(all_texts), batch_size): batches.append(
                (all_texts[i:i + batch_size], self.config.EMBEDDING_MODEL))

            all_vectors = []
            try:
                with Pool(processes=num_cores) as pool:
                    results = pool.map(worker_embed_batch_global, batches)
                    for res in results: all_vectors.extend(res)
            except Exception as e:
                print(f"âŒ Ä°ÅŸlemci HatasÄ±: {e}");
                return False

            print(f"      ğŸ’¾ Kaydediliyor...");
            points = []
            for i, (vec, meta, txt) in enumerate(zip(all_vectors, all_metadatas, all_texts)):
                payload = {"page_content": txt, "source": meta["source"], "page": meta["page"], "type": meta["type"]}
                point_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, txt + meta["source"] + collection_name))
                points.append(PointStruct(id=point_id, vector=vec, payload=payload))

            batch_size_upload = 64
            for i in range(0, len(points), batch_size_upload): self.client.upsert(collection_name,
                                                                                  points[i:i + batch_size_upload])

        print("âœ… Ä°ndeksleme TamamlandÄ±.");
        return True

    def retrieve_raw_candidates(self, full_query):
        print("\nğŸ” Belgeler TaranÄ±yor (Dual Search - AÅŸama 1: GeniÅŸ Havuz)...")
        try:
            query_vector = self.dense_embedder.embed_query(full_query)
        except Exception as e:
            print(f"âŒ Embedding HatasÄ±: {e}");
            return []

        all_candidates = []
        for key, config in self.config.SOURCES.items():
            try:
                results = self.client.query_points(collection_name=config["collection"], query=query_vector,
                                                   limit=self.config.SEARCH_LIMIT_PER_SOURCE).points
                for hit in results:
                    if 'type' not in hit.payload: hit.payload['type'] = config['desc']
                    all_candidates.append(hit)
            except:
                pass

        unique_docs = {}
        for hit in all_candidates:
            if hit.score < self.config.SCORE_THRESHOLD: continue
            key = f"{hit.payload['source']}_{hit.payload['page']}"
            if key not in unique_docs or hit.score > unique_docs[key].score: unique_docs[key] = hit

        # V101: KOTA SÄ°STEMÄ° UYGULAMASI
        emsal_hits = []
        mevzuat_hits = []

        for hit in unique_docs.values():
            if hit.payload.get('type') == 'MEVZUAT':
                mevzuat_hits.append(hit)
            else:
                emsal_hits.append(hit)

        emsal_hits.sort(key=lambda x: x.score, reverse=True)
        mevzuat_hits.sort(key=lambda x: x.score, reverse=True)

        limit = self.config.LLM_RERANK_LIMIT
        statute_quota = 3
        precedent_quota = limit - statute_quota

        final_candidates = emsal_hits[:precedent_quota] + mevzuat_hits[:statute_quota]

        if len(mevzuat_hits) < statute_quota:
            needed = limit - len(final_candidates)
            if needed > 0:
                extras = emsal_hits[precedent_quota: precedent_quota + needed]
                final_candidates.extend(extras)

        if not final_candidates: print("ğŸ”´ Uygun belge bulunamadÄ±."); return []
        print(f"   âœ… {len(final_candidates)} potansiyel belge bulundu. YargÄ±ca gÃ¶nderiliyor...")
        return final_candidates


# ==================================================
# 9ï¸âƒ£ YARGIÃ‡ VE MUHAKEME SINIFI (JUDGE)
# ==================================================
class LegalJudge:
    def __init__(self, memory_manager=None):
        # V120: Global Config KullanÄ±mÄ±
        self.llm = ChatOllama(
            model=LegalConfig.LLM_MODEL,
            temperature=LegalConfig.LLM_CONFIG["temperature"],
            top_p=LegalConfig.LLM_CONFIG["top_p"],
            # DiÄŸer parametreler LangChain entegrasyonuna gÃ¶re kwargs olarak geÃ§ilebilir
            # ancak temel olarak temp ve top_p yeterlidir.
        )
        self.memory = memory_manager
        self.sanitizer = LegalTextSanitizer()

    # ğŸ”¨ Commit 5.3: Build Query Context (Single Source)
    def build_query_context(self, story, topic, negatives) -> QueryContext:
        """
        Ham kullanÄ±cÄ± girdilerini alÄ±r, hukuk alanÄ±nÄ± tespit eder ve
        tek bir QueryContext nesnesi olarak paketler.
        """
        # Hukuk AlanÄ± Tespiti (Memory varsa oradan, yoksa basitÃ§e 'Genel')
        domain = "Genel"
        if self.memory:
            # Domain tespiti iÃ§in memory_manager iÃ§indeki fonksiyonu kullanÄ±yoruz
            domain = self.memory._detect_domain_from_query(f"{story} {topic}")

        ctx = QueryContext(
            query_text=story,
            topic=topic,
            detected_domain=domain,
            negative_scope=negatives,
            allowed_sources=["mevzuat", "emsal"],
            allow_analogy=False,
            allow_speculation=False,
            allow_soft_language=False
        )

        # GÃ¼venlik kemerini baÄŸla
        ctx.assert_hard_limits()

        return ctx

    def validate_user_input(self, story, topic):
        prompt = f"""
GÃ–REV: Metnin tamamen anlamsÄ±z rastgele tuÅŸlama (gibberish) olup olmadÄ±ÄŸÄ±nÄ± tespit et.
METÄ°N: "{story} {topic}"
ANALÄ°Z KURALLARI:
1. "araba", "miras" gibi tek kelimelik girdiler [GEÃ‡ERLÄ°].
2. Sadece "asdasd", "lkgjdf" gibi rastgele tuÅŸlamalar [GEÃ‡ERSÄ°Z].
CEVAP (SADECE BÄ°RÄ°): [GEÃ‡ERLÄ°] veya [GEÃ‡ERSÄ°Z]
"""
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "GEÃ‡ERSÄ°Z" in res: return False
            return True
        except:
            return True

    def generate_expanded_queries(self, story, topic):
        print("   â†³ ğŸ§  Sorgu GeniÅŸletiliyor...")
        try:
            prompt = f"GÃ–REV: Hukuki terimler.\nOLAY: {story}\nODAK: {topic}\n3 kÄ±sa cÃ¼mle."
            res = self.llm.invoke(prompt).content
            return [line.strip() for line in res.splitlines() if len(line) > 5][:3]
        except:
            return [story]

    # [YENÄ° EKLENEN METOT]
    def _build_scope_block(self, topic, negatives=None):
        scope = f"""
ALLOWED SCOPE (ZORUNLU):
- Analiz SADECE ÅŸu konu ile sÄ±nÄ±rlÄ± olacak: {topic}
- TÃ¼rk Hukuku (YargÄ±tay/BAM uygulamasÄ±)
- Somut olay ve delil odaklÄ± deÄŸerlendirme
"""
        if negatives:
            scope += "\nIMPLICITLY EXCLUDED (Bu alanlar analiz dÄ±ÅŸÄ±dÄ±r):\n"
            for n in negatives:
                scope += f"- {n}\n"

        scope += "\nBu sÄ±nÄ±rlarÄ±n DIÅINA Ã‡IKMA.\n"
        return scope

    def _check_relevance_judge_smart(self, user_query, user_filter, negative_keywords, document_text, source_name,
                                     doc_type="EMSAL"):
        found_negative = None
        if negative_keywords:
            doc_lower = document_text.lower()
            for bad in negative_keywords:
                if re.search(rf"\b{re.escape(bad)}\b", doc_lower): found_negative = bad; break

        if found_negative:
            prompt = f"HUKUKÃ‡U. Sorgu: '{user_query}'. YasaklÄ±: '{found_negative}'. Uygun mu? [RED]/[KABUL]."
            res = self.llm.invoke(prompt).content.strip()
            if "RED" in res: return False, f"â›” YASAKLI: {res}"

        memory_context = ""
        if self.memory:
            memory_context = self.memory.recall_principles(user_query)

        # [YENÄ°] Scope bloÄŸunun oluÅŸturulmasÄ±
        scope_block = self._build_scope_block(user_filter, negative_keywords)

        # V102: DOC TYPE SPECIFIC PROMPT
        if doc_type == "MEVZUAT":
            focus_instruction = "GÃ–REV: Bu kanun maddesi, yukarÄ±daki olaya HUKUKÄ° DAYANAK (Kanuni Temel) teÅŸkil ediyor mu?\nBenzerlik arama, uygulanabilirlik ara."
        else:
            focus_instruction = "GÃ–REV: Bu emsal karar, yukarÄ±daki olayla Ã–RGÃœ VE SONUÃ‡ bakÄ±mÄ±ndan BENZER mi?\nOlay benzerliÄŸi ara."

        prompt_gen = f"""
SEN KIDEMLI BIR HUKUKCUSSUN.

{scope_block}

{memory_context}

Sorgu: "{user_query}"
Belge ({doc_type}): "{document_text[:700]}..."

{focus_instruction}

SADECE BÄ°RÄ°NÄ° SEÃ‡: [Ã‡OK BENZER/UYGUN], [BENZER/UYGUN], [ZAYIF/ALAKASIZ]
AltÄ±na tek cÃ¼mlelik gerekÃ§e yaz.
"""
        res = self.llm.invoke(prompt_gen).content.strip()
        is_ok = ("Ã‡OK BENZER" in res) or ("BENZER" in res) or ("UYGUN" in res) or ("KABUL" in res)
        return is_ok, res

    def _assign_document_role(self, user_query, document_text):
        prompt = f"""
SEN HUKUKÃ‡USUN.
Sorgu: "{user_query}"
Belge: "{document_text[:800]}..."
GÃ–REV: Bu belge hukuki analizde nasÄ±l kullanÄ±lmalÄ±?
1. [DOÄRUDAN DELÄ°L]: Olay Ã¶rgÃ¼sÃ¼ birebir Ã¶rtÃ¼ÅŸÃ¼yor.
2. [EMSAL Ä°LKE]: Olay farklÄ± ama hukuk kuralÄ± uygulanabilir.
SADECE ÅUNLARDAN BÄ°RÄ°NÄ° SEÃ‡:
[DOÄRUDAN DELÄ°L] veya [EMSAL Ä°LKE]
"""
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "DOÄRUDAN" in res: return "[DOÄRUDAN DELÄ°L]"
            return "[EMSAL Ä°LKE]"
        except:
            return "[EMSAL Ä°LKE]"

    def evaluate_candidates(self, candidates, story, topic, negatives):
        print("\nâš–ï¸  AkÄ±llÄ± YargÄ±Ã§ DeÄŸerlendiriyor (V120: Corporate Intelligence):")
        valid_docs = []

        for hit in candidates:
            doc_text = hit.payload['page_content']
            source = hit.payload['source']
            page = hit.payload['page']
            type_desc = hit.payload['type']

            is_ok, reason = self._check_relevance_judge_smart(story, topic, negatives, doc_text, source, type_desc)

            consensus_multiplier = 1.0
            if self.memory:
                consensus_decision = "KABUL" if is_ok else "RED"
                consensus_multiplier = self.memory.calculate_memory_consensus(source, consensus_decision, hit.score)

            base_score = min(max(hit.score, 0), 1) * 100
            norm_score = min(base_score * consensus_multiplier, 100.0)

            icon = "âœ…" if is_ok else "âŒ"

            if self.memory:
                decision_tag = "KABUL" if is_ok else "RED"
                self.memory.save_decision(f"{story} {topic}", source, decision_tag, reason, type_desc)

            if is_ok:
                role = self._assign_document_role(story, doc_text)

                log_score = f"%{norm_score:.1f}"
                if consensus_multiplier > 1.1:
                    log_score += " (â¬†ï¸ YÃœKSEK GÃœVEN)"
                elif consensus_multiplier < 1.0:
                    log_score += " (â¬‡ï¸ RÄ°SKLÄ°)"

                print(f"{icon} [{type_desc}] {source:<20} | GÃ¼ven: {log_score} | Rol: {role}")

                extra_context = ""
                if type_desc == "EMSAL KARAR":
                    real_path = os.path.join(LegalConfig.SOURCES["emsal"]["folder"], source)
                    verdict = LegalUtils.extract_pdf_conclusion(real_path)
                    extra_context = f"\n\nğŸ›‘ [OTOMATÄ°K EKLENEN KARAR SONUCU ({source})]:\n{verdict}\nğŸ›‘ KARAR SONU."

                valid_docs.append({
                    "source": source, "page": page, "type": type_desc, "role": role,
                    "text": doc_text + extra_context, "score": norm_score, "reason": reason
                })
            else:
                print(f"{icon} [{type_desc}] {source:<20} | GÃ¼ven: %{norm_score:.1f}")

        return valid_docs

    # [V128 EKLENTÄ°SÄ°] PDF Ä°Ã§in Emsal AÃ§Ä±klama KartlarÄ±
    def explain_precedents_for_pdf(self, accepted_docs, topic):
        print("\nğŸ“ PDF Ä°Ã§in Emsal KartlarÄ± HazÄ±rlanÄ±yor...")
        cards = []

        # Sadece kabul edilen ve anlamlÄ± rolÃ¼ olan belgeleri seÃ§iyoruz
        targets = [d for d in accepted_docs if d.get("role") in ["[EMSAL Ä°LKE]", "[DOÄRUDAN DELÄ°L]"]]

        for doc in targets:
            prompt = f"""
SEN BÄ°R TÃœRK HUKUKÃ‡USUSUN.
Ama bu bir KARAR deÄŸil, PDF RAPOR AÃ‡IKLAMASIDIR.

KONU: {topic}

BELGE:
- Dosya: {doc['source']}
- Sayfa: {doc['page']}
- Rol: {doc['role']}
- GerekÃ§e: {doc.get('reason', '')}

METÄ°N PARÃ‡ASI:
\"\"\"{doc['text'][:800]}...\"\"\"

GÃ–REV:
Bu belgenin neden bu dosya aÃ§Ä±sÄ±ndan Ã¶nemli olduÄŸunu,
avukatÄ±n veya mÃ¼vekkilin rahatÃ§a okuyabileceÄŸi ÅŸekilde aÃ§Ä±kla.

KURALLAR:
- Hukuki uydurma YAPMA
- Genel ders anlatÄ±mÄ± YAPMA
- Hakim gibi hÃ¼kÃ¼m kurma
- 1 paragrafÄ± geÃ§me
- "Bu belge Ã¶nemlidir" diye baÅŸlama, direkt iÃ§eriÄŸe gir.

Ã‡IKTI FORMATI:
**GerekÃ§e:** [AÃ§Ä±klama]
**Ä°Ã§erik:** [Ã–zet]
"""
            try:
                explanation = self.llm.invoke(prompt).content.strip()
                cards.append({
                    "filename": doc["source"],
                    "page": doc["page"],
                    "role": doc["role"],
                    "content": explanation
                })
            except Exception as e:
                print(f"âš ï¸ Kart oluÅŸturma hatasÄ±: {e}")

        return cards

    # -------------------------------------------------------------------------
    # DÃœZELTME 1: JudgeReflex parametresi eklendi ve Prompt kÄ±sÄ±tlandÄ±
    # -------------------------------------------------------------------------
    def generate_final_opinion(self, story, topic, context_str, judge_reflex=None):
        print("\nğŸ§‘â€âš–ï¸  AVUKAT YAZIYOR (V120: Final Output)...")

        # EÄŸer JudgeCore sonucu geldiyse prompt'a gÃ¶mÃ¼yoruz
        decision_lock = ""
        if judge_reflex:
            decision_lock = f"""
        ğŸ›‘ KESÄ°N TALÄ°MAT (JUDGE CORE LOCK):
        Sistem tarafÄ±ndan yapÄ±lan matematiksel analiz sonucunda:
        1. HAKÄ°M EÄÄ°LÄ°MÄ°: "{judge_reflex.tendency}" olarak tespit edilmiÅŸtir.
        2. DOSYA GÃœÃ‡ SKORU: {judge_reflex.score}/100
        3. TESPÄ°T EDÄ°LEN TEREDDÃœTLER: {', '.join(judge_reflex.doubts)}

        GÃ–REVÄ°N:
        YENÄ°DEN HÃœKÃœM KURMAK DEÄÄ°L, YUKARIDAKÄ° "{judge_reflex.tendency}" KARARINI HUKUKÄ° DÄ°LLE GEREKÃ‡ELENDÄ°RMEKTÄ°R.
        Analizini bu kararÄ± destekleyecek veya bu kararÄ±n risklerini aÃ§Ä±klayacak ÅŸekilde yap.
        """

        system_content = f"""SEN, TÃœRK MAHKEMESÄ°NDE GÃ–REVLÄ° BÄ°R HAKÄ°M RAPORTÃ–RÃœSÃœN.
HÃœKMÃœ SEN VERMÄ°YORSUN; VERÄ°LMÄ°Å HÃœKMÃœN GEREKÃ‡ESÄ°NÄ° YAZIYORSUN.
{LegalConfig.PROMPT_GUARD}

ğŸ›‘ KRÄ°TÄ°K VE ZORUNLU KURAL:
BU SÄ°STEM SADECE TÃœRKÃ‡E Ã‡ALIÅIR. 

{decision_lock}

HER NE OLURSA OLSUN Ã‡IKTIYI SADECE VE SADECE **TÃœRKÃ‡E** DÄ°LÄ°NDE VER.
(RESPONSE MUST BE ONLY IN TURKISH LANGUAGE. DO NOT USE CHINESE OR ENGLISH.)

GÃ¶revin:
- TaraflarÄ± savunmak DEÄÄ°L
- JudgeCore tarafÄ±ndan belirlenen eÄŸilim doÄŸrultusunda
  RED riskinin nedenleri ve azaltma yollarÄ±nÄ± deÄŸerlendir.

NORMLAR HÄ°YERARÅÄ°SÄ° (ZORUNLU):
- [MEVZUAT] etiketli metinler KANUN maddesidir (TMK, BK vb.). BunlarÄ± kesin kural olarak sun.
- [EMSAL KARAR] etiketli metinler YARGITAY uygulamasÄ±dÄ±r. BunlarÄ± "yorum ve uygulama" olarak sun.

Ã–N KABULLER:
1. Veraset ilamÄ± Ã§ekiÅŸmesiz yargÄ± iÅŸidir.
2. Ã‡ekiÅŸmesiz yargÄ± kararlarÄ± maddi anlamda kesin hÃ¼kÃ¼m oluÅŸturmaz.
3. Hakim her zaman Ã¶nce RED ihtimalini deÄŸerlendirir.
4. Usul eksikliÄŸi varsa ESASA GÄ°RÄ°LMEZ.
5. Analiz bÃ¶lÃ¼mÃ¼nde en fazla 5 belge kullan.
6. Her belge en fazla 3 cÃ¼mleyle Ã¶zetlenir.
7. AynÄ± belge ikinci kez yazÄ±lamaz.


SANA SAÄLANAN BELGELER ETÄ°KETLÄ°DÄ°R:
- [MEVZUAT]
- [EMSAL KARAR]

BELGE DIÅINA Ã‡IKMA.
YENÄ° EMSAL UYDURMA.
GENEL HUKUK ANLATISI YAPMA.

----------------------------------------------------------------
AÅAMA 1 â€” JUDGE CORE DEÄERLENDÄ°RMESÄ°NÄ°N HUKUKÄ° OKUMASI
----------------------------------------------------------------
UYARI:
Bu aÅŸamada YENÄ° bir deÄŸerlendirme yapma.
Sadece JudgeCore tarafÄ±ndan tespit edilen tereddÃ¼tleri hukuki dile Ã§evir.
Yeni tereddÃ¼t ekleme.

AÅŸaÄŸÄ±daki sorularÄ± KENDÄ°N iÃ§in cevapla ve analizini buna gÃ¶re yap:

- Dosya usulden reddedilebilir mi?
- Hakimin temel tereddÃ¼t noktalarÄ± neler?
- Sunulan emsal kararlar:
  - YerleÅŸik mi?
  - GÃ¼ncel mi?
  - Somut olayla birebir mi?
- Bu dosyada hakimin takdir alanÄ± var mÄ±?

----------------------------------------------------------------
AÅAMA 2 â€” YAPILANDIRILMIÅ HUKUKÄ° RAPOR
----------------------------------------------------------------

Ã‡IKTIYI AÅAÄIDAKÄ° BAÅLIKLARLA VE AYNI SIRAYLA VER.
BAÅLIKLARI VE SIRAYI ASLA DEÄÄ°ÅTÄ°RME.

------------------------------------------------------------
A. MEVZUAT DAYANAKLARI
------------------------------------------------------------
Burada:
- SADECE [MEVZUAT] etiketli belgeleri kullan.
- Ä°lgili kanun maddelerini KISA ve NET ÅŸekilde Ã¶zetle.
- Somut olayla doÄŸrudan baÄŸlantÄ±yÄ± belirt.
- Yorum yapma, normu aÃ§Ä±kla.
- AynÄ± kanun maddesini birden fazla kez Ã¶zetleme.
- Her madde numarasÄ±nÄ± sadece bir kez belirt.

------------------------------------------------------------
B. Ä°LGÄ°LÄ° EMSAL KARARLAR (ZORUNLU BÃ–LÃœM)
------------------------------------------------------------
Burada:
- SADECE [EMSAL KARAR] etiketli belgeleri kullan. En az 2 emsal karar Ã–ZETLE.
- Her emsal iÃ§in:
  - Karar numarasÄ± / tarihi (varsa)
  - YargÄ±tay dairesi
  - ROLâ€™Ã¼nÃ¼ belirt (EMSAL Ä°LKE / DESTEKLEYÄ°CÄ° / AYIRT EDÄ°LEBÄ°LÄ°R)
  - Hakimin bakÄ±ÅŸ aÃ§Ä±sÄ±ndan kÄ±sa GEREKÃ‡E yaz (2-3 cÃ¼mle)
- EÄŸer emsal yoksa "Somut olayla doÄŸrudan ilgili gÃ¼ncel emsal karar tespit edilememiÅŸtir." yaz.

------------------------------------------------------------
C. SONUÃ‡ VE HUKUKÄ° TAVSÄ°YE
------------------------------------------------------------
Burada:
- KullanÄ±cÄ±nÄ±n anlattÄ±ÄŸÄ± somut olaya gÃ¶re konuÅŸ.
- Bulunan emsaller ve mevzuata dayanarak:
  - DosyanÄ±n ZAYIF yÃ¶nlerini aÃ§Ä±kla
  - GÃ¼Ã§lendirilmesi gereken noktalarÄ± belirt
  - Net bir yol haritasÄ± Ã§iz (ne yapÄ±lmalÄ± / ne yapÄ±lmamalÄ±)
- â€œÅu yapÄ±lÄ±rsa RED riski azalÄ±râ€ mantÄ±ÄŸÄ±yla yaz.
- DosyanÄ±n kabul edilme ihtimalini dÃ¼ÅŸÃ¼k/orta/yÃ¼ksek olarak belirt.
- Red riskini azaltmak iÃ§in 2-3 somut aksiyon Ã¶ner.

----------------------------------------------------------------
YASAKLAR:
- Genel hukuk anlatÄ±sÄ±
- Akademik aÃ§Ä±klama
- AynÄ± fikri tekrar etmek
- Belge dÄ±ÅŸÄ± yorum

SADECE BU DOSYAYI VE SAÄLANAN BELGELERÄ° DEÄERLENDÄ°R. CEVABI TÃœRKÃ‡E YAZ.
"""

        user_content = f"""AÅŸaÄŸÄ±daki "DELÄ°LLER" listesinde sunulan belgeleri kullanarak olayÄ± analiz et.
OLAY: "{story}"
ODAK: "{topic}"
DELÄ°LLER:
{context_str}
ANALÄ°ZÄ° BAÅLAT (TÃœRKÃ‡E):"""

        messages = [SystemMessage(content=system_content), HumanMessage(content=user_content)]

        full_res = ""
        for chunk in self.llm.stream(messages):
            c = chunk.content;
            full_res += c;
            print(c, end="", flush=True)
        print("\n")

        # V120 SANITIZATION
        cleaned_res = self.sanitizer.enforce_no_repeat(full_res)

        if judge_reflex and not _contains_decision(cleaned_res, judge_reflex.tendency):
            cleaned_res = (
                    f"âš ï¸ JUDGE CORE EÄÄ°LÄ°MÄ°: {judge_reflex.tendency}\n\n"
                    + cleaned_res
            )

        return cleaned_res


# ==================================================
# ğŸ”Ÿ RAPORLAMA SINIFI (V120 - ROBUST FONT LOADER)
# ==================================================
class BrandedPDFGenerator(FPDF):
    def __init__(self, branding):
        super().__init__()
        self.branding = branding
        self.font_loaded = False

        # Font YollarÄ± (Ã–ncelik SÄ±rasÄ±)
        possible_paths = [
            "fonts/DejaVuSans.ttf",  # 1. Yerel klasÃ¶r
            os.path.join(LegalConfig.DRIVE_ROOT, "fonts/DejaVuSans.ttf"),  # 2. Drive klasÃ¶rÃ¼
            "/content/drive/MyDrive/HukAI/fonts/DejaVuSans.ttf"  # 3. Tam yol (Hardcoded)
        ]

        font_path = None
        for p in possible_paths:
            if os.path.exists(p):
                font_path = p
                break

        # Font YÃ¼kleme Denemesi
        if font_path:
            try:
                self.add_font("DejaVu", "", font_path)
                # Bold iÃ§in de aynÄ±sÄ±nÄ± veya regular'Ä± kullan
                bold_path = font_path.replace("Sans.ttf", "Sans-Bold.ttf")
                if os.path.exists(bold_path):
                    self.add_font("DejaVu", "B", bold_path)
                    self.add_font("DejaVu", "BI", bold_path)
                else:
                    self.add_font("DejaVu", "B", font_path)  # Fallback
                    self.add_font("DejaVu", "BI", font_path)  # Fallback

                self.add_font("DejaVu", "I", font_path)
                self.font_loaded = True
                print(f"âœ… PDF Fontu YÃ¼klendi: {font_path}")
            except Exception as e:
                print(f"âš ï¸ Font yÃ¼kleme hatasÄ±: {e}")
        else:
            print(f"âš ï¸ UYARI: DejaVuSans.ttf bulunamadÄ±! TÃ¼rkÃ§e karakterler bozuk Ã§Ä±kabilir.")
            print(
                f"   LÃ¼tfen ÅŸu dosyayÄ± indirip 'HukAI/fonts' klasÃ¶rÃ¼ne koyun: https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans.ttf")

    def header(self):
        if self.branding.logo_path and os.path.exists(self.branding.logo_path):
            self.image(self.branding.logo_path, x=10, y=8, w=30)

        # Font SeÃ§imi
        font = "DejaVu" if self.font_loaded else "helvetica"

        self.set_font(font, "B", 12)
        self.set_text_color(*self.branding.color)
        self.cell(0, 10, self.branding.firm_name, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')
        self.set_draw_color(200, 200, 200)
        self.line(10, 25, 200, 25)
        self.ln(15)
        self.set_text_color(0, 0, 0)

    def footer(self):
        self.set_y(-15)
        font = "DejaVu" if self.font_loaded else "helvetica"
        self.set_font(font, 'I', 8)
        self.set_text_color(128, 128, 128)
        self.cell(0, 10, f'{self.branding.footer_text} | Sayfa {self.page_no()}', align='C')


class LegalReporter:
    @staticmethod
    def add_persona_comparison_page(pdf, personas):
        if not personas: return
        pdf.add_page()
        pdf.set_font("DejaVu", "B", 12)
        pdf.cell(0, 10, "EK-2: YARGISAL PERSPEKTIF KARSILASTIRMASI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)

        col_width = pdf.epw / 3
        start_y = pdf.get_y()

        p_list = [
            ("HAKIM", personas.get("judge", "")),
            ("KARSI TARAF", personas.get("opponent", "")),
            ("BILIRKISI", personas.get("expert", ""))
        ]

        max_y = start_y
        for i, (title, text) in enumerate(p_list):
            x = pdf.l_margin + i * col_width
            pdf.set_xy(x, start_y)
            pdf.set_font("DejaVu", "B", 10)
            pdf.multi_cell(col_width - 2, 6, title, align='C')
            pdf.ln(1)
            pdf.set_xy(x, pdf.get_y())  # Reset X after multicell
            pdf.set_font("DejaVu", size=8)
            pdf.multi_cell(col_width - 2, 4, text)
            max_y = max(max_y, pdf.get_y())

        pdf.set_y(max_y + 10)

    @staticmethod
    def add_appeal_arguments_page(pdf, appeal_text):
        if not appeal_text: return
        pdf.add_page()
        pdf.set_font("DejaVu", "B", 12)
        pdf.cell(0, 10, "EK-3: OLASI ITIRAZ ARGUMANLARI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)
        pdf.set_font("DejaVu", "", 10)
        pdf.multi_cell(0, 6, appeal_text)

    @staticmethod
    def add_petition_page(pdf, petition_text):
        if not petition_text: return
        pdf.add_page()
        pdf.set_font("DejaVu", "B", 12)
        pdf.cell(0, 10, "EK-4: ISTINAF / TEMYIZ DILEKCESI TASLAGI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)
        pdf.set_font("DejaVu", "", 10)
        pdf.multi_cell(0, 6, petition_text)

    @staticmethod
    def add_action_plan_page(pdf, action_plan):
        if not action_plan: return
        pdf.add_page()
        pdf.set_font("DejaVu", "B", 12)
        pdf.cell(0, 10, "EK-5: ITIRAZ AKSÄ°YON PLANI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)

        for action in action_plan:
            pdf.set_font("DejaVu", "B", 10)
            pdf.cell(0, 8, f">> {action.get('title', 'Aksiyon')}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            pdf.set_font("DejaVu", size=9)
            pdf.multi_cell(0, 5, f"Kaynak: {action.get('source', '')} | Risk: {action.get('risk_if_missing', '')}")
            pdf.ln(2)

    @staticmethod
    def add_audit_log_section(pdf, audit_data):
        if not audit_data or "timeline" not in audit_data: return
        pdf.add_page()
        pdf.set_font("DejaVu", "B", 13)
        pdf.cell(0, 10, "3. KARAR SURECI VE DENETIM (AUDIT LOG)", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(3)

        timeline = AuditTimelineBuilder.build(audit_data)
        explanation = ScoreExplanationEngine.generate(timeline)

        pdf.set_font("DejaVu", "B", 10)
        pdf.cell(0, 8, "SKOR DEGISIM ANALIZI:", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", "I", 10)
        pdf.multi_cell(0, 5, explanation)
        pdf.ln(5)

        for log in audit_data["timeline"]:
            step = log.get("step", 0)
            title = log.get("title", "Islem")
            desc = log.get("description", "")
            score = log.get("resulting_score")
            ts = datetime.fromtimestamp(log.get("timestamp", time.time())).strftime('%H:%M:%S')

            pdf.set_font("DejaVu", "B", 10)
            pdf.cell(0, 6, f"{step}. {title.upper()} [{ts}]", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            pdf.set_font("DejaVu", size=9)
            pdf.multi_cell(w=0, h=5, text=f"Detay: {desc}")
            if score:
                pdf.set_font("DejaVu", "B", 8)
                pdf.cell(0, 5, f">> SKOR ETKISI: %{score}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            pdf.ln(2)

    # V120: YENÄ° PERSONA BÃ–LÃœMÃœ
    @staticmethod
    def add_persona_debate_section_v120(pdf, personas_data):
        if not personas_data: return

        pdf.add_page()
        pdf.set_font("DejaVu", "B", 14)
        # Siyah zemin Ã¼zerine beyaz yazÄ± efekti simÃ¼lasyonu (Draw Rect + White Text)
        pdf.set_fill_color(0, 0, 0)
        pdf.rect(pdf.get_x(), pdf.get_y(), 190, 12, 'F')
        pdf.set_text_color(255, 255, 255)
        pdf.cell(0, 12, "X. YARGISAL TARTISMA VE TARAFLARIN POZISYONU", align='C', new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_text_color(0, 0, 0)  # Rengi geri al
        pdf.ln(5)

        # 1. DAVACI VEKÄ°LÄ°
        pdf.set_font("DejaVu", "B", 11)
        pdf.set_text_color(0, 102, 51)  # Koyu YeÅŸil
        pdf.cell(0, 8, "DAVACI VEKILI DEGERLENDIRMESI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_text_color(0, 0, 0)
        pdf.set_font("DejaVu", "", 10)
        pdf.multi_cell(0, 5, personas_data.get("plaintiff", "Veri yok."))
        pdf.ln(5)

        # 2. DAVALI VEKÄ°LÄ°
        pdf.set_font("DejaVu", "B", 11)
        pdf.set_text_color(153, 0, 0)  # Koyu KÄ±rmÄ±zÄ±
        pdf.cell(0, 8, "DAVALI VEKILI (KARSI TARAF) DEGERLENDIRMESI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_text_color(0, 0, 0)
        pdf.set_font("DejaVu", "", 10)
        pdf.multi_cell(0, 5, personas_data.get("defendant", "Veri yok."))
        pdf.ln(5)

        # 3. BÄ°LÄ°RKÄ°ÅÄ°
        pdf.set_font("DejaVu", "B", 11)
        pdf.set_text_color(0, 51, 102)  # Lacivert
        pdf.cell(0, 8, "TARAFSIZ BILIRKISI TESPITLERI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_text_color(0, 0, 0)
        pdf.set_font("DejaVu", "I", 10)
        pdf.multi_cell(0, 5, personas_data.get("expert", "Veri yok."))
        pdf.ln(5)

        # 4. FINAL NOTU
        pdf.set_draw_color(100, 100, 100)
        pdf.line(pdf.get_x(), pdf.get_y(), 200, pdf.get_y())
        pdf.ln(2)
        pdf.set_font("DejaVu", "B", 10)
        pdf.cell(0, 6, "HAKIMIN PERSONA SONRASI DEGERLENDIRMESI:", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", "", 9)
        reflex = personas_data.get("judge_reflex", "Belirsiz")
        pdf.multi_cell(0, 5,
                       f"Taraflarin beyanlari birlikte degerlendirildiginde, hakimin ilk refleksi olan '{reflex}' egilimi cercevesinde, bazi tereddutlerin giderildigi ancak dosyanin kabulu icin ek aciklama ve belge sunulmasinin gerekli oldugu kanaatine varilmistir.")

    # [V128 EKLENTÄ°SÄ°] PDF Emsal KartlarÄ± BÃ¶lÃ¼mÃ¼
    @staticmethod
    def add_precedent_cards_section(pdf, cards):
        if not cards: return

        pdf.add_page()
        pdf.set_font("DejaVu", "B", 12)
        pdf.cell(0, 10, "EK-1: DETAYLI EMSAL ANALÄ°Z KARTLARI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)

        for card in cards:
            # Kart BaÅŸlÄ±ÄŸÄ± (Gri ArkaplanlÄ±)
            pdf.set_fill_color(240, 240, 240)
            pdf.set_font("DejaVu", "B", 10)
            header = f"ğŸ“„ {card['filename']} (Sayfa {card['page']}) | {card['role']}"
            pdf.cell(0, 8, header, fill=True, new_x=XPos.LMARGIN, new_y=YPos.NEXT)

            # Kart Ä°Ã§eriÄŸi
            pdf.set_font("DejaVu", "", 9)
            # Ä°Ã§erikteki Markdown bold (**) iÅŸaretlerini temizle veya iÅŸle
            clean_content = card['content'].replace("**", "")
            pdf.multi_cell(0, 5, clean_content)
            pdf.ln(4)

            # AyÄ±rÄ±cÄ± Ã‡izgi
            pdf.set_draw_color(200, 200, 200)
            pdf.line(pdf.get_x(), pdf.get_y(), 200, pdf.get_y())
            pdf.ln(4)

    # ğŸ”¨ Commit 5.1: Yeni HÄ±zlÄ± Ã–zet SayfasÄ± Metodu
    @staticmethod
    def add_executive_summary_page(pdf, story, docs, personas, advice_text):
        pdf.add_page()
        pdf.set_font("DejaVu", "B", 16)
        pdf.cell(0, 10, "YÃ–NETÄ°CÄ° Ã–ZETÄ° (Executive Summary)", align='C', new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(10)

        def clean(t):
            return t.replace("\r", "") if t else ""

        # 1. Sorgu Ã–zeti
        pdf.set_font("DejaVu", "B", 11)
        pdf.cell(0, 8, "1. SORGU Ã–ZETÄ°:", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", "", 10)
        pdf.multi_cell(0, 6, clean(story)[:400] + ("..." if len(story) > 400 else ""))
        pdf.ln(5)

        # 2. 3 Ana Hukuki BulgÄ±
        pdf.set_font("DejaVu", "B", 11)
        pdf.cell(0, 8, "2. ANA HUKUKÄ° BULGULAR:", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", "", 10)
        if docs:
            count = 0
            for d in docs:
                if count >= 3: break
                # Type ve Reason kullanarak Ã¶zetle
                bullet = f"â€¢ {d['type']} ({d['role']}): {d['reason']}"
                pdf.multi_cell(0, 6, clean(bullet))
                count += 1
        else:
            pdf.multi_cell(0, 6, "Yeterli hukuki bulgu elde edilemedi.")
        pdf.ln(5)

        # 3. Hakim Riski
        pdf.set_font("DejaVu", "B", 11)
        pdf.cell(0, 8, "3. HAKÄ°M RÄ°SKÄ° (EÄÄ°LÄ°M):", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", "B", 10)  # Biraz daha vurgulu
        risk = "Belirsiz"
        if personas and "judge_reflex" in personas:
            risk = personas["judge_reflex"]
        pdf.cell(0, 8, f">> {clean(risk)}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)

        # 4. Net Ã–neri
        # Advice text iÃ§inden sonucu Ã§Ä±karmaya Ã§alÄ±ÅŸalÄ±m veya son paragrafÄ± alalÄ±m
        recommendation = "DetaylÄ± raporda sonuÃ§ bÃ¶lÃ¼mÃ¼nÃ¼ inceleyiniz."
        if advice_text:
            # Basit bir parsing denemesi: SonuÃ§ baÅŸlÄ±ÄŸÄ±nÄ± ara
            parts = advice_text.split("C. SONUÃ‡ VE HUKUKÄ° TAVSÄ°YE")
            if len(parts) > 1:
                recommendation = parts[1].strip()[:600] + "..."  # Ä°lk 600 karakter
            else:
                # Son 500 karakteri al
                recommendation = advice_text[-500:]

        pdf.set_font("DejaVu", "B", 11)
        pdf.cell(0, 8, "4. NET Ã–NERÄ°:", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("DejaVu", "I", 10)
        pdf.multi_cell(0, 6, clean(recommendation))
        pdf.ln(5)

        # Sayfa sonu Ã§izgisi
        pdf.set_draw_color(0, 0, 0)
        pdf.line(10, pdf.get_y(), 200, pdf.get_y())

    @staticmethod
    def create_report(user_story, valid_docs, advice_text, audit_data=None, filename="Hukuki_Rapor_V120.pdf", llm=None,
                      personas=None, case_topic="", precedent_cards=None):
        branding = WhiteLabelConfig(
            firm_name="LEGAL OS CORP",
            footer_text="Gizli ve Ozeldir - Otomatik Analiz Raporu",
            color=(0, 51, 102)
        )
        pdf = BrandedPDFGenerator(branding)

        CorporateCover.add(pdf, audit_data.get("case_id", "N/A") if audit_data else "N/A", "V120")

        # ğŸ”¨ Commit 5.1 Entegrasyonu: HÄ±zlÄ± Ã–zet SayfasÄ± Ekle
        LegalReporter.add_executive_summary_page(pdf, user_story, valid_docs, personas, advice_text)

        pdf.add_page();
        pdf.set_font("DejaVu", size=11)

        # V120 FIX: Latin-1 zorlamasÄ± kaldÄ±rÄ±ldÄ±. DejaVu fontu Unicode destekler.
        def clean(t):
            if not t: return ""
            # Sadece PDF'i bozabilecek kontrol karakterlerini temizle
            return t.replace("\r", "")

        # 1. OLAY VE KAPSAM
        pdf.set_font(style='B', size=12);
        pdf.cell(0, 10, clean("1. OLAY VE KAPSAM:"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font(style='', size=10);
        pdf.multi_cell(0, 6, clean(user_story));
        pdf.ln(5)

        # 2. Ä°NCELEME VE HUKUKÄ° GÃ–RÃœÅ
        pdf.set_font(style='B', size=12);
        pdf.cell(0, 10, clean("2. INCELEME VE HUKUKI GORUS:"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font(style='', size=10);
        pdf.multi_cell(0, 6, clean(advice_text))

        # 3. YARGISAL TARTIÅMA (PERSONA)
        if personas:
            clean_personas = {k: clean(v) if isinstance(v, str) else v for k, v in personas.items()}
            if "judge_reflex" in personas:
                LegalReporter.add_persona_debate_section_v120(pdf, clean_personas)
            else:
                LegalReporter.add_persona_comparison_page(pdf, clean_personas)  # Fallback

        # 4. KARAR SÃœRECÄ° VE DENETÄ°M (AUDIT)
        if audit_data:
            LegalReporter.add_audit_log_section(pdf, audit_data)

            if llm:
                # [V128 EKLENTÄ°SÄ°] PDF KartlarÄ±
                if precedent_cards:
                    LegalReporter.add_precedent_cards_section(pdf, precedent_cards)

                # EK-1 (Åimdiki EK-2): HAKÄ°M KARAR GEREKÃ‡ESÄ°
                reasoning_gen = JudgeReasoningGenerator(llm)
                judge_text = reasoning_gen.generate(
                    audit_logs=audit_data,
                    story=user_story,
                    context_str=advice_text
                )

                pdf.add_page()
                pdf.set_font("DejaVu", "B", 13)
                pdf.cell(0, 10, clean("EK-2: HAKIM KARAR GEREKCESI TASLAGI"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
                pdf.ln(5)
                pdf.set_font("DejaVu", "I", 10)
                pdf.multi_cell(0, 6, clean(judge_text))

                appeal_gen = AppealArgumentGenerator(llm)
                appeal_text = appeal_gen.generate(judge_text)

                # EK-3: OLASI Ä°TÄ°RAZ ARGÃœMANLARI
                LegalReporter.add_appeal_arguments_page(pdf, clean(appeal_text))

                # EK-4: Ä°STÄ°NAF DÄ°LEKÃ‡ESÄ°
                petition_gen = AppealPetitionGenerator(llm)
                petition_text = petition_gen.generate(judge_text, case_topic)
                LegalReporter.add_petition_page(pdf, clean(petition_text))

                # EK-5: Ä°TÄ°RAZ AKSÄ°YON PLANI
                action_mapper = AppealActionMapper(llm)
                action_plan = action_mapper.map_arguments(appeal_text)
                for ap in action_plan:
                    ap['title'] = clean(ap.get('title', ''))
                    ap['source'] = clean(ap.get('source', ''))
                    ap['risk_if_missing'] = clean(ap.get('risk_if_missing', ''))
                LegalReporter.add_action_plan_page(pdf, action_plan)

        try:
            pdf.output(filename);
            print(f"\nğŸ“„ Kurumsal Rapor (V120) HazÄ±r: {filename}")
        except:
            pass


# ==================================================
# 1ï¸âƒ£1ï¸âƒ£ LEGAL UI PRINTER
# ==================================================
class LegalUIPrinter:
    # ğŸ”¨ Commit 5.2: Sade Log Tablosu
    @staticmethod
    def print_simple_console_table(audit_data):
        if not audit_data or "timeline" not in audit_data: return

        print("\n" + "=" * 80)
        print(f"ğŸ“Š Ä°ÅLEM Ã–ZET TABLOSU (Commit 5.2)")
        print("=" * 80)
        # BaÅŸlÄ±klar: Zaman | AÅŸama | SonuÃ§
        print(f"| {'ZAMAN':<10} | {'AÅAMA':<25} | {'SONUÃ‡':<38} |")
        print("|" + "-" * 12 + "|" + "-" * 27 + "|" + "-" * 40 + "|")

        for log in audit_data["timeline"]:
            ts = datetime.fromtimestamp(log.get("timestamp", time.time())).strftime('%H:%M:%S')
            stage = log.get("title", "Ä°ÅŸlem")[:24]
            # SonuÃ§ kÄ±smÄ±na score varsa onu, yoksa kÄ±sa description, yoksa boÅŸ
            result = ""
            if log.get("resulting_score"):
                result = f"Skor: {log['resulting_score']}"
            elif log.get("outputs") and "reflex" in log["outputs"]:
                result = f"Refleks: {log['outputs']['reflex']}"
            else:
                result = log.get("description", "")[:37]

            print(f"| {ts:<10} | {stage:<25} | {result:<38} |")

        print("=" * 80 + "\n")

    @staticmethod
    def print_grand_ui_log(ui_data, doc_scan_log):
        if not ui_data or not ui_data.get("principles"): return

        print("\n" + "â–ˆ" * 80)
        print(f"ğŸ–¥ï¸  LEGAL OS V120 - YARGISAL ANALÄ°Z VE TARTIÅMA RAPORU")
        print("â–ˆ" * 80 + "\n")

        # AUDIT TIMELINE (V120 FORMAT)
        print(f"â±ï¸ Ä°ÅLEM ZAMAN Ã‡Ä°ZELGESÄ° (AUDIT LOG V120):")
        for log in ui_data.get("audit_log", {}).get("timeline", []):
            ts = datetime.fromtimestamp(log['timestamp']).strftime('%H:%M:%S')

            # V120 Ã–zel Ä°konlar
            icon = "ğŸ”¹"
            if log['stage'] == "judge_analysis":
                icon = "ğŸ§ "
            elif log['stage'] == "persona_phase":
                icon = "âš”ï¸"
            elif log['stage'] == "plaintiff_arg":
                icon = "ğŸ‘¨â€ğŸ’¼"
            elif log['stage'] == "defendant_arg":
                icon = "ğŸ›ï¸"
            elif log['stage'] == "expert_arg":
                icon = "ğŸ”"
            elif log['stage'] == "persona_completed":
                icon = "âš–ï¸"
            elif log['stage'] == "output_sanitizer":
                icon = "ğŸ§¹"

            print(f"   {icon} [{ts}] {log['title']}")
            if log.get('description'):
                print(f"      â†³ {log['description']}")
            # Outputs detaylarÄ±
            outs = log.get('outputs', {})
            if "reflex" in outs: print(f"      â†³ Refleks: {outs['reflex']} | TereddÃ¼tler: {outs['doubt_count']}")
            if "full_text" in outs:
                # Ä°lk 100 karakteri gÃ¶ster
                preview = outs['full_text'].replace('\n', ' ')[:100]
                print(f"      â†³ Ã–zet: \"{preview}...\"")

        print("-" * 80)

        # PRINCIPLE & ACTION PLAN
        p = ui_data["principles"][0]
        print(f"âš–ï¸  TEMEL Ä°LKE:\n   \"{p['text'][:120]}...\"")

        # V120 Persona Ã–zeti
        if "personas_v120" in p:
            v120 = p["personas_v120"]
            print(f"\nğŸ—£ï¸  TARAFLARIN POZÄ°SYONLARI (V120 DETAY):")
            print(f"   ğŸ§  HAKÄ°M: {v120.get('reflex', 'N/A')}")
            print(f"      âš ï¸ TereddÃ¼tler: {v120.get('doubts', [])}")
            print("-" * 40)
            print(f"   ğŸ‘¨â€ğŸ’¼ DAVACI: {len(v120.get('plaintiff', ''))} karakterlik savunma sunuldu.")
            print(f"   ğŸ›ï¸ DAVALI: {len(v120.get('defendant', ''))} karakterlik itiraz sunuldu.")
            print(f"   ğŸ” BÄ°LÄ°RKÄ°ÅÄ°: Zincir kontrolÃ¼ yapÄ±ldÄ±.")

        print("-" * 80)
        print("ğŸš€ GÃœÃ‡LENDÄ°RME & SOMUT Ä°Å PAKETLERÄ°:")
        for act in p['action_plan']:
            print(f"   ğŸ“¦ {act['title']} (+{act['risk_reduction']['expected_score_increase']} Puan)")

        print("â–ˆ" * 80 + "\n")


# ==================================================
# 1ï¸âƒ£2ï¸âƒ£ ANA UYGULAMA (MAIN APP)
# ==================================================
class LegalApp:
    def __init__(self):
        print("ğŸš€ LEGAL SUITE V128 (Precedent Layer Added)...")
        self.search_engine = LegalSearchEngine()

        if self.search_engine.connect_db():
            self.memory_manager = LegalMemoryManager(
                self.search_engine.client,
                self.search_engine.dense_embedder,
                ChatOllama(model=LegalConfig.LLM_MODEL, temperature=0.1)
            )
        else:
            self.memory_manager = None

        self.judge = LegalJudge(memory_manager=self.memory_manager)
        self.reporter = LegalReporter()
        self.ui_printer = LegalUIPrinter()

    def run(self):
        if not self.search_engine.run_indexing():
            self.search_engine.close()
            sys.exit()

        if self.memory_manager:
            self.memory_manager.consolidate_principles_v79()

        print("\nâœ… SÄ°STEM HAZIR. (Ã‡Ä±kÄ±ÅŸ: 'q')")

        try:
            while True:
                print("-" * 60)
                story = input("ğŸ“ Olay: ");
                if story == 'q': break
                topic = input("ğŸ¯ Odak: ")
                neg_input = input("ğŸš« YasaklÄ±: ")
                negatives = [w.strip().lower() for w in neg_input.split(",")] if neg_input else []

                print("   ğŸ›¡ï¸ Girdi kontrol ediliyor...")
                if not self.judge.validate_user_input(story, topic):
                    print("   âŒ UYARI: Girdi anlamsÄ±z. LÃ¼tfen mantÄ±klÄ± bir olay giriniz.")
                    continue

                # ğŸ”¨ Commit 5.3: Single Source of Truth
                # ArtÄ±k daÄŸÄ±nÄ±k deÄŸiÅŸkenler yerine "QueryContext" nesnesi oluÅŸturuyoruz.
                ctx = self.judge.build_query_context(story, topic, negatives)
                print(f"   âœ“ BaÄŸlam OluÅŸturuldu: {ctx.detected_domain}")

                expanded = self.judge.generate_expanded_queries(ctx.query_text, ctx.topic)
                full_query = f"{ctx.query_text} {ctx.topic} " + " ".join(expanded)
                print(f"   âœ“ Sorgu: {len(full_query)} karakter")

                candidates = self.search_engine.retrieve_raw_candidates(full_query)
                if not candidates: continue

                # Mevcut fonksiyonlara ctx iÃ§inden okuyarak gÃ¶nderiyoruz (Geri uyumluluk)
                valid_docs = self.judge.evaluate_candidates(candidates, ctx.query_text, ctx.topic, ctx.negative_scope)
                if not valid_docs: print("ğŸ”´ YargÄ±Ã§ hepsini eledi."); continue

                # [V128 EKLENTÄ°SÄ°] PDF KatmanÄ± iÃ§in Veri HazÄ±rlÄ±ÄŸÄ±
                # Ana motor etkilenmez, sadece PDF'e gidecek 'precedent_cards' hazÄ±rlanÄ±r.
                precedent_cards = self.judge.explain_precedents_for_pdf(valid_docs, ctx.topic)

                context_str = ""
                doc_scan_log = []
                for i, d in enumerate(valid_docs):
                    doc_scan_log.append({
                        "source": d['source'], "page": d['page'],
                        "role": d['role'], "reason": d['reason']
                    })

                    # V122 GÃœNCELLEME: Emsal ve Mevzuat AyrÄ±mÄ±
                    is_emsal = "EMSAL" in d['type'].upper()
                    doc_label = "[EMSAL KARAR]" if is_emsal else "[MEVZUAT]"
                    char_limit = 1000 if is_emsal else 800

                    context_str += f"""
                        BELGE #{i + 1}
                        ETÄ°KET: {doc_label}
                        KAYNAK: {d['source']}
                        TÃœR: {d['type']}
                        ROL: {d['role']}
                        YARGIÃ‡ GEREKÃ‡ESÄ°: {d['reason']}
                        Ä°Ã‡ERÄ°K: {d['text'][:char_limit]}...
                        =========================================
                        """

                current_personas = {}
                mem_principles = []  # HafÄ±zadan gelen ilkeleri tutmak iÃ§in
                if self.memory_manager:
                    self.memory_manager.recall_principles(full_query)
                    self.ui_printer.print_grand_ui_log(self.memory_manager.latest_ui_data, doc_scan_log)

                    if self.memory_manager.latest_ui_data.get("principles"):
                        p_data = self.memory_manager.latest_ui_data["principles"][0]
                        mem_principles = self.memory_manager.latest_ui_data["principles"]
                        # V120 kontrolÃ¼
                        if "personas_v120" in p_data:
                            current_personas = p_data["personas_v120"]
                        else:
                            current_personas = p_data["personas"]

                # ğŸ”¨ Commit 5.4: Decision Context Entegrasyonu
                # Arama ve hafÄ±za sonuÃ§larÄ±nÄ± ortak bir yargÄ±sal zeminde birleÅŸtiriyoruz.
                decision_context = DecisionBuilder.build_decision_context_from_valid_docs(valid_docs)
                decision_context = DecisionBuilder.enrich_decision_context_with_memory(decision_context, mem_principles)

                if not decision_context.has_minimum_legal_basis():
                    print("ğŸ”´ KRÄ°TÄ°K UYARI: Yeterli hukuki belge veya ilke bulunamadÄ±. Analiz durduruluyor.")
                    continue

                # ğŸ”¨ Commit 5.5: Judge Core (Deterministik AkÄ±l)
                # LLM'e gitmeden Ã¶nce dosyanÄ±n gÃ¼cÃ¼nÃ¼ matematiksel olarak Ã¶lÃ§Ã¼yoruz.
                judge_core = JudgeCore()
                reflex = judge_core.evaluate(decision_context)
                print(f"   âš–ï¸  Ã–N YARGIÃ‡ REFLEKSÄ°: {reflex.tendency} (Skor: {reflex.score})")

                if reflex.score < 30:
                    raise RuntimeError(
                        f"Dosya hukuki olarak zayÄ±f (Skor: {reflex.score}). Hakim ilk refleksi RED yÃ¶nÃ¼nde. LÃ¼tfen daha gÃ¼Ã§lÃ¼ delil veya emsal ile tekrar deneyin.")

                # ğŸ”¨ Commit 5.6: Persona Engine (KontrollÃ¼ LLM)
                # Hakim tereddÃ¼tlerine cevap veren yeni persona motoru
                llm_for_persona = ChatOllama(model=LegalConfig.LLM_MODEL, temperature=0.7)  # Biraz daha yaratÄ±cÄ±
                persona_engine = PersonaEngine(llm_for_persona)

                persona_outputs = persona_engine.run(ctx, decision_context, reflex)

                # PDF Raporu iÃ§in persona verilerini gÃ¼ncelle
                # (Eski hafÄ±za verilerini ezerek gÃ¼ncel duruma gÃ¶re cevap veriyoruz)
                current_personas = {
                    "judge_reflex": reflex.tendency,
                    "doubts": reflex.doubts,
                    "plaintiff": next((p.response for p in persona_outputs if "DAVACI" in p.role), "Beyan yok"),
                    "defendant": next((p.response for p in persona_outputs if "DAVALI" in p.role), "Beyan yok"),
                    "expert": next((p.response for p in persona_outputs if "BÄ°LÄ°RKÄ°ÅÄ°" in p.role), "Beyan yok")
                }

                # ğŸ”¨ Commit 5.7: Action Engine (Somut GÃ¼Ã§lendirme)
                action_engine = ActionEngine(llm_for_persona)  # Reuse LLM
                strengthening_actions = action_engine.run(reflex, persona_outputs)

                # Avukat MasasÄ± (Konsol Ã‡Ä±ktÄ±sÄ±)
                if strengthening_actions:
                    print(f"\n   ğŸ› ï¸  GÃœÃ‡LENDÄ°RME AKSÄ°YONLARI ({len(strengthening_actions)} Adet):")
                    for act in strengthening_actions:
                        print(f"      ğŸ”¹ [{act.impact_score}/10] {act.title}: {act.description[:100]}...")

                full_advice = self.judge.generate_final_opinion(ctx.query_text, ctx.topic, context_str,judge_reflex=reflex)

                # =========================================================
                # ğŸš€ COMMIT 6.0 ENTEGRASYONU: RAPOR ORKESTRASYONU
                # =========================================================

                print("\nğŸ–¨ï¸  Raporlama SÃ¼reci BaÅŸlatÄ±lÄ±yor...")

                # 1. OrkestratÃ¶rÃ¼ HazÄ±rla
                # Ä°sterseniz buraya ClientSummaryPDF() de ekleyebilirsiniz listeye.
                report_orchestrator = ReportOrchestrator(
                    reporters=[
                        LegacyPDFReport(),  # pdf_reports.py iÃ§indeki basit legacy
                        JudicialPDFReport()  # pdf_reports.py iÃ§indeki geliÅŸmiÅŸ judicial
                    ]
                )

                # 2. TÃ¼m RaporlarÄ± Tek Seferde Ãœret
                # Not: decision_context (d_ctx) iÃ§inden documents listesini Ã§ekiyoruz.
                pdf_paths = report_orchestrator.generate_all(
                    context=ctx,  # QueryContext
                    judge_reflex=reflex,  # JudgeReflex (Commit 5.5)
                    persona_outputs=persona_outputs,  # List[PersonaResponse] (Commit 5.6)
                    actions=strengthening_actions,  # List[StrengtheningAction] (Commit 5.7)
                    documents=decision_context.documents  # DecisionContext (Commit 5.4)
                )

                # 3. SonuÃ§larÄ± Bildir
                for path in pdf_paths:
                    print(f"   âœ… Rapor Ãœretildi: {path}")

                # 4. MÃ¼ÅŸteri Ã–zeti (Opsiyonel - Veri varsa)
                # Not: client_summary objesi ÅŸu an kodda Ã¼retilmiyor,
                # eÄŸer Ã¼retirseniz burayÄ± aÃ§abilirsiniz.
                """
                client_pdf = ClientSummaryPDF()
                client_pdf.generate(client_summary=client_summary_objesi)
                """

                # 5. Konsol Tablosu (Commit 5.2)
                audit_dump = {}
                if self.memory_manager and hasattr(self.memory_manager, 'latest_ui_data'):
                    audit_dump = self.memory_manager.latest_ui_data.get("audit_log", {})
                self.ui_printer.print_simple_console_table(audit_dump)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Program durduruldu.")
        except Exception as e:
            print(f"\nâš ï¸ Hata: {e}")
        finally:
            self.search_engine.close()


if __name__ == "__main__":
    freeze_support()
    app = LegalApp()
    app.run()