import sys
import os
import re
import uuid
import time
import shutil
import atexit
import json
import random
import math
from typing import Dict, Any, List, Tuple
from datetime import datetime
from multiprocessing import Pool, cpu_count, freeze_support
from dataclasses import dataclass
from collections import Counter

# --------------------------------------------------
# ğŸ“¦ IMPORTLAR
# --------------------------------------------------
import fitz  # PyMuPDF
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_core.messages import SystemMessage, HumanMessage
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance, Filter, FieldCondition, MatchValue, Range
from fpdf import FPDF
from fpdf.enums import XPos, YPos
from langchain_community.document_loaders import PyMuPDFLoader

# UTF-8 AyarÄ±
sys.stdout.reconfigure(encoding="utf-8")


# ==================================================
# 1ï¸âƒ£ KONFÄ°GÃœRASYON SINIFI
# ==================================================
@dataclass
class LegalConfig:
    SOURCES = {
        "mevzuat": {
            "folder": "mevzuatlar",
            "collection": "legal_statutes_v48",
            "desc": "MEVZUAT"
        },
        "emsal": {
            "folder": "belgeler",
            "collection": "legal_precedents_v48",
            "desc": "EMSAL KARAR"
        }
    }
    MEMORY_COLLECTIONS = {
        "decision": "judge_memory_v1",
        "principle": "principle_memory_v1"
    }

    QDRANT_PATH = "qdrant_db_master"
    STATE_FILE = "system_state.json"

    EMBEDDING_MODEL = "nomic-embed-text"
    LLM_MODEL = "qwen2.5"

    SEARCH_LIMIT_PER_SOURCE = 60
    SCORE_THRESHOLD = 0.35
    LLM_RERANK_LIMIT = 10

    DECAY_RATE_PER_MONTH = 0.98
    PRINCIPLE_MERGE_THRESHOLD = 0.90
    MIN_CONFIDENCE_THRESHOLD = 0.55


# ==================================================
# 2ï¸âƒ£ YARDIMCI ARAÃ‡LAR (STATIC)
# ==================================================
def worker_embed_batch_global(args):
    """Multiprocessing iÃ§in global kalmalÄ±."""
    texts, model_name = args
    try:
        embedder = OllamaEmbeddings(model=model_name)
        return embedder.embed_documents(texts)
    except Exception as e:
        print(f"âš ï¸ Batch hatasÄ± (atlanÄ±yor): {e}")
        return []


class LegalUtils:
    @staticmethod
    def force_unlock_db():
        lock_file = os.path.join(LegalConfig.QDRANT_PATH, ".lock")
        if os.path.exists(lock_file):
            try:
                os.remove(lock_file);
                print("ğŸ”“ KÄ°LÄ°T DOSYASI TEMÄ°ZLENDÄ°.")
            except:
                pass

    @staticmethod
    def extract_pdf_conclusion(file_path, char_limit=2500):
        try:
            if not os.path.exists(file_path): return "[Dosya bulunamadÄ±.]"
            doc = fitz.open(file_path)
            total_pages = len(doc)
            text = "";
            start_page = max(0, total_pages - 2)
            for i in range(start_page, total_pages): text += doc[i].get_text()
            doc.close();
            return text[-char_limit:]
        except Exception as e:
            return f"[Karar okunamadÄ±: {e}]"

    @staticmethod
    def clean_text(text):
        text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text


# ==================================================
# 3ï¸âƒ£ LEGAL AUDIT LOGGER
# ==================================================
class LegalAuditLogger:
    """
    Sistemin verdiÄŸi tÃ¼m kararlarÄ±n izlenebilir, aÃ§Ä±klanabilir ve UI-uyumlu log kaydÄ±.
    """

    def __init__(self, case_id: str | None = None):
        self.case_id = case_id or str(uuid.uuid4())
        self.started_at = time.time()
        self.logs: List[Dict[str, Any]] = []
        self._step_counter = 0

    def log_event(
            self,
            stage: str,
            title: str,
            description: str,
            inputs: Dict[str, Any] | None = None,
            outputs: Dict[str, Any] | None = None,
            score_impact: int | float | None = None,
            resulting_score: int | float | None = None,
            confidence: str | None = None,
    ):
        """
        Sistemdeki HER anlamlÄ± adÄ±m buradan geÃ§er
        """
        self._step_counter += 1

        event = {
            "step": self._step_counter,
            "timestamp": time.time(),
            "stage": stage,
            "title": title,
            "description": description,
            "inputs": inputs or {},
            "outputs": outputs or {},
        }

        if score_impact is not None:
            event["score_impact"] = score_impact

        if resulting_score is not None:
            event["resulting_score"] = resulting_score

        if confidence is not None:
            event["confidence"] = confidence

        self.logs.append(event)

    def export(self) -> Dict[str, Any]:
        """
        UI / API / Storage iÃ§in tek JSON
        """
        return {
            "case_id": self.case_id,
            "started_at": self.started_at,
            "completed_at": time.time(),
            "timeline": self.logs,
        }


# ==================================================
# 4ï¸âƒ£ ACTIONABLE RECOMMENDATION ENGINE (V100)
# ==================================================
class ActionableRecommendationEngine:
    # 1. Sabit Profil HaritasÄ± (Safety Layer)
    RECOMMENDATION_PROFILE = {
        "DELIL": {
            "evidence_type": ["tanÄ±k", "belge", "bilirkiÅŸi", "keÅŸif", "yemin"],
            "priority": "YÃœKSEK",
            "estimated_cost": "Orta",
            "time_impact": "Orta",
            "base_score_range": (5, 10)
        },
        "ICTIHAT": {
            "evidence_type": ["emsal karar", "HGK kararÄ±", "Ä°BK"],
            "priority": "ORTA",
            "estimated_cost": "DÃ¼ÅŸÃ¼k",
            "time_impact": "KÄ±sa",
            "base_score_range": (3, 7)
        },
        "USUL": {
            "evidence_type": ["dilekÃ§e", "itiraz", "sÃ¼re tutum"],
            "priority": "YÃœKSEK",
            "estimated_cost": "DÃ¼ÅŸÃ¼k",
            "time_impact": "KÄ±sa",
            "base_score_range": (2, 4)
        },
        "TALEP_DARALTMA": {
            "evidence_type": ["strateji"],
            "priority": "ORTA",
            "estimated_cost": "DÃ¼ÅŸÃ¼k",
            "time_impact": "KÄ±sa",
            "base_score_range": (4, 6)
        }
    }

    # V100: KESÄ°N USUL KURALLARI
    PROCEDURAL_RULES_DB = {
        "MÄ°RAS": {
            "required_evidence": ["NÃ¼fus KayÄ±t Ã–rneÄŸi (MERNÄ°S)", "Veraset Ä°lamÄ± Talebi", "TanÄ±k (Gerekirse)"],
            "excluded_evidence": ["SGK KayÄ±tlarÄ±", "MaaÅŸ Bordrosu", "Ticari Defterler"],
            "authority": "Sulh Hukuk Mahkemesi / Noter"
        },
        "Ä°Å DAVASI": {
            "required_evidence": ["SGK Hizmet DÃ¶kÃ¼mÃ¼", "Ä°ÅŸyeri Åahsi Sicil DosyasÄ±", "Banka MaaÅŸ YazÄ±sÄ±", "TanÄ±k"],
            "authority": "Ä°ÅŸ Mahkemesi"
        },
        "TAPU": {
            "required_evidence": ["Tapu KaydÄ± (TAKBÄ°S)", "KeÅŸif", "BilirkiÅŸi Raporu"],
            "authority": "Asliye Hukuk Mahkemesi"
        },
        "CEZA": {
            "required_evidence": ["Ä°fade TutanaklarÄ±", "HTS KayÄ±tlarÄ±", "Adli TÄ±p Raporu"],
            "authority": "Cumhuriyet BaÅŸsavcÄ±lÄ±ÄŸÄ± / Ceza Mahkemesi"
        }
    }

    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_concerns, query_text=""):
        recommendations = []
        for concern in judge_concerns:
            category = self._classify_concern(concern)
            if not category: category = "DELIL"

            profile = self.RECOMMENDATION_PROFILE.get(category, self.RECOMMENDATION_PROFILE["DELIL"])
            rec_text = self._generate_recommendation_text(concern, self._category_to_turkish(category))
            score_boost = random.randint(profile["base_score_range"][0], profile["base_score_range"][1])
            source_detail = self._infer_source(concern, query_text)

            recommendations.append({
                "action_id": str(uuid.uuid4()),
                "title": rec_text.split(".")[0][:80] + "...",
                "description": rec_text,
                "category": category,
                "focus": category,
                "evidence": {
                    "type": self._pick_evidence(profile["evidence_type"]),
                    "source": source_detail,
                    "count": self._estimate_count(category)
                },
                "priority": profile["priority"],
                "estimated_cost": profile["estimated_cost"],
                "time_impact": profile["time_impact"],
                "risk_reduction": {
                    "area": self._category_to_turkish(category),
                    "expected_score_increase": score_boost
                },
                "suggestion": rec_text,
                "if_not_done": self._generate_risk_note(concern),
                "why": concern
            })
        return recommendations

    def _infer_source(self, concern, query_text):
        concern_lower = concern.lower()
        query_lower = query_text.lower()

        if "miras" in query_lower or "veraset" in query_lower:
            if "sgk" in concern_lower or "iÅŸ" in concern_lower:
                return {"entity": "NÃ¼fus MÃ¼dÃ¼rlÃ¼ÄŸÃ¼ / UYAP", "method": "KayÄ±t Celbi", "responsible": "Mahkeme"}
            return {"entity": "NÃ¼fus MÃ¼dÃ¼rlÃ¼ÄŸÃ¼ (MERNÄ°S)", "method": "MÃ¼zekkere/Sorgu", "responsible": "Mahkeme"}

        if "iÅŸ" in concern_lower or "bordro" in concern_lower: return {"entity": "SGK Ä°l MÃ¼dÃ¼rlÃ¼ÄŸÃ¼ / Ä°ÅŸyeri",
                                                                       "method": "MÃ¼zekkere", "responsible": "Mahkeme"}
        if "banka" in concern_lower or "dekont" in concern_lower: return {"entity": "Ä°lgili Banka Genel MÃ¼dÃ¼rlÃ¼ÄŸÃ¼",
                                                                          "method": "MÃ¼zekkere",
                                                                          "responsible": "Mahkeme"}
        if "rapor" in concern_lower or "teknik" in concern_lower: return {"entity": "BilirkiÅŸi Heyeti",
                                                                          "method": "KeÅŸif/Ä°nceleme",
                                                                          "responsible": "Mahkeme"}
        if "tanÄ±k" in concern_lower or "gÃ¶rgÃ¼" in concern_lower: return {"entity": "TanÄ±klar",
                                                                         "method": "DuruÅŸmada Dinletme",
                                                                         "responsible": "Avukat"}
        if "tapu" in concern_lower: return {"entity": "Tapu Sicil MÃ¼dÃ¼rlÃ¼ÄŸÃ¼", "method": "MÃ¼zekkere",
                                            "responsible": "Mahkeme"}
        return {"entity": "Dosya KapsamÄ±", "method": "Ä°nceleme", "responsible": "Avukat"}

    def _estimate_count(self, category):
        if category == "DELIL": return random.randint(2, 4)
        if category == "ICTIHAT": return 1
        return 1

    def _generate_risk_note(self, concern):
        return f"Bu husus giderilmezse '{concern[:40]}...' yÃ¶nÃ¼nden hakim tereddÃ¼dÃ¼ devam eder ve ispat yÃ¼kÃ¼ karÅŸÄ±lanamaz."

    def _classify_concern(self, concern_text):
        text = concern_text.lower()
        if any(k in text for k in
               ["delil", "ispat", "kanÄ±t", "tanÄ±k", "belge", "tespit", "bilirkiÅŸi", "rapor"]): return "DELIL"
        if any(k in text for k in ["iÃ§tihat", "emsal", "yerleÅŸik", "karar", "yargÄ±tay", "daire"]): return "ICTIHAT"
        if any(k in text for k in ["usul", "sÃ¼re", "ehliyet", "ÅŸekil", "gÃ¶rev", "yetki", "husumet"]): return "USUL"
        if any(k in text for k in ["talep", "fazla", "aÅŸan", "kÄ±smi", "daraltma"]): return "TALEP_DARALTMA"
        return None

    def _category_to_turkish(self, category):
        return {"DELIL": "delil ve ispat", "ICTIHAT": "emsal iÃ§tihat", "USUL": "usul hukuku",
                "TALEP_DARALTMA": "stratejik talep"}.get(category, "hukuki")

    def _generate_recommendation_text(self, concern, category_tr):
        prompt = f"""
BAÄLAM: TÃ¼rk Hukuku (YargÄ±tay/BAM uygulamasÄ±). BaÅŸka Ã¼lke veya sistem kullanma.
Bir avukata yol gÃ¶sterecek ÅŸekilde, aÅŸaÄŸÄ±daki hakim tereddÃ¼dÃ¼ne yÃ¶nelik {category_tr} odaklÄ± SOMUT bir aksiyon Ã¶nerisi yaz.
Hakim TereddÃ¼dÃ¼: "{concern}"
Kurallar: Tek bir cÃ¼mle yaz. Emir kipi kullan.
Ã‡IKTI:
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "Ä°lgili hususta ek delil ve beyan sunulmalÄ±dÄ±r."

    def _pick_evidence(self, options):
        if not options: return "Genel"
        return random.choice(options)


# ==================================================
# 5ï¸âƒ£ HAFIZA YÃ–NETÄ°CÄ°SÄ° (FULL INTEGRATED)
# ==================================================
class LegalMemoryManager:
    # --- V93: SIMULATION CONFIG ---
    MITIGATION_EFFECTS = {
        "DELIL": {"min": 5, "max": 10}, "BELGE": {"min": 5, "max": 10},
        "ICTIHAT": {"min": 3, "max": 7}, "ARGUMAN": {"min": 3, "max": 7},
        "TALEP_DARALTMA": {"min": 4, "max": 6}, "USUL": {"min": 2, "max": 4}
    }
    MAX_TOTAL_BOOST = 15
    MAX_SCORE = 95

    def __init__(self, client, embedder, llm):
        self.client = client
        self.embedder = embedder
        self.llm = llm
        self._init_memory_collections()
        self.last_consolidation_ts = self._load_state()
        self.domain_cache = {}
        self.last_recalled_query = None
        self.recommendation_engine = ActionableRecommendationEngine(llm)
        self.audit_logger = LegalAuditLogger()
        self.latest_ui_data = {}

    def _init_memory_collections(self):
        for name, col_name in LegalConfig.MEMORY_COLLECTIONS.items():
            if not self.client.collection_exists(col_name):
                print(f"ğŸ§  HafÄ±za oluÅŸturuluyor: {col_name}")
                self.client.create_collection(col_name, vectors_config=VectorParams(size=768, distance=Distance.COSINE))

    def _load_state(self):
        try:
            if os.path.exists(LegalConfig.STATE_FILE):
                with open(LegalConfig.STATE_FILE, 'r') as f:
                    data = json.load(f)
                    return data.get("last_consolidation", 0.0)
        except:
            pass
        return 0.0

    def _save_state(self):
        try:
            with open(LegalConfig.STATE_FILE, 'w') as f:
                json.dump({"last_consolidation": time.time()}, f)
        except:
            pass

    def _detect_polarity(self, principle_text):
        prompt = f"BAÄLAM: TÃ¼rk Hukuku.\nÄ°LKE: '{principle_text}'\nCEVAP (SADECE BÄ°RÄ°): [LEHINE] veya [ALEYHINE] veya [BELIRSIZ]"
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "LEHINE" in res: return "LEHINE"
            if "ALEYHINE" in res: return "ALEYHINE"
            return "BELIRSIZ"
        except:
            return "BELIRSIZ"

    def _detect_domain_from_query(self, query_text):
        if query_text in self.domain_cache: return self.domain_cache[query_text]
        prompt = f"Sorgu: \"{query_text}\"\nBu sorgu hangi hukuk dalÄ±na girer? SADECE TEK KELÄ°ME CEVAP VER."
        try:
            domain = self.llm.invoke(prompt).content.strip().split()[0]
            self.domain_cache[query_text] = domain
            return domain
        except:
            return "Genel"

    def _extract_year_bucket(self, timestamp):
        year = datetime.fromtimestamp(timestamp).year
        if year <= 2018:
            return "2015-2018"
        elif year <= 2021:
            return "2019-2021"
        else:
            return "2022-2024"

    def _apply_time_decay(self, confidence, timestamp):
        if not timestamp: return confidence
        elapsed_months = (time.time() - timestamp) / (30 * 24 * 3600)
        return confidence * math.pow(LegalConfig.DECAY_RATE_PER_MONTH, elapsed_months)

    def _detect_legal_context(self, query_text):
        query_lower = query_text.lower()
        if any(k in query_lower for k in ["ceza", "suÃ§", "sanÄ±k", "savcÄ±", "aÄŸÄ±r ceza"]):
            return {"domain": "CEZA", "court_type": "Ceza Mahkemesi", "prosecutor_active": True,
                    "opposing_party": "Ä°ddia MakamÄ±"}
        if any(k in query_lower for k in ["idare", "vergi", "iptal davasÄ±", "yÃ¼rÃ¼tme"]):
            return {"domain": "IDARI", "court_type": "Ä°dare Mahkemesi", "prosecutor_active": False,
                    "opposing_party": "DavalÄ± Ä°dare"}
        return {"domain": "HUKUK", "court_type": "Hukuk Mahkemesi", "prosecutor_active": False,
                "opposing_party": "DavalÄ± Vekili"}

    def _calculate_case_success_probability(self, principle_confidence, trend_direction, conflict, domain_match,
                                            polarity="LEHINE"):
        score = principle_confidence * 100
        if trend_direction == "up":
            score += 10
        elif trend_direction == "down":
            score -= 10
        if conflict: score -= 15
        if not domain_match: score -= 10
        if polarity == "BELIRSIZ": score -= 5

        if principle_confidence > 0.85 and polarity == "LEHINE":
            if score < 65: score = 75.0

        score = max(0, min(100, round(score, 1)))
        conf_level = "YÃ¼ksek" if score >= 70 else "Orta" if score >= 40 else "DÃ¼ÅŸÃ¼k"
        summary = "BaÅŸarÄ± ihtimali yÃ¼ksek." if score >= 70 else "Riskli."
        return {"success_probability": score, "confidence_level": conf_level, "summary": summary}

    def _derive_persona_signals(self, analysis_data, item_data, query_text):
        context = self._detect_legal_context(query_text)
        judge_score = analysis_data['success_probability']
        judge = {
            "title": f"TÃœRK {context['domain']} HAKÄ°MÄ°",
            "stance": "strong" if judge_score > 70 or judge_score < 30 else "weak",
            "direction": "acceptance" if judge_score >= 50 else "rejection",
            "confidence_level": "high" if judge_score > 80 else "medium",
            "risk_focus": ["evidence"] if judge_score < 50 else []
        }
        opponent_dir = "rejection" if (item_data['conflict'] or item_data['trend_dir'] == 'down') else "acceptance"
        opponent = {
            "title": context["opposing_party"],
            "stance": "strong",
            "direction": opponent_dir,
            "confidence_level": "high",
            "risk_focus": ["conflict", "public_order"] if item_data['conflict'] else []
        }
        expert = {
            "title": "BÄ°LÄ°RKÄ°ÅÄ° / UZMAN GÃ–RÃœÅÃœ",
            "stance": "neutral",
            "direction": "cautious",
            "confidence_level": "medium",
            "risk_focus": ["technical_data"]
        }
        return {"judge": judge, "opponent": opponent, "expert": expert}

    def _analyze_persona_conflict(self, personas):
        score = 0
        reasons = []
        if personas["opponent"]["direction"] != personas["judge"]["direction"]:
            score += 40
            reasons.append("YargÄ±sal yÃ¶nler zÄ±t")
        if personas["opponent"]["stance"] == "strong" and personas["judge"]["stance"] == "weak":
            score += 30
            reasons.append("SavcÄ± gÃ¼Ã§lÃ¼, hakim ihtiyatlÄ±")

        p_risks = set(personas["opponent"].get("risk_focus", []))
        j_risks = set(personas["judge"].get("risk_focus", []))
        if not p_risks.intersection(j_risks) and (p_risks or j_risks):
            score += 20
            reasons.append("Risk odaklarÄ± farklÄ±")

        return {"conflict_score": min(score, 100), "conflict_level": "YÃ¼ksek" if score >= 70 else "DÃ¼ÅŸÃ¼k",
                "summary": reasons}

    def _simulate_net_decision(self, personas):
        dir_map = {"acceptance": 1, "cautious": 0, "rejection": -1}
        stance_map = {"strong": 1.0, "neutral": 0.6, "weak": 0.3}
        conf_map = {"high": 1.0, "medium": 0.7, "low": 0.4}
        weights = {"judge": 0.60, "opponent": 0.25, "expert": 0.15}

        total = 0
        breakdown = {}
        for name, data in personas.items():
            s = dir_map.get(data["direction"], 0) * stance_map.get(data["stance"], 0.6) * conf_map.get(
                data["confidence_level"], 0.7) * weights.get(name, 0)
            breakdown[name] = round(s, 3)
            total += s
        decision = "KABUL EÄÄ°LÄ°MLÄ°" if total >= 0.25 else "RED EÄÄ°LÄ°MLÄ°" if total <= -0.25 else "BELIRSIZ"
        return {"final_score": round(total, 3), "decision": decision, "breakdown": breakdown}

    # --- GENERATORS (V98 UPDATES) ---
    def _generate_judicial_reasoning(self, analysis):
        prompt = f"BAÄLAM: TÃ¼rk Hukuku (YargÄ±tay/BAM).\nSEN TÃœRK HAKÄ°MÄ°SÄ°N. ({analysis['success_probability']} skor). Aksi gÃ¶rÃ¼ÅŸ neden zayÄ±f? Tek cÃ¼mleyle ekle."
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return ""

    def _generate_opponent_reasoning(self, analysis, title):
        prompt = f"BAÄLAM: TÃ¼rk Hukuku.\nSEN {title}'sÄ±n. ({analysis['success_probability']} skor). Kendi perspektifinden deÄŸerlendir."
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return ""

    def _generate_expert_witness_reasoning(self, analysis):
        prompt = f"BAÄLAM: TÃ¼rk Hukuku.\nSEN BÄ°LÄ°RKÄ°ÅÄ°SÄ°N. ({analysis['success_probability']} skor). Teknik dil."
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return ""

    def _generate_rejection_reasoning(self, analysis):
        prompt = f"BAÄLAM: TÃ¼rk Hukuku.\nSEN HAKÄ°MSÄ°N. DavayÄ± REDDETSEYDÄ°N gerekÃ§en ne olurdu? ({analysis['success_probability']} skor)."
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return ""

    def _generate_final_verdict_reasoning(self, net_decision, topic, trend, principles):
        prompt = f"BAÄLAM: TÃ¼rk Hukuku.\nSEN HAKÄ°MSÄ°N. Karar: {net_decision['decision']}. Konu: {topic}. GerekÃ§eli karar taslaÄŸÄ± yaz."
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return ""

    def _generate_executive_summary(self, net_decision, judge, pros, exp, trend):
        prompt = f"BAÄLAM: TÃ¼rk Hukuku.\nSEN YÃ–NETÄ°CÄ°SÄ°N. Risk Ã¶zeti yaz. Karar: {net_decision['decision']}. KÄ±rÄ±lma noktasÄ± nedir?"
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return ""

    def _extract_concerns_for_engine(self, text):
        try:
            return [l.strip("- *") for l in
                    self.llm.invoke(f"Metindeki 3 hukuki zayÄ±flÄ±ÄŸÄ± listele:\n{text}").content.strip().splitlines() if
                    len(l) > 5][:3]
        except:
            return ["Genel ispat eksikliÄŸi"]

    def _estimate_mitigation_impact(self, rec_text, min_val, max_val):
        try:
            val = int(re.findall(r"\d+", self.llm.invoke(
                f"Ã–nerinin etkisi ({min_val}-{max_val}) puanla kaÃ§? Sadece rakam.\n{rec_text}").content.strip())[0])
            return max(min(val, max_val), min_val)
        except:
            return min_val

    def _simulate_post_strengthening_score(self, base_score, recommendations):
        total_boost = 0
        seen_cats = {}
        for rec in recommendations:
            cat = rec.get("category", "DELIL")
            cfg = self.MITIGATION_EFFECTS.get(cat, {"min": 1, "max": 3})
            impact = rec['risk_reduction']['expected_score_increase']

            if cat in seen_cats: impact = int(impact * 0.6)
            seen_cats[cat] = True
            total_boost += impact

        return {"current_score": base_score, "projected_score": min(base_score + total_boost, self.MAX_SCORE),
                "total_boost": total_boost}

    # --- MAIN RECALL FUNCTION (V103: AUDIT LOGGER INTEGRATED) ---
    def recall_principles(self, query_text):
        try:
            # 1. AUDIT START
            self.audit_logger = LegalAuditLogger()

            query_domain = self._detect_domain_from_query(query_text)
            vector = self.embedder.embed_query(query_text)
            hits = self.client.query_points(LegalConfig.MEMORY_COLLECTIONS["principle"], query=vector, limit=15).points

            processed_hits = []
            for h in hits:
                raw_conf = h.payload.get("confidence", 0.5)
                ts = h.payload.get("timestamp", time.time())
                domain = h.payload.get("domain", "Genel")
                evolution_note = h.payload.get("evolution_note", "")
                polarity = h.payload.get("polarity", "BELIRSIZ")
                final_conf = self._apply_time_decay(raw_conf, ts)
                if polarity == "BELIRSIZ": final_conf *= 0.8

                is_domain_match = (query_domain.lower() in domain.lower())

                if final_conf >= LegalConfig.MIN_CONFIDENCE_THRESHOLD:
                    trend_dir = "up" if "GÃœÃ‡LENEN" in evolution_note else "down" if "ZAYIFLAYAN" in evolution_note else "stable"
                    item = {
                        "text": h.payload['principle'], "conf": final_conf, "domain": domain,
                        "conflict": h.payload.get("conflict_flag", False), "score": h.score,
                        "trend_dir": trend_dir, "domain_match": is_domain_match,
                        "evolution_note": evolution_note, "polarity": polarity,
                        "year_bucket": self._extract_year_bucket(ts)
                    }
                    processed_hits.append(item)

            sorted_hits = sorted(processed_hits, key=lambda x: x["score"], reverse=True)[:3]

            # AUDIT: PRINCIPLE ANALYSIS
            self.audit_logger.log_event(
                stage="principle_analysis", title="Ä°Ã§tihatlar Analiz Edildi",
                description=f"{len(sorted_hits)} adet yÃ¼ksek gÃ¼venli ilke tespit edildi.",
                outputs={"domain": query_domain, "hit_count": len(sorted_hits)}
            )

            if not sorted_hits: return ""

            memory_text = f"\nğŸ’¡ YERLEÅÄ°K Ä°Ã‡TÄ°HAT HAFIZASI ({query_domain} AlanÄ±):\n"

            self.latest_ui_data = {
                "query": query_text, "domain": query_domain, "principles": [], "net_decision": {},
                "executive_summary": "", "audit_log": {}
            }

            for item in sorted_hits:
                # 2. Risk Analizi
                analysis = self._calculate_case_success_probability(
                    item["conf"], item["trend_dir"], item["conflict"], item["domain_match"], item["polarity"]
                )
                self.audit_logger.log_event("risk_calculation", "Risk Skoru HesaplandÄ±",
                                            f"BaÅŸarÄ± ihtimali: %{analysis['success_probability']}", outputs=analysis)

                persona_signals = self._derive_persona_signals(analysis, item, query_text)
                conflict_analysis = self._analyze_persona_conflict(persona_signals)
                net_decision = self._simulate_net_decision(persona_signals)

                # 3. Metin Ãœretimi
                judicial_text = self._generate_judicial_reasoning(analysis)
                opponent_title = persona_signals["opponent"]["title"]
                opponent_text = self._generate_opponent_reasoning(analysis, opponent_title)
                expert_text = self._generate_expert_witness_reasoning(analysis)
                rejection_text = self._generate_rejection_reasoning(analysis)
                verdict_text = self._generate_final_verdict_reasoning(net_decision, query_text, item['evolution_note'],
                                                                      item['text'])
                exec_summary = self._generate_executive_summary(net_decision, judicial_text, opponent_text, expert_text,
                                                                item['evolution_note'])

                self.audit_logger.log_event("persona_views", "YargÄ±sal BakÄ±ÅŸlar Ãœretildi",
                                            "Hakim, KarÅŸÄ± Taraf ve Uzman gÃ¶rÃ¼ÅŸleri simÃ¼le edildi.")

                # 4. Aksiyon PlanÄ± ve SimÃ¼lasyon
                concerns = self._extract_concerns_for_engine(judicial_text + "\n" + rejection_text)
                action_plan = self.recommendation_engine.generate(concerns, query_text)

                self.audit_logger.log_event("action_plan", "Aksiyon PlanÄ± OluÅŸturuldu",
                                            f"{len(action_plan)} adet somut iÅŸ paketi hazÄ±rlandÄ±.",
                                            outputs={"count": len(action_plan)})

                simulation_result = self._simulate_post_strengthening_score(analysis['success_probability'],
                                                                            action_plan)

                self.audit_logger.log_event("simulation_result", "Gelecek SimÃ¼lasyonu",
                                            f"Skor artÄ±ÅŸ potansiyeli: +{simulation_result['total_boost']}",
                                            outputs=simulation_result)

                # Store Complete Data
                self.latest_ui_data["principles"].append({
                    "text": item['text'], "trend_log": item['evolution_note'], "polarity": item['polarity'],
                    "conflict_flag": item['conflict'], "year_bucket": item['year_bucket'],
                    "score_data": analysis,
                    "personas": {
                        "judge": judicial_text, "opponent": opponent_text, "opponent_title": opponent_title,
                        "expert": expert_text, "devil": rejection_text
                    },
                    "conflict_analysis": conflict_analysis,
                    "reasoned_verdict": verdict_text,
                    "action_plan": action_plan,
                    "simulation": simulation_result
                })
                self.latest_ui_data["net_decision"] = net_decision
                self.latest_ui_data["executive_summary"] = exec_summary

                warning = "âš ï¸ [YARGISAL Ã‡ELÄ°ÅKÄ°]" if item["conflict"] else ""
                memory_text += f"- {warning} [{item['domain']}] {item['text']}\n"
                memory_text += f"  ğŸ“ Ã–ZET: {exec_summary}\n"
                memory_text += f"  ğŸ† EÄÄ°LÄ°M: {net_decision['decision']}\n"

            # V103: Audit Logunu UI Verisine Ekle
            self.latest_ui_data["audit_log"] = self.audit_logger.export()

            return memory_text
        except Exception as e:
            print(f"Hata: {e}")
            return ""

    # --- MATEMATÄ°KSEL YARDIMCILAR (TAM) ---
    def _cosine_similarity(self, v1, v2):
        dot = sum(a * b for a, b in zip(v1, v2))
        mag1 = math.sqrt(sum(a * a for a in v1))
        mag2 = math.sqrt(sum(b * b for b in v2))
        if mag1 == 0 or mag2 == 0: return 0.0
        return dot / (mag1 * mag2)

    def _calculate_vector_mean(self, vectors):
        if not vectors: return []
        dim = len(vectors[0])
        mean = [0.0] * dim
        for v in vectors:
            for i in range(dim):
                mean[i] += v[i]
        return [x / len(vectors) for x in mean]

    def _cluster_reasonings(self, items, threshold=0.86):
        clusters = []
        for item in items:
            added = False
            for c in clusters:
                if self._cosine_similarity(item['vector'], c['centroid']) >= threshold:
                    c['members'].append(item)
                    all_vecs = [m['vector'] for m in c['members']]
                    c['centroid'] = self._calculate_vector_mean(all_vecs)
                    added = True
                    break
            if not added:
                clusters.append({'members': [item], 'centroid': item['vector']})
        return [c['members'] for c in clusters]

    def _calculate_principle_confidence(self, cluster):
        count = len(cluster)
        count_score = min(1.0, count / 10)
        return 0.7 + (count_score * 0.3)

    def _analyze_trend_momentum(self, trend_dict):
        if not trend_dict: return "Veri Yetersiz"
        return "Ä°stikrarlÄ± Seyir"

    # --- ESKÄ° SAVE FONKSÄ°YONLARI (TAM & EKSÄ°KSÄ°Z) ---
    def calculate_memory_consensus(self, source_name, current_decision, vector_score):
        try:
            f = Filter(must=[FieldCondition(key="source", match=MatchValue(value=source_name))])
            p, _ = self.client.scroll("judge_memory_v1", scroll_filter=f, limit=20)
            if not p:
                if vector_score > 0.8: return 1.10
                return 1.0

            match_c = sum(1 for x in p if x.payload.get("decision") == current_decision)
            if len(p) == 0: return 1.0
            ratio = match_c / len(p)

            if ratio > 0.8: return 1.15
            if ratio < 0.2: return 0.85
            return 1.0
        except:
            return 1.0

    def save_decision(self, query, doc_name, decision, reason, doc_type):
        try:
            vec = self.embedder.embed_query(f"{query} {doc_name} {decision} {reason}")
            payload = {
                "query": query, "source": doc_name, "decision": decision,
                "reason": reason, "doc_type": doc_type,
                "timestamp": time.time(), "created_at": datetime.now().isoformat(), "id": str(uuid.uuid4())
            }
            self.client.upsert("judge_memory_v1", [PointStruct(id=payload['id'], vector=vec, payload=payload)])
        except:
            pass

    # --- KONSOLÄ°DASYON (TAM) ---
    def consolidate_principles_v79(self):
        print("\nğŸ”¥ Ä°Ã‡TÄ°HAT MÄ°MARI: ArtÄ±mlÄ± Konsolidasyon (V110)...")
        try:
            time_filter = Filter(must=[FieldCondition(key="timestamp", range=Range(gt=self.last_consolidation_ts))])
            points, _ = self.client.scroll(LegalConfig.MEMORY_COLLECTIONS["decision"], scroll_filter=time_filter,
                                           limit=200)

            candidates = []
            for p in points:
                if (p.payload.get('doc_type') == 'EMSAL KARAR' and len(
                        p.payload.get('reason', '')) > 30 and p.payload.get('decision') == 'KABUL'):
                    candidates.append({
                        "reason": p.payload['reason'], "id": p.id,
                        "source": p.payload.get('source', 'Bilinmeyen'),
                        "timestamp": p.payload.get('timestamp', time.time()),
                        "decision": p.payload.get('decision'), "vector": None
                    })

            if len(candidates) < 3:
                print("   â„¹ï¸ Yeterli yeni veri yok.")
                return

            print(f"   ğŸ” {len(candidates)} adet YENÄ° gerekÃ§e analiz ediliyor...")
            texts = [c["reason"] for c in candidates]
            vectors = self.embedder.embed_documents(texts)
            for i, v in enumerate(vectors): candidates[i]["vector"] = v
            clusters = self._cluster_reasonings(candidates, threshold=0.86)

            for cluster in clusters:
                if len(cluster) < 3: continue

                # KÃ¼me GerekÃ§elerini BirleÅŸtir
                reasonings_text = "\n".join([f"- {c['reason']}" for c in cluster])
                prompt = f"""
GÃ–REV: AÅŸaÄŸÄ±daki mahkeme gerekÃ§elerini analiz et.
1. Ortak hukuki ilkeyi TEK CÃœMLEDE Ã¶zetle.
2. Bu konunun ait olduÄŸu Hukuk DalÄ±nÄ± (Miras, Ceza, BorÃ§lar vb.) belirle.

GEREKÃ‡ELER:
{reasonings_text}

FORMAT:
Ä°LKE: [Ä°lke CÃ¼mlesi]
ALAN: [Hukuk DalÄ±]
"""
                res = self.llm.invoke(prompt).content.strip()
                principle_match = re.search(r"Ä°LKE:\s*(.*)", res)
                domain_match = re.search(r"ALAN:\s*(.*)", res)

                if principle_match:
                    principle_text = principle_match.group(1)
                    domain_text = domain_match.group(1) if domain_match else "Genel"
                    conf = self._calculate_principle_confidence(cluster)
                    source_ids = [c['id'] for c in cluster]

                    self._save_principle_v79(principle_text, conf, source_ids, domain_text, cluster)

            self._save_state()
            print("âœ… Konsolidasyon tamamlandÄ±.")
        except Exception as e:
            print(f"Hata: {e}")

    def _save_principle_v79(self, text, confidence, source_ids, domain, cluster_data):
        try:
            vec = self.embedder.embed_query(text)
            polarity = self._detect_polarity(text)
            hits = self.client.query_points("principle_memory_v1", query=vec, limit=10, score_threshold=0.80).points

            conflict = False
            trend = Counter()
            p_stats = {"LEHINE": 0, "ALEYHINE": 0, "BELIRSIZ": 0}

            # Conflict Check
            if polarity in p_stats: p_stats[polarity] += 1
            for h in hits:
                p = h.payload.get("polarity", "BELIRSIZ")
                if p in p_stats: p_stats[p] += 1
                if (p == "LEHINE" and polarity == "ALEYHINE") or (
                        p == "ALEYHINE" and polarity == "LEHINE"): conflict = True

            # Trend Check
            for c in cluster_data:
                bucket = self._extract_year_bucket(c.get("timestamp", time.time()))
                trend[(bucket, c.get("decision", "KABUL"))] += 1

            trend_dict = {}
            for (b, d), count in trend.items():
                if b not in trend_dict: trend_dict[b] = {"KABUL": 0, "RED": 0}
                trend_dict[b][d] = count

            evolution = self._analyze_trend_momentum(trend_dict)

            payload = {
                "principle": text, "confidence": confidence, "domain": domain,
                "polarity": polarity, "trend": trend_dict, "conflict_flag": conflict,
                "source_count": len(source_ids), "source_ids": source_ids, "evolution_note": evolution,
                "generated_by": "consolidation_v110", "timestamp": time.time(), "created_at": datetime.now().isoformat()
            }
            self.client.upsert("principle_memory_v1", [PointStruct(id=str(uuid.uuid4()), vector=vec, payload=payload)])
        except:
            pass


# ==================================================
# 7ï¸âƒ£ YENÄ° ARAÃ‡LAR: REASONING & STRATEGY (V105-V109)
# ==================================================
class WhiteLabelConfig:
    def __init__(self, firm_name="LEGAL OS", logo_path=None, footer_text="Otomatik Analiz Raporu", color=(0, 0, 0)):
        self.firm_name = firm_name
        self.logo_path = logo_path
        self.footer_text = footer_text
        self.color = color


class AuditTimelineBuilder:
    @staticmethod
    def build(audit_logs):
        timeline = []
        last_score = None
        logs_list = audit_logs.get("timeline", []) if isinstance(audit_logs, dict) else audit_logs
        for idx, log in enumerate(logs_list):
            score = log.get("resulting_score")
            if score is None: continue
            delta = None
            if last_score is not None: delta = round(score - last_score, 1)
            timeline.append({"step": idx + 1, "stage": log.get("title", "Ä°ÅŸlem"), "score": score, "delta": delta})
            last_score = score
        return timeline


class ScoreExplanationEngine:
    @staticmethod
    def generate(timeline):
        if not timeline: return "Yeterli veri yok."
        increases = [t for t in timeline if t["delta"] and t["delta"] > 0]
        decreases = [t for t in timeline if t["delta"] and t["delta"] < 0]
        parts = []
        if decreases:
            worst = min(decreases, key=lambda x: x["delta"])
            parts.append(f"BaÅŸarÄ± olasÄ±lÄ±ÄŸÄ±, '{worst['stage']}' aÅŸamasÄ±nda %{abs(worst['delta'])} dÃ¼ÅŸmÃ¼ÅŸtÃ¼r.")
        if increases:
            best = max(increases, key=lambda x: x["delta"])
            parts.append(
                f"Ancak '{best['stage']}' aÅŸamasÄ±nda stratejik deÄŸerlendirme ile %{best['delta']} artÄ±ÅŸ saÄŸlanmÄ±ÅŸtÄ±r.")
        return " ".join(parts) if parts else "Skor duraÄŸan seyretmiÅŸtir."


class JudgeReasoningGenerator:
    def __init__(self, llm):
        self.llm = llm

    def generate(self, audit_logs):
        logs_list = audit_logs.get("timeline", []) if isinstance(audit_logs, dict) else audit_logs
        summary_lines = [f"- {log['description']}" for log in logs_list if "description" in log]
        audit_summary = "\n".join(summary_lines)

        prompt = f"""
SEN BIR HAKIMSIN.
Asagida, bir davaya iliskin teknik degerlendirme adimlari yer almaktadir.
Bu adimlari kullanarak, resmi, hukuki ve tarafsiz bir 'KARAR GEREKCESI' yaz.

KURALLAR:
- 'Dosya kapsami', 'toplanan deliller', 'birlikte degerlendirildiginde' gibi ifadeler kullan.
- Sayisal skor veya yapay zeka terimi kullanma.
- Tek bir butun metin halinde yaz.

DEGERLENDIRME ADIMLARI:
{audit_summary}
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "GerekÃ§e oluÅŸturulamadÄ±."


class AppealArgumentGenerator:
    """V107: Hakim gerekÃ§esine karÅŸÄ± otomatik itiraz Ã¼retici (Eksik Ä°nceleme OdaklÄ±)"""

    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_reasoning):
        prompt = f"""
SEN KIDEMLI BIR AVUKATSIN.
Asagida bir hakimin karar gerekcesi yer almaktadir.
Bu gerekceden hareketle, UST MAHKEMEYE sunulmak uzere itiraz argumanlari yaz.

KURALLAR:
- Hakime saygi dili kullan
- "eksik inceleme", "yanlis takdir", "delillerin birlikte degerlendirilmemesi" kaliplari kullan
- Madde madde yaz (Max 5 madde)

HAKIM GEREKCESI:
{judge_reasoning}
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "Ä°tiraz argÃ¼manlarÄ± oluÅŸturulamadÄ±."


# --- V108 YENÄ° SINIFLAR ---
class AppealPetitionGenerator:
    """V108: Tam Metin Ä°stinaf/Temyiz DilekÃ§esi Yazar"""

    def __init__(self, llm):
        self.llm = llm

    def generate(self, judge_reasoning, case_topic):
        prompt = f"""
BAÄLAM: TÃ¼rk Hukuku. BAM / YargÄ±tay uygulamasÄ±.
SEN: KÄ±demli bir avukatsÄ±n.

AÅŸaÄŸÄ±da yer alan hakim gerekÃ§esine karÅŸÄ±, Ã¼st mahkemeye sunulmak Ã¼zere
RESMÄ°, KURUMSAL ve HUKUKÄ° DÄ°LDE tam bir Ä°TÄ°RAZ / Ä°STÄ°NAF / TEMYÄ°Z DÄ°LEKÃ‡ESÄ° taslaÄŸÄ± yaz.

KURALLAR:
- Hakime saygÄ±lÄ± dil kullan.
- "Eksik inceleme", "yanlÄ±ÅŸ takdir", "hukuka aykÄ±rÄ±lÄ±k" kalÄ±plarÄ± yer alsÄ±n.
- Madde numaralarÄ± kullan.

ZORUNLU BAÅLIKLAR:
1. KARARIN Ã–ZETÄ°
2. Ä°TÄ°RAZ NEDENLERÄ°
3. HUKUKÄ° DEÄERLENDÄ°RME
4. SONUÃ‡ VE Ä°STEM

DOSYA KONUSU: {case_topic}
HAKÄ°M GEREKÃ‡ESÄ°: {judge_reasoning}

Ã‡IKTI (Sadece DilekÃ§e Metni):
"""
        try:
            return self.llm.invoke(prompt).content.strip()
        except:
            return "DilekÃ§e oluÅŸturulamadÄ±."


class AppealActionMapper:
    """V108: Ä°tiraz maddelerini somut iÅŸ paketlerine Ã§evirir"""

    def __init__(self, llm):
        self.llm = llm

    def map_arguments(self, appeal_text):
        actions = []
        # Basit madde ayrÄ±ÅŸtÄ±rma (1., 2. vb.)
        arguments = [a.strip() for a in appeal_text.split("\n") if re.match(r"^\d+\.", a.strip())][:5]

        for arg in arguments:
            prompt = f"""
SEN KIDEMLI BIR AVUKATSIN.
Asagidaki itiraz argumanindan hareketle, avukatin fiilen yapmasi gereken SOMUT bir aksiyon tanimla.
JSON formatinda ver.

ALANLAR: title, evidence_type (tanÄ±k/belge/bilirkiÅŸi/iÃ§tihat), source, estimated_time, estimated_cost, risk_if_missing

ITIRAZ ARGUMANI: {arg}
"""
            try:
                res = self.llm.invoke(prompt).content.strip()
                # JSON temizliÄŸi
                if "```json" in res:
                    res = res.split("```json")[1].split("```")[0].strip()
                elif "```" in res:
                    res = res.split("```")[1].split("```")[0].strip()

                action = json.loads(res)
                action["action_id"] = str(uuid.uuid4())
                action["linked_argument"] = arg
                actions.append(action)
            except:
                continue
        return actions


class CorporateCover:
    @staticmethod
    def add(pdf, case_id, version="V110"):
        pdf.add_page()
        pdf.set_font("helvetica", "B", 24)
        pdf.ln(60)
        pdf.cell(0, 10, "LEGAL OS", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("helvetica", size=14)
        pdf.cell(0, 10, "Yapay Zeka Destekli Hukuki Analiz Raporu", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(30)
        pdf.set_font("helvetica", "B", 10)
        pdf.cell(0, 8, f"DOSYA KIMLIGI: {case_id}", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("helvetica", size=10)
        pdf.cell(0, 8, f"RAPOR TARIHI: {datetime.now().strftime('%d.%m.%Y %H:%M')}", align="C", new_x=XPos.LMARGIN,
                 new_y=YPos.NEXT)
        pdf.cell(0, 8, f"SISTEM SURUMU: {version}", align="C", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(50)
        pdf.set_font("helvetica", "I", 8)
        pdf.multi_cell(0, 5,
                       "YASAL UYARI: Bu rapor, yapay zeka algoritmalari kullanilarak uretilmistir. Hukuki tavsiye niteliginde olmayip, karar destek amaclidir.",
                       align="C")


# ==================================================
# 8ï¸âƒ£ ARAMA MOTORU SINIFI (SEARCH ENGINE)
# ==================================================
class LegalSearchEngine:
    def __init__(self):
        self.config = LegalConfig()
        self.dense_embedder = OllamaEmbeddings(model=self.config.EMBEDDING_MODEL)
        self.client = None
        atexit.register(self.close)

    def connect_db(self):
        if self.client is not None: return True
        print("   ğŸ”Œ VeritabanÄ± baÄŸlantÄ±sÄ± baÅŸlatÄ±lÄ±yor...")
        LegalUtils.force_unlock_db()
        try:
            self.client = QdrantClient(path=self.config.QDRANT_PATH)
            print("   âœ… VeritabanÄ± baÄŸlantÄ±sÄ± BAÅARILI.")
            return True
        except Exception as e:
            print(f"\nâŒ VERÄ°TABANI HATASI: {e}")
            return False

    def close(self):
        if self.client:
            try:
                self.client.close()
                self.client = None
                print("\nğŸ”’ VeritabanÄ± baÄŸlantÄ±sÄ± gÃ¼venli ÅŸekilde kapatÄ±ldÄ±.")
            except:
                pass

    def run_indexing(self):
        if not self.connect_db(): return False

        for key, config in self.config.SOURCES.items():
            collection_name = config["collection"];
            folder_path = config["folder"]
            print(f"   ğŸ‘‰ Koleksiyon kontrol ediliyor: {config['desc']}...")

            if not os.path.exists(folder_path):
                os.makedirs(folder_path);
                print(f"      âš ï¸ KlasÃ¶r oluÅŸturuldu: {folder_path}");
                continue

            if not self.client.collection_exists(collection_name):
                print(f"      âš™ï¸ '{collection_name}' oluÅŸturuluyor...")
                self.client.create_collection(collection_name,
                                              vectors_config=VectorParams(size=768, distance=Distance.COSINE))

            print(f"      ğŸ” Mevcut dosyalar taranÄ±yor...")
            indexed_files = set()
            offset = None
            while True:
                points, offset = self.client.scroll(collection_name, limit=100, with_payload=True, with_vectors=False,
                                                    offset=offset)
                for p in points:
                    if 'source' in p.payload: indexed_files.add(p.payload['source'])
                if offset is None: break

            files_on_disk = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]
            new_files = [f for f in files_on_disk if f not in indexed_files]

            if not new_files: print(f"      âœ… {config['desc']} gÃ¼ncel ({len(files_on_disk)} dosya)."); continue
            print(f"      â™»ï¸ {config['desc']} iÃ§in {len(new_files)} yeni dosya iÅŸleniyor...")

            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            all_texts = [];
            all_metadatas = []

            for filename in new_files:
                try:
                    loader = PyMuPDFLoader(os.path.join(folder_path, filename))
                    docs = loader.load()
                    chunks = text_splitter.split_documents(docs)
                    for c in chunks:
                        clean_content = LegalUtils.clean_text(c.page_content)
                        all_texts.append(clean_content)
                        all_metadatas.append(
                            {"source": filename, "type": config['desc'], "page": c.metadata.get("page", 0) + 1})
                    print(f"      ğŸ“„ Okundu: {filename}")
                except Exception as e:
                    print(f"      âš ï¸ Hata: {filename} - {e}")

            if not all_texts: continue
            print(f"      ğŸš€ VektÃ¶rleÅŸtiriliyor ({len(all_texts)} parÃ§a)...")

            num_cores = cpu_count();
            batch_size = (len(all_texts) // num_cores) + 1;
            batches = []
            for i in range(0, len(all_texts), batch_size): batches.append(
                (all_texts[i:i + batch_size], self.config.EMBEDDING_MODEL))

            all_vectors = []
            try:
                with Pool(processes=num_cores) as pool:
                    results = pool.map(worker_embed_batch_global, batches)
                    for res in results: all_vectors.extend(res)
            except Exception as e:
                print(f"âŒ Ä°ÅŸlemci HatasÄ±: {e}");
                return False

            print(f"      ğŸ’¾ Kaydediliyor...");
            points = []
            for i, (vec, meta, txt) in enumerate(zip(all_vectors, all_metadatas, all_texts)):
                payload = {"page_content": txt, "source": meta["source"], "page": meta["page"], "type": meta["type"]}
                point_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, txt + meta["source"] + collection_name))
                points.append(PointStruct(id=point_id, vector=vec, payload=payload))

            batch_size_upload = 64
            for i in range(0, len(points), batch_size_upload): self.client.upsert(collection_name,
                                                                                  points[i:i + batch_size_upload])

        print("âœ… Ä°ndeksleme TamamlandÄ±.");
        return True

    # --- V101: KOTA SÄ°STEMÄ° (FIX FOR STATUTE VISIBILITY) ---
    def retrieve_raw_candidates(self, full_query):
        print("\nğŸ” Belgeler TaranÄ±yor (Dual Search - AÅŸama 1: GeniÅŸ Havuz)...")
        try:
            query_vector = self.dense_embedder.embed_query(full_query)
        except Exception as e:
            print(f"âŒ Embedding HatasÄ±: {e}");
            return []

        all_candidates = []
        for key, config in self.config.SOURCES.items():
            try:
                results = self.client.query_points(collection_name=config["collection"], query=query_vector,
                                                   limit=self.config.SEARCH_LIMIT_PER_SOURCE).points
                for hit in results:
                    if 'type' not in hit.payload: hit.payload['type'] = config['desc']
                    all_candidates.append(hit)
            except:
                pass

        unique_docs = {}
        for hit in all_candidates:
            if hit.score < self.config.SCORE_THRESHOLD: continue
            key = f"{hit.payload['source']}_{hit.payload['page']}"
            if key not in unique_docs or hit.score > unique_docs[key].score: unique_docs[key] = hit

        # V101: KOTA SÄ°STEMÄ° UYGULAMASI
        emsal_hits = []
        mevzuat_hits = []

        for hit in unique_docs.values():
            if hit.payload.get('type') == 'MEVZUAT':
                mevzuat_hits.append(hit)
            else:
                emsal_hits.append(hit)

        emsal_hits.sort(key=lambda x: x.score, reverse=True)
        mevzuat_hits.sort(key=lambda x: x.score, reverse=True)

        limit = self.config.LLM_RERANK_LIMIT
        statute_quota = 3
        precedent_quota = limit - statute_quota

        final_candidates = emsal_hits[:precedent_quota] + mevzuat_hits[:statute_quota]

        if len(mevzuat_hits) < statute_quota:
            needed = limit - len(final_candidates)
            if needed > 0:
                extras = emsal_hits[precedent_quota: precedent_quota + needed]
                final_candidates.extend(extras)

        if not final_candidates: print("ğŸ”´ Uygun belge bulunamadÄ±."); return []
        print(f"   âœ… {len(final_candidates)} potansiyel belge bulundu. YargÄ±ca gÃ¶nderiliyor...")
        return final_candidates


# ==================================================
# 9ï¸âƒ£ YARGIÃ‡ VE MUHAKEME SINIFI (JUDGE)
# ==================================================
class LegalJudge:
    def __init__(self, memory_manager=None):
        self.llm = ChatOllama(model=LegalConfig.LLM_MODEL, temperature=0.1)
        self.memory = memory_manager

    def validate_user_input(self, story, topic):
        prompt = f"""
GÃ–REV: Metnin tamamen anlamsÄ±z rastgele tuÅŸlama (gibberish) olup olmadÄ±ÄŸÄ±nÄ± tespit et.
METÄ°N: "{story} {topic}"
ANALÄ°Z KURALLARI:
1. "araba", "miras" gibi tek kelimelik girdiler [GEÃ‡ERLÄ°].
2. Sadece "asdasd", "lkgjdf" gibi rastgele tuÅŸlamalar [GEÃ‡ERSÄ°Z].
CEVAP (SADECE BÄ°RÄ°): [GEÃ‡ERLÄ°] veya [GEÃ‡ERSÄ°Z]
"""
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "GEÃ‡ERSÄ°Z" in res: return False
            return True
        except:
            return True

    def generate_expanded_queries(self, story, topic):
        print("   â†³ ğŸ§  Sorgu GeniÅŸletiliyor...")
        try:
            prompt = f"GÃ–REV: Hukuki terimler.\nOLAY: {story}\nODAK: {topic}\n3 kÄ±sa cÃ¼mle."
            res = self.llm.invoke(prompt).content
            return [line.strip() for line in res.splitlines() if len(line) > 5][:3]
        except:
            return [story]

    def _check_relevance_judge_smart(self, user_query, user_filter, negative_keywords, document_text, source_name,
                                     doc_type="EMSAL"):
        found_negative = None
        if negative_keywords:
            doc_lower = document_text.lower()
            for bad in negative_keywords:
                if re.search(rf"\b{re.escape(bad)}\b", doc_lower): found_negative = bad; break

        if found_negative:
            prompt = f"HUKUKÃ‡U. Sorgu: '{user_query}'. YasaklÄ±: '{found_negative}'. Uygun mu? [RED]/[KABUL]."
            res = self.llm.invoke(prompt).content.strip()
            if "RED" in res: return False, f"â›” YASAKLI: {res}"

        memory_context = ""
        if self.memory:
            memory_context = self.memory.recall_principles(user_query)

        # V102: DOC TYPE SPECIFIC PROMPT
        if doc_type == "MEVZUAT":
            focus_instruction = "GÃ–REV: Bu kanun maddesi, yukarÄ±daki olaya HUKUKÄ° DAYANAK (Kanuni Temel) teÅŸkil ediyor mu?\nBenzerlik arama, uygulanabilirlik ara."
        else:
            focus_instruction = "GÃ–REV: Bu emsal karar, yukarÄ±daki olayla Ã–RGÃœ VE SONUÃ‡ bakÄ±mÄ±ndan BENZER mi?\nOlay benzerliÄŸi ara."

        prompt_gen = f"""
SEN KIDEMLI BIR HUKUKCUSSUN.
{memory_context}

Sorgu: "{user_query}"
Belge ({doc_type}): "{document_text[:700]}..."

{focus_instruction}

SADECE BÄ°RÄ°NÄ° SEÃ‡: [Ã‡OK BENZER/UYGUN], [BENZER/UYGUN], [ZAYIF/ALAKASIZ]
AltÄ±na tek cÃ¼mlelik gerekÃ§e yaz.
"""
        res = self.llm.invoke(prompt_gen).content.strip()
        is_ok = ("Ã‡OK BENZER" in res) or ("BENZER" in res) or ("UYGUN" in res) or ("KABUL" in res)
        return is_ok, res

    def _assign_document_role(self, user_query, document_text):
        prompt = f"""
SEN HUKUKÃ‡USUN.
Sorgu: "{user_query}"
Belge: "{document_text[:800]}..."
GÃ–REV: Bu belge hukuki analizde nasÄ±l kullanÄ±lmalÄ±?
1. [DOÄRUDAN DELÄ°L]: Olay Ã¶rgÃ¼sÃ¼ birebir Ã¶rtÃ¼ÅŸÃ¼yor.
2. [EMSAL Ä°LKE]: Olay farklÄ± ama hukuk kuralÄ± uygulanabilir.
SADECE ÅUNLARDAN BÄ°RÄ°NÄ° SEÃ‡:
[DOÄRUDAN DELÄ°L] veya [EMSAL Ä°LKE]
"""
        try:
            res = self.llm.invoke(prompt).content.strip()
            if "DOÄRUDAN" in res: return "[DOÄRUDAN DELÄ°L]"
            return "[EMSAL Ä°LKE]"
        except:
            return "[EMSAL Ä°LKE]"

    def evaluate_candidates(self, candidates, story, topic, negatives):
        print("\nâš–ï¸  AkÄ±llÄ± YargÄ±Ã§ DeÄŸerlendiriyor (V105: Corporate Intelligence):")
        valid_docs = []

        for hit in candidates:
            doc_text = hit.payload['page_content']
            source = hit.payload['source']
            page = hit.payload['page']
            type_desc = hit.payload['type']

            is_ok, reason = self._check_relevance_judge_smart(story, topic, negatives, doc_text, source, type_desc)

            consensus_multiplier = 1.0
            if self.memory:
                consensus_decision = "KABUL" if is_ok else "RED"
                consensus_multiplier = self.memory.calculate_memory_consensus(source, consensus_decision, hit.score)

            base_score = min(max(hit.score, 0), 1) * 100
            norm_score = min(base_score * consensus_multiplier, 100.0)

            icon = "âœ…" if is_ok else "âŒ"

            if self.memory:
                decision_tag = "KABUL" if is_ok else "RED"
                self.memory.save_decision(f"{story} {topic}", source, decision_tag, reason, type_desc)

            if is_ok:
                role = self._assign_document_role(story, doc_text)

                log_score = f"%{norm_score:.1f}"
                if consensus_multiplier > 1.1:
                    log_score += " (â¬†ï¸ YÃœKSEK GÃœVEN)"
                elif consensus_multiplier < 1.0:
                    log_score += " (â¬‡ï¸ RÄ°SKLÄ°)"

                print(f"{icon} [{type_desc}] {source:<20} | GÃ¼ven: {log_score} | Rol: {role}")

                extra_context = ""
                if type_desc == "EMSAL KARAR":
                    real_path = os.path.join(LegalConfig.SOURCES["emsal"]["folder"], source)
                    verdict = LegalUtils.extract_pdf_conclusion(real_path)
                    extra_context = f"\n\nğŸ›‘ [OTOMATÄ°K EKLENEN KARAR SONUCU ({source})]:\n{verdict}\nğŸ›‘ KARAR SONU."

                valid_docs.append({
                    "source": source, "page": page, "type": type_desc, "role": role,
                    "text": doc_text + extra_context, "score": norm_score, "reason": reason
                })
            else:
                print(f"{icon} [{type_desc}] {source:<20} | GÃ¼ven: %{norm_score:.1f}")

        return valid_docs

    def generate_final_opinion(self, story, topic, context_str):
        print("\nğŸ§‘â€âš–ï¸  AVUKAT YAZIYOR (V105: Final Output)...")

        system_content = """SEN KIDEMLÄ° BÄ°R HUKUKÃ‡USUN.
GÃ–REVÄ°N: Sana verilen "DELÄ°LLER" listesindeki YargÄ±Ã§ notlarÄ±nÄ± derleyerek nihai raporu yazmak.

KURALLAR:
1. SADECE YargÄ±Ã§'Ä±n "GerekÃ§e" veya "Sebep" olarak yazdÄ±ÄŸÄ± bilgileri temel al.
2. Belgelerin iÃ§indeki konuyla alakasÄ±z (harÃ§ iadesi, usul detaylarÄ± vb.) kÄ±sÄ±mlarÄ± GÃ–RMEZDEN GEL.
3. ASLA aynÄ± bilgiyi tekrar etme.
4. Ã‡Ä±ktÄ±yÄ± tam olarak ÅŸu baÅŸlÄ±klarla ver:

A. MEVZUAT DAYANAKLARI
(Burada sadece MEVZUAT etiketli belgeleri Ã¶zetle)

B. Ä°LGÄ°LÄ° EMSAL KARARLAR
(Burada EMSAL KARAR etiketli belgeleri, YargÄ±Ã§'Ä±n belirlediÄŸi ROL'e gÃ¶re, YargÄ±Ã§ GerekÃ§esi'ni kullanarak anlat)

C. SONUÃ‡ VE HUKUKÄ° TAVSÄ°YE
(KullanÄ±cÄ±nÄ±n olayÄ±na gÃ¶re, bulunan emsallere dayanarak net bir yol haritasÄ± Ã§iz)"""

        user_content = f"""AÅŸaÄŸÄ±daki "DELÄ°LLER" listesinde sunulan belgeleri kullanarak olayÄ± analiz et.
OLAY: "{story}"
ODAK: "{topic}"
DELÄ°LLER:
{context_str}
ANALÄ°ZÄ° BAÅLAT:"""

        messages = [SystemMessage(content=system_content), HumanMessage(content=user_content)]

        full_res = ""
        for chunk in self.llm.stream(messages):
            c = chunk.content;
            full_res += c;
            print(c, end="", flush=True)
        print("\n")
        return full_res


# ==================================================
# ğŸ”Ÿ RAPORLAMA SINIFI (BRANDED GENERATOR)
# ==================================================
class BrandedPDFGenerator(FPDF):
    """V106: Markalanabilir PDF Motoru"""

    def __init__(self, branding):
        super().__init__()
        self.branding = branding

    def header(self):
        if self.branding.logo_path and os.path.exists(self.branding.logo_path):
            self.image(self.branding.logo_path, x=10, y=8, w=30)
        self.set_font("helvetica", "B", 12)
        self.set_text_color(*self.branding.color)
        self.cell(0, 10, self.branding.firm_name, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')
        self.set_draw_color(200, 200, 200)
        self.line(10, 25, 200, 25)
        self.ln(15)
        self.set_text_color(0, 0, 0)

    def footer(self):
        self.set_y(-15);
        self.set_font('helvetica', 'I', 8);
        self.set_text_color(128, 128, 128)
        self.cell(0, 10, f'{self.branding.footer_text} | Sayfa {self.page_no()}', align='C')


class LegalReporter:
    @staticmethod
    def add_persona_comparison_page(pdf, personas):
        if not personas: return
        pdf.add_page()
        pdf.set_font("helvetica", "B", 12)
        pdf.cell(0, 10, "EK-2: YARGISAL PERSPEKTIF KARSILASTIRMASI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)

        col_width = pdf.epw / 3
        start_y = pdf.get_y()

        p_list = [
            ("HAKIM", personas.get("judge", "")),
            ("KARSI TARAF", personas.get("opponent", "")),
            ("BILIRKISI", personas.get("expert", ""))
        ]

        max_y = start_y
        for i, (title, text) in enumerate(p_list):
            x = pdf.l_margin + i * col_width
            pdf.set_xy(x, start_y)
            pdf.set_font("helvetica", "B", 10)
            pdf.multi_cell(col_width - 2, 6, title, align='C')
            pdf.ln(1)
            pdf.set_xy(x, pdf.get_y())  # Reset X after multicell
            pdf.set_font("helvetica", size=8)
            pdf.multi_cell(col_width - 2, 4, text)
            max_y = max(max_y, pdf.get_y())

        pdf.set_y(max_y + 10)

    @staticmethod
    def add_appeal_arguments_page(pdf, appeal_text):
        if not appeal_text: return
        pdf.add_page()
        pdf.set_font("helvetica", "B", 12)
        pdf.cell(0, 10, "EK-3: OLASI ITIRAZ ARGUMANLARI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)
        pdf.set_font("helvetica", size=10)
        pdf.multi_cell(0, 6, appeal_text)

    # V108: Ä°STÄ°NAF DÄ°LEKÃ‡ESÄ° EKLEME
    @staticmethod
    def add_petition_page(pdf, petition_text):
        if not petition_text: return
        pdf.add_page()
        pdf.set_font("helvetica", "B", 12)
        pdf.cell(0, 10, "EK-4: ISTINAF / TEMYIZ DILEKCESI TASLAGI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)
        pdf.set_font("helvetica", size=10)
        pdf.multi_cell(0, 6, petition_text)

    # V108: AKSÄ°YON PLANI EKLEME
    @staticmethod
    def add_action_plan_page(pdf, action_plan):
        if not action_plan: return
        pdf.add_page()
        pdf.set_font("helvetica", "B", 12)
        pdf.cell(0, 10, "EK-5: ITIRAZ AKSÄ°YON PLANI", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)

        for action in action_plan:
            pdf.set_font("helvetica", "B", 10)
            pdf.cell(0, 8, f">> {action.get('title', 'Aksiyon')}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            pdf.set_font("helvetica", size=9)
            pdf.multi_cell(0, 5, f"Kaynak: {action.get('source', '')} | Risk: {action.get('risk_if_missing', '')}")
            pdf.ln(2)

    @staticmethod
    def add_audit_log_section(pdf, audit_data):
        if not audit_data or "timeline" not in audit_data: return
        pdf.add_page()
        pdf.set_font("helvetica", "B", 13)
        pdf.cell(0, 10, "3. KARAR SURECI VE DENETIM (AUDIT LOG)", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(3)

        timeline = AuditTimelineBuilder.build(audit_data)
        explanation = ScoreExplanationEngine.generate(timeline)

        pdf.set_font("helvetica", "B", 10)
        pdf.cell(0, 8, "SKOR DEGISIM ANALIZI:", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("helvetica", "I", 10)
        pdf.multi_cell(0, 5, explanation)
        pdf.ln(5)

        for log in audit_data["timeline"]:
            step = log.get("step", 0)
            title = log.get("title", "Islem")
            desc = log.get("description", "")
            score = log.get("resulting_score")
            ts = datetime.fromtimestamp(log.get("timestamp", time.time())).strftime('%H:%M:%S')

            pdf.set_font("helvetica", "B", 10)
            pdf.cell(0, 6, f"{step}. {title.upper()} [{ts}]", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            pdf.set_font("helvetica", size=9)
            pdf.multi_cell(w=0, h=5, text=f"Detay: {desc}")
            if score:
                pdf.set_font("helvetica", "B", 8)
                pdf.cell(0, 5, f">> SKOR ETKISI: %{score}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            pdf.ln(2)

    @staticmethod
    def create_report(user_story, valid_docs, advice_text, audit_data=None, filename="Hukuki_Rapor_V110.pdf", llm=None,
                      personas=None, case_topic=""):
        branding = WhiteLabelConfig(
            firm_name="LEGAL OS CORP",
            footer_text="Gizli ve Ozeldir - Otomatik Analiz Raporu",
            color=(0, 51, 102)
        )
        pdf = BrandedPDFGenerator(branding)

        CorporateCover.add(pdf, audit_data.get("case_id", "N/A") if audit_data else "N/A", "V110")

        pdf.add_page();
        pdf.set_font("helvetica", size=11)

        def clean(t):
            if not t: return ""
            tr = {'ÄŸ': 'g', 'Ã¼': 'u', 'ÅŸ': 's', 'Ä±': 'i', 'Ã¶': 'o', 'Ã§': 'c', 'Ä': 'G', 'Ãœ': 'U', 'Å': 'S', 'Ä°': 'I',
                  'Ã–': 'O', 'Ã‡': 'C'}
            for k, v in tr.items(): t = t.replace(k, v)
            return t.encode('latin-1', 'replace').decode('latin-1')

        pdf.set_font(style='B', size=12);
        pdf.cell(0, 10, clean("1. OLAY VE KAPSAM:"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font(style='', size=10);
        pdf.multi_cell(0, 6, clean(user_story));
        pdf.ln(5)

        pdf.set_font(style='B', size=12);
        pdf.cell(0, 10, clean("2. INCELEME VE HUKUKI GORUS:"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font(style='', size=10);
        pdf.multi_cell(0, 6, clean(advice_text))

        if audit_data:
            LegalReporter.add_audit_log_section(pdf, audit_data)

            if llm:
                reasoning_gen = JudgeReasoningGenerator(llm)
                judge_text = reasoning_gen.generate(audit_data)

                pdf.add_page()
                pdf.set_font("helvetica", "B", 13)
                pdf.cell(0, 10, clean("EK-1: HAKIM KARAR GEREKCESI TASLAGI"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)
                pdf.ln(5)
                pdf.set_font("helvetica", "I", 10)
                pdf.multi_cell(0, 6, clean(judge_text))

                appeal_gen = AppealArgumentGenerator(llm)
                appeal_text = appeal_gen.generate(judge_text)
                LegalReporter.add_appeal_arguments_page(pdf, clean(appeal_text))

                # V108: Ä°STÄ°NAF DÄ°LEKÃ‡ESÄ°
                petition_gen = AppealPetitionGenerator(llm)
                petition_text = petition_gen.generate(judge_text, case_topic)
                LegalReporter.add_petition_page(pdf, clean(petition_text))

                # V108: AKSÄ°YON PLANI
                action_mapper = AppealActionMapper(llm)
                action_plan = action_mapper.map_arguments(appeal_text)
                # Clean action plan texts
                for ap in action_plan:
                    ap['title'] = clean(ap.get('title', ''))
                    ap['source'] = clean(ap.get('source', ''))
                    ap['risk_if_missing'] = clean(ap.get('risk_if_missing', ''))
                LegalReporter.add_action_plan_page(pdf, action_plan)

            if personas:
                clean_personas = {k: clean(v) for k, v in personas.items() if isinstance(v, str)}
                LegalReporter.add_persona_comparison_page(pdf, clean_personas)

        try:
            pdf.output(filename); print(f"\nğŸ“„ Kurumsal Rapor (V110) HazÄ±r: {filename}")
        except:
            pass


# ==================================================
# 1ï¸âƒ£1ï¸âƒ£ LEGAL UI PRINTER
# ==================================================
class LegalUIPrinter:
    @staticmethod
    def print_grand_ui_log(ui_data, doc_scan_log):
        if not ui_data or not ui_data.get("principles"): return

        print("\n" + "â–ˆ" * 80)
        print(f"ğŸ–¥ï¸  LEGAL OS V110 - TAM KAPSAMLI ANALÄ°Z VE TAKÄ°P RAPORU")
        print("â–ˆ" * 80 + "\n")

        # 0. AUDIT TIMELINE
        print(f"â±ï¸ 0. Ä°ÅLEM ZAMAN Ã‡Ä°ZELGESÄ° (AUDIT LOG):")
        for log in ui_data.get("audit_log", {}).get("timeline", []):
            ts = datetime.fromtimestamp(log['timestamp']).strftime('%H:%M:%S')
            print(f"   ğŸ•’ [{ts}] {log['title']} -> {log['description']}")
        print("-" * 80)

        # 1. BELGELER & YARGIÃ‡ GEREKÃ‡ELERÄ°
        print(f"ğŸ“‚ 1. BELGE TARAMA VE YARGIÃ‡ DEÄERLENDÄ°RMESÄ°:")
        for doc in doc_scan_log:
            print(f"   ğŸ“„ {doc['source']} (Sf.{doc['page']}) -> {doc['role']}")
            print(f"      â†³ GerekÃ§e: {doc['reason'][:100]}...")
        print("-" * 80)

        # PRINCIPLE LOOP
        p = ui_data["principles"][0]

        # 2-6. Ä°LKE ANALÄ°ZÄ°
        print(f"âš–ï¸  2. SEÃ‡Ä°LEN TEMEL Ä°LKE:\n   \"{p['text'][:120]}...\"")
        print(f"   ğŸ“Š 3. ZÄ±tlÄ±k Analizi: {'âš ï¸ VAR' if p['conflict_flag'] else 'âœ… YOK'}")
        print(f"   ğŸ“ˆ 4. Trend Logu: {p['trend_log']}")
        print(f"   ğŸ§­ 5. Polarite: {p['polarity']}")
        print(f"   ğŸ”¥ 6. Ã‡eliÅŸki Tespiti: {p['conflict_analysis']['conflict_level']}")
        print("-" * 80)

        # 10-12. ZAMAN VE EVRÄ°M
        print(f"â³ 10. Ä°LKE EVRÄ°MÄ°: {p['trend_log']}")
        print(f"ğŸ“… 11. GÃœNCEL Ä°Ã‡TÄ°HAT UYARISI: {p['year_bucket']} DÃ¶nemi")
        print("-" * 80)

        # 13-14. SKOR VE NEDENÄ°
        print(
            f"ğŸ² 13. RÄ°SK & BAÅARI SKORU: %{p['score_data']['success_probability']} ({p['score_data']['confidence_level']})")
        print(f"â“ 14. NEDEN BU SKOR?: {p['score_data']['summary']}")
        print("-" * 80)

        # 15-18. PERSONA LOGLARI
        opp_title = p['personas']['opponent_title']
        print("ğŸ—£ï¸  PERSONA GÃ–RÃœÅLERÄ°:")
        print(f"   ğŸ‘¨â€âš–ï¸ 15. HAKÄ°M DÄ°LÄ°: \"{p['personas']['judge'][:100]}...\"")
        print(f"   ğŸ›ï¸ 16. {opp_title} (KARÅI TARAF): \"{p['personas']['opponent'][:100]}...\"")
        print(f"   ğŸ” 17. BÄ°LÄ°RKÄ°ÅÄ° DÄ°LÄ°: \"{p['personas']['expert'][:100]}...\"")
        print(f"   ğŸ›‘ 18. HAKÄ°M NEDEN REDDEDER?: \"{p['personas']['devil'][:100]}...\"")
        print("-" * 80)

        # 19. Ã‡ELÄ°ÅKÄ° ANALÄ°ZÄ°
        if p['conflict_analysis']['conflict_score'] > 0:
            print(
                f"âš”ï¸  19. PERSONA Ã‡ELÄ°ÅKÄ° ANALÄ°ZÄ°: {p['conflict_analysis']['conflict_level']} (Skor: {p['conflict_analysis']['conflict_score']})")
            for r in p['conflict_analysis']['summary']: print(f"      ğŸ”´ {r}")
        print("-" * 80)

        # 20. GEREKÃ‡ELÄ° KARAR
        print(f"âœï¸  20. GEREKÃ‡ELÄ° KARAR TASLAÄI:\n   {p['reasoned_verdict'][:200]}...")
        print("-" * 80)

        # 21. YÃ–NETÄ°CÄ° Ã–ZETÄ°
        print(f"ğŸ“ 21. YÃ–NETÄ°CÄ° Ã–ZETÄ° (BU DOSYA NEDEN RÄ°SKLÄ°?):\n   {ui_data['executive_summary']}")
        print("-" * 80)

        # 22, 26, 27. STRATEJÄ° VE Ä°Å PAKETLERÄ°
        print("ğŸš€ 22/26/27. GÃœÃ‡LENDÄ°RME & SOMUT Ä°Å PAKETLERÄ°:")
        for act in p['action_plan']:
            src = act['evidence']['source']
            src_str = f"{src['entity']} ({src['method']})" if isinstance(src, dict) else src
            print(f"   ğŸ“¦ [ID: {act['action_id'][:6]}] {act['title']}")
            print(f"      â†³ Kaynak: {src_str} (Adet: {act['evidence']['count']})")
            print(f"      â†³ Risk: {act['if_not_done']}")
            print(f"      â†³ Etki: +{act['risk_reduction']['expected_score_increase']} Puan")
        print("-" * 80)

        # 23, 28. SÄ°MÃœLASYON
        sim = p['simulation']
        print(f"ğŸ”® 23/28. SÄ°MÃœLASYON SONUCU:")
        print(f"   Mevcut: %{sim['current_score']} --> Hedef: %{sim['projected_score']}")
        print(f"   ArtÄ±ÅŸ: +{sim['total_boost']} Puan")
        print("â–ˆ" * 80 + "\n")


# ==================================================
# 1ï¸âƒ£2ï¸âƒ£ ANA UYGULAMA (MAIN APP)
# ==================================================
class LegalApp:
    def __init__(self):
        print("ğŸš€ LEGAL SUITE V110 (Ultimate Full Stack)...")
        self.search_engine = LegalSearchEngine()

        if self.search_engine.connect_db():
            self.memory_manager = LegalMemoryManager(
                self.search_engine.client,
                self.search_engine.dense_embedder,
                ChatOllama(model=LegalConfig.LLM_MODEL, temperature=0.1)
            )
        else:
            self.memory_manager = None

        self.judge = LegalJudge(memory_manager=self.memory_manager)
        self.reporter = LegalReporter()
        self.ui_printer = LegalUIPrinter()

    def run(self):
        if not self.search_engine.run_indexing():
            self.search_engine.close()
            sys.exit()

        if self.memory_manager:
            self.memory_manager.consolidate_principles_v79()

        print("\nâœ… SÄ°STEM HAZIR. (Ã‡Ä±kÄ±ÅŸ: 'q')")

        try:
            while True:
                print("-" * 60)
                story = input("ğŸ“ Olay: ");
                if story == 'q': break
                topic = input("ğŸ¯ Odak: ")
                neg_input = input("ğŸš« YasaklÄ±: ")
                negatives = [w.strip().lower() for w in neg_input.split(",")] if neg_input else []

                print("   ğŸ›¡ï¸ Girdi kontrol ediliyor...")
                if not self.judge.validate_user_input(story, topic):
                    print("   âŒ UYARI: Girdi anlamsÄ±z. LÃ¼tfen mantÄ±klÄ± bir olay giriniz.")
                    continue

                expanded = self.judge.generate_expanded_queries(story, topic)
                full_query = f"{story} {topic} " + " ".join(expanded)
                print(f"   âœ“ Sorgu: {len(full_query)} karakter")

                candidates = self.search_engine.retrieve_raw_candidates(full_query)
                if not candidates: continue

                valid_docs = self.judge.evaluate_candidates(candidates, story, topic, negatives)
                if not valid_docs: print("ğŸ”´ YargÄ±Ã§ hepsini eledi."); continue

                context_str = ""
                doc_scan_log = []
                for i, d in enumerate(valid_docs):
                    doc_scan_log.append({
                        "source": d['source'], "page": d['page'],
                        "role": d['role'], "reason": d['reason']
                    })
                    context_str += f"""
                        BELGE #{i + 1}
                        KAYNAK: {d['source']}
                        TÃœR: {d['type']}
                        ROL: {d['role']}
                        YARGIÃ‡ GEREKÃ‡ESÄ°: {d['reason']}
                        Ä°Ã‡ERÄ°K Ã–ZETÄ°: {d['text'][:800]}...
                        =========================================
                        """

                current_personas = {}
                if self.memory_manager:
                    self.memory_manager.recall_principles(full_query)
                    self.ui_printer.print_grand_ui_log(self.memory_manager.latest_ui_data, doc_scan_log)

                    if self.memory_manager.latest_ui_data.get("principles"):
                        current_personas = self.memory_manager.latest_ui_data["principles"][0]["personas"]

                full_advice = self.judge.generate_final_opinion(story, topic, context_str)

                # V110: FULL PARAMETER PASS
                audit_dump = {}
                llm_instance = None
                if self.memory_manager and hasattr(self.memory_manager, 'latest_ui_data'):
                    audit_dump = self.memory_manager.latest_ui_data.get("audit_log", {})
                    llm_instance = self.memory_manager.recommendation_engine.llm

                self.reporter.create_report(story, valid_docs, full_advice, audit_dump, "Hukuki_Rapor_V110.pdf",
                                            llm_instance, current_personas, full_query)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Program durduruldu.")
        except Exception as e:
            print(f"\nâš ï¸ Hata: {e}")
        finally:
            self.search_engine.close()


if __name__ == "__main__":
    freeze_support()
    app = LegalApp()
    app.run()